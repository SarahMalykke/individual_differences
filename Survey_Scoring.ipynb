{"cells":[{"cell_type":"markdown","source":["*Note: Updated scoring functions have not yet been run for Session 1 surveys*"],"metadata":{"id":"F4C_kJGaM7t6"}},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"Lu33PE-UAp3t"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","from openpyxl import load_workbook\n","import os\n","!pip install timezonefinder pytz\n","from timezonefinder import TimezoneFinder\n","import pytz"],"metadata":{"id":"GhDLMV6KApLL","executionInfo":{"status":"ok","timestamp":1761053075948,"user_tz":240,"elapsed":14170,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e42a1d0d-3cab-4bbe-d335-f64a2c6c1054"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timezonefinder\n","  Downloading timezonefinder-8.1.0-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (2025.2)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from timezonefinder) (2.0.2)\n","Collecting h3>4 (from timezonefinder)\n","  Downloading h3-4.3.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: cffi<3,>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from timezonefinder) (2.0.0)\n","Requirement already satisfied: flatbuffers>=25.2.10 in /usr/local/lib/python3.12/dist-packages (from timezonefinder) (25.9.23)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi<3,>=1.15.1->timezonefinder) (2.23)\n","Downloading timezonefinder-8.1.0-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h3-4.3.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: h3, timezonefinder\n","Successfully installed h3-4.3.1 timezonefinder-8.1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"8DGFbiIgdE5P"},"source":["# Set up Environment and Prep Survey Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26514,"status":"ok","timestamp":1761053233642,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"},"user_tz":240},"id":"4QxZL2XtdDJS","outputId":"6904979d-7e87-4b21-acdb-a6707830b007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Total Prolific IDs in Session 1: 1701\n","Total unique IDs in S1 filtered data: 1701\n","Total Prolific IDs in survey: 1218\n","Total unique IDs in filtered data: 1218\n","Total Prolific IDs in Session 3: 779\n","Total unique IDs in S3 filtered data: 779\n"]}],"source":["# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","# Define path to survey data\n","# Session 1\n","#s1_data_path = '/content/drive/My Drive/battery_survey_scoring/data/survey/Burnout Battery - Prolific (April 2024)_August 1, 2024_08.30.csv'\n","s1_data_path = '/content/drive/My Drive/battery_survey_scoring/data/survey/Burnout Battery - Prolific - Session 1 (April 2024)_October 8, 2025_14.15.csv' # new path with new participants 10-8-25\n","s1_prolific_data_paths = [\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s1_b1.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s1_b2.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s1_b3.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s1_b4.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s1_b5.csv',\n","]\n","\n","# Session 2\n","s2_data_path = '/content/drive/My Drive/battery_survey_scoring/data/survey/Burnout Battery - Prolific - Session 2 (2024)_October 8, 2025_14.16.csv' #updated for readi pt 2\n","s2_prolific_data_paths = [\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s2.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s2_b2.csv',\n","]\n","\n","# Session 3\n","s3_data_path = '/content/drive/My Drive/battery_survey_scoring/data/survey/Burnout Battery - Session 3 Pilot (Spring 2025)_October 8, 2025_14.16.csv'\n","s3_prolific_data_paths = [\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s3.csv',\n","    '/content/drive/My Drive/battery_survey_scoring/data/worker_info/prolific_export_s3_b2.csv',\n","    ]\n","\n","\n","# For seeing if they have Ts and Ls data:\n","# worker_data_path = '/content/drive/My Drive/battery_survey_scoring/data/worker_info/worker_conditions_S2.csv'\n","\n","# Load survey data\n","s1_data = pd.read_csv(s1_data_path)\n","s1_prolific_dfs = [pd.read_csv(path) for path in s1_prolific_data_paths]\n","s1_prolific_combined_df = pd.concat(s1_prolific_dfs, ignore_index=True)\n","\n","s2_data = pd.read_csv(s2_data_path)\n","s2_prolific_dfs = [pd.read_csv(path) for path in s2_prolific_data_paths]\n","s2_prolific_data = pd.concat(s2_prolific_dfs, ignore_index=True)\n","\n","s3_data = pd.read_csv(s3_data_path)\n","s3_prolific_dfs = [pd.read_csv(path) for path in s3_prolific_data_paths]\n","s3_prolific_data = pd.concat(s3_prolific_dfs, ignore_index=True)\n","\n","# To load in question text\n","s1_metadata_row = s1_data.iloc[0]\n","s2_metadata_row = s2_data.iloc[0]\n","s3_metadata_row = s3_data.iloc[0]\n","\n","\n","# Load worker data (Ts and Ls IDs)\n","#worker_data = pd.read_csv(worker_data_path)\n","#prolific_ids = set(worker_data['workerId'].tolist())  # Use a set for faster lookup\n","\n","# Regular expression to filter valid Prolific IDs (assumes Prolific IDs are 24 alphanumeric characters)\n","valid_id_regex = r'^[a-zA-Z0-9]{24}$'\n","\n","# IDs to exclude (experimenters' IDs)\n","exceptions = ['659efaac1d035e0153317cbc']\n","\n","#**TO DO: filter out participants who do not have prolific data**\n","\n","# Specify which column to use for prolific_id\n","# S1\n","s1_prolific_id = 'Q5'\n","# S2\n","s2_prolific_id = 'Q1'\n","# S3\n","s3_prolific_id = 'Q5'\n","\n","\n","# Filter data to only include valid Prolific IDs and exclude specific exceptions\n","s1_data = s1_data[s1_data[s1_prolific_id].str.match(valid_id_regex, na=False) & ~s1_data[s1_prolific_id].isin(exceptions)]\n","s2_data = s2_data[s2_data[s2_prolific_id].str.match(valid_id_regex, na=False) & ~s2_data[s2_prolific_id].isin(exceptions)]\n","s3_data = s3_data[s3_data[s3_prolific_id].str.match(valid_id_regex, na=False) & ~s3_data[s3_prolific_id].isin(exceptions)]\n","\n","\n","# Add a column to mark if the respondent is in the worker data\n","#data['has_Ts_and_Ls'] = data[prolific_id].apply(lambda x: 'Yes' if x in prolific_ids else 'No')\n","\n","# Remove duplicates based on PROLIFIC_PID\n","s1_filtered_data = s1_data.drop_duplicates(subset=[s1_prolific_id], keep='first')\n","s2_filtered_data = s2_data.drop_duplicates(subset=[s2_prolific_id], keep='first')\n","s3_filtered_data = s3_data.drop_duplicates(subset=[s3_prolific_id], keep='first')\n","\n","\n","#===========================================\n","# merge prolific data with qualtrics data to keep relevant fields from qualtrics\n","#===========================================\n","s1_prolific_combined_df = s1_prolific_combined_df.merge(\n","    s1_filtered_data[['Q5', 'LocationLatitude', 'LocationLongitude']],\n","    how='left',\n","    left_on='Participant id',\n","    right_on='Q5'\n",").drop(columns=['Q5'])  # drop Q5 after merge\n","\n","\n","s2_prolific_data = s2_prolific_data.merge(\n","    s2_filtered_data[['Q1', 'LocationLatitude', 'LocationLongitude']],\n","    how='left',\n","    left_on='Participant id',\n","    right_on='Q1'\n",").drop(columns=['Q1'])  # drop Q5 after merge\n","\n","\n","s3_prolific_data = s3_prolific_data.merge(\n","    s3_filtered_data[['Q5', 'LocationLatitude', 'LocationLongitude']],\n","    how='left',\n","    left_on='Participant id',\n","    right_on='Q5'\n",").drop(columns=['Q5'])\n","#===========================================\n","\n","# Output the number of unique PROLIFIC_PID in the survey and those matching with worker data\n","print(f\"Total Prolific IDs in Session 1: {s1_data[s1_prolific_id].nunique()}\")\n","print(f\"Total unique IDs in S1 filtered data: {s1_filtered_data[s1_prolific_id].nunique()}\")\n","\n","print(f\"Total Prolific IDs in survey: {s2_data[s2_prolific_id].nunique()}\")\n","print(f\"Total unique IDs in filtered data: {s2_filtered_data[s2_prolific_id].nunique()}\")\n","#print(f\"IDs matched with Ts and Ls data: {filtered_data['has_Ts_and_Ls'].value_counts().get('Yes', 0)}\")  # Safe access\n","\n","#Session 3\n","print(f\"Total Prolific IDs in Session 3: {s3_data[s3_prolific_id].nunique()}\")\n","print(f\"Total unique IDs in S3 filtered data: {s3_filtered_data[s3_prolific_id].nunique()}\")"]},{"cell_type":"code","source":["s1_prolific_combined_df['Participant id'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"6nD7qoX487Bp","executionInfo":{"status":"ok","timestamp":1761053357018,"user_tz":240,"elapsed":41,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"1da24717-d4bc-4269-ec57-15f45769d9f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    65985fb8ca6a586ffeb25e6c\n","1    659c055cbfece76fed7304eb\n","2    5c78b032419dcc0014119082\n","3    5d901b10d7a21a001d635d12\n","4    65959564477c6a68a50176e4\n","Name: Participant id, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Participant id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65985fb8ca6a586ffeb25e6c</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>659c055cbfece76fed7304eb</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5c78b032419dcc0014119082</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5d901b10d7a21a001d635d12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>65959564477c6a68a50176e4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)\n","\n","s1_filtered_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":730},"id":"N10ukKfTf8Ya","executionInfo":{"status":"ok","timestamp":1760028207693,"user_tz":240,"elapsed":538,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"132d76d0-dd44-4fc4-acfd-deae57f175a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              StartDate              EndDate      Status       IPAddress  \\\n","7   2024-02-01 14:23:11  2024-02-01 14:38:01  IP Address   63.119.86.210   \n","8   2024-02-01 14:20:37  2024-02-01 14:42:37  IP Address  128.197.29.239   \n","9   2024-02-01 14:22:00  2024-02-01 14:43:34  IP Address   173.21.155.28   \n","10  2024-02-01 14:20:58  2024-02-01 14:48:00  IP Address   76.135.144.47   \n","11  2024-02-01 14:22:49  2024-02-01 14:50:29  IP Address   24.160.82.249   \n","\n","   Progress Duration (in seconds) Finished         RecordedDate  \\\n","7       100                   889     True  2024-02-01 14:38:02   \n","8       100                  1319     True  2024-02-01 14:42:37   \n","9       100                  1294     True  2024-02-01 14:43:35   \n","10      100                  1622     True  2024-02-01 14:48:01   \n","11      100                  1659     True  2024-02-01 14:50:30   \n","\n","           ResponseId RecipientLastName RecipientFirstName RecipientEmail  \\\n","7   R_1MANoWmYyLjw5O6               NaN                NaN            NaN   \n","8   R_6U3AK02VLDajycS               NaN                NaN            NaN   \n","9   R_1BRx0GHWVMPUJ3p               NaN                NaN            NaN   \n","10  R_6O1WyW2hbyUfpdp               NaN                NaN            NaN   \n","11  R_1fjqyGX6HmWWiKB               NaN                NaN            NaN   \n","\n","   ExternalReference LocationLatitude LocationLongitude DistributionChannel  \\\n","7                NaN          40.8806          -74.1456           anonymous   \n","8                NaN          42.3464          -71.0975           anonymous   \n","9                NaN          33.3987         -111.5013           anonymous   \n","10               NaN           48.799         -122.4499           anonymous   \n","11               NaN          27.9786          -82.7015           anonymous   \n","\n","   UserLanguage Q_BallotBoxStuffing                        Q5  \\\n","7            EN                 NaN  5ad4a9f30f5d3900016a4d8b   \n","8            EN                 NaN  610b4e7c62e3c559c069bc8e   \n","9            EN                 NaN  5cfd45060dffe10017eb8aad   \n","10           EN                 NaN  6108b3ff82db698c577e6165   \n","11           EN                 NaN  601b492280b3ce4fa542774f   \n","\n","   Time Prolific ID_First Click Time Prolific ID_Last Click  \\\n","7                             0                           0   \n","8                             0                           0   \n","9                             0                           0   \n","10                            0                           0   \n","11                            0                           0   \n","\n","   Time Prolific ID_Page Submit Time Prolific ID_Click Count  \\\n","7                         1.282                            0   \n","8                           1.5                            0   \n","9                           5.8                            0   \n","10                        5.978                            0   \n","11                        1.613                            0   \n","\n","   Time - Inf Consent_First Click Time - Inf Consent_Last Click  \\\n","7                               0                             0   \n","8                               0                             0   \n","9                            3.17                          3.17   \n","10                              0                             0   \n","11                          7.572                         7.572   \n","\n","   Time - Inf Consent_Page Submit Time - Inf Consent_Click Count  \\\n","7                           3.078                              0   \n","8                          12.119                              0   \n","9                           4.653                              1   \n","10                        423.985                              0   \n","11                          9.146                              1   \n","\n","   Time - Intro/MturkID_First Click Time - Intro/MturkID_Last Click  \\\n","7                                 0                               0   \n","8                                 0                               0   \n","9                                 0                               0   \n","10                                0                               0   \n","11                                0                               0   \n","\n","   Time - Intro/MturkID_Page Submit Time - Intro/MturkID_Click Count  \\\n","7                             6.782                                0   \n","8                              13.2                                0   \n","9                            15.219                                0   \n","10                           15.041                                0   \n","11                           45.655                                0   \n","\n","   Demos_1_1 Demos_1_2                Demos_2       Demos_3    Demos_4  \\\n","7         33         0                 Female       College  Full-time   \n","8         27         5                   Male       Masters  Full-time   \n","9         28        11                 Female       College  Full-time   \n","10        22         6  Prefer not to respond  Some College  Part-time   \n","11        29         4                   Male   High School  Part-time   \n","\n","   Demos_5 Demos_6_1 Time - Demo1_First Click Time - Demo1_Last Click  \\\n","7       No         6                     1.31                  28.285   \n","8       No         9                    1.003                  34.203   \n","9      Yes         7                    1.504                   13.67   \n","10      No         8                    1.182                    23.4   \n","11      No         6                    1.702                  42.567   \n","\n","   Time - Demo1_Page Submit Time - Demo1_Click Count  \\\n","7                     32.63                        7   \n","8                    36.366                        9   \n","9                    14.459                       17   \n","10                   24.774                       11   \n","11                   44.681                       14   \n","\n","                             Demos_7                               Demos_8  \\\n","7                 Health and Medical  In-person office or work environment   \n","8           Social and Life Sciences  In-person office or work environment   \n","9   Education, Teaching and Training           Remote or working from home   \n","10               Sales and Marketing  In-person office or work environment   \n","11         Transportation and Moving  In-person office or work environment   \n","\n","   Time - Demo2_First Click Time - Demo2_Last Click Time - Demo2_Page Submit  \\\n","7                     7.894                   9.334                    10.84   \n","8                     0.894                  24.021                   25.051   \n","9                      0.86                   3.335                    4.059   \n","10                     1.42                  15.167                   16.571   \n","11                   30.244                   32.98                   34.054   \n","\n","   Time - Demo2_Click Count Demos_9 Demos_10              Demos_11  \\\n","7                         2     NaN        5        60-119 minutes   \n","8                         3     NaN        6         30-59 minutes   \n","9                         4       5      NaN                   NaN   \n","10                        3     NaN        5         15-29 minutes   \n","11                        2     NaN        4  Less than 15 minutes   \n","\n","   Time - Demo3_First Click Time - Demo3_Last Click Time - Demo3_Page Submit  \\\n","7                         0                       0                   11.935   \n","8                     1.884                   6.138                    8.493   \n","9                     0.796                   4.516                    5.116   \n","10                    1.725                   4.904                    5.914   \n","11                    9.186                  25.552                   26.667   \n","\n","   Time - Demo3_Click Count           Demos_12 Demos_13  \\\n","7                         0           Divorced      Yes   \n","8                         2  In a relationship       No   \n","9                         4             Single       No   \n","10                        4             Single       No   \n","11                        8             Single       No   \n","\n","   Time - Demo4_First Click Time - Demo4_Last Click Time - Demo4_Page Submit  \\\n","7                     6.642                   8.945                    9.947   \n","8                      1.35                   4.143                    5.234   \n","9                     1.342                       3                    3.809   \n","10                    1.111                   2.382                    3.798   \n","11                    1.439                    3.44                    4.924   \n","\n","   Time - Demo4_Click Count Demos_14_1 Demos_15_1 Demos_16  \\\n","7                         2        NaN          1    Right   \n","8                         3        NaN        NaN    Right   \n","9                         4        NaN        NaN    Right   \n","10                        2        NaN        NaN    Right   \n","11                        3        NaN        NaN    Right   \n","\n","                                             Demos_17 Demos_18  \\\n","7   Normal (do not require contacts, glasses, etc....       No   \n","8   Normal (do not require contacts, glasses, etc....       No   \n","9   Normal (do not require contacts, glasses, etc....       No   \n","10  Normal (do not require contacts, glasses, etc....       No   \n","11  Normal (do not require contacts, glasses, etc....       No   \n","\n","   Time - Demo5_First Click Time - Demo5_Last Click Time - Demo5_Page Submit  \\\n","7                     1.287                   8.983                    9.979   \n","8                     1.343                   5.024                    6.064   \n","9                      2.38                  22.261                   23.285   \n","10                    1.147                   5.077                    6.158   \n","11                    1.337                   5.821                    6.701   \n","\n","   Time - Demo5_Click Count Readiness_1 Readiness_2_1 Readiness_3  \\\n","7                         5         Yes             8       10 pm   \n","8                         3          No             8       11 pm   \n","9                         8         Yes             5        8 pm   \n","10                        3         Yes             8        1 am   \n","11                        4         Yes             9        1 am   \n","\n","   Readiness_4_1 Readiness_5 Readiness_6 Readiness_7         Readiness_8  \\\n","7              8       10 pm          10          No  I didn't nap today   \n","8             10        9 pm           8          No  I didn't nap today   \n","9              7        8 pm           4          No  I didn't nap today   \n","10             8        1 am           3          No  I didn't nap today   \n","11             8        2 am           7          No  I didn't nap today   \n","\n","           Readiness_9 Readiness_10_1 Readiness_11_1  \\\n","7   I didn't nap today             44              0   \n","8   I didn't nap today             80              0   \n","9   I didn't nap today             42              0   \n","10  I didn't nap today             40              0   \n","11  I didn't nap today             71              6   \n","\n","                                   Readiness_12 Readiness_13_1 Readiness_14_1  \\\n","7   I have not used any nicotine products today              1              1   \n","8   I have not used any nicotine products today              4              4   \n","9   I have not used any nicotine products today              0              0   \n","10  I have not used any nicotine products today              2              1   \n","11                            30 minutes-1 hour              0              0   \n","\n","   Readiness_15 Readiness_16 Time - Readiness_First Click  \\\n","7            No        Never                        2.173   \n","8            No       Rarely                         3.68   \n","9           Yes    Sometimes                        1.953   \n","10           No        Never                          2.2   \n","11           No        Never                        2.809   \n","\n","   Time - Readiness_Last Click Time - Readiness_Page Submit  \\\n","7                       68.086                       69.581   \n","8                      130.544                      131.696   \n","9                       62.698                       63.345   \n","10                     102.401                      103.838   \n","11                     108.916                      109.901   \n","\n","   Time - Readiness_Click Count       Burnout_1       Burnout_2 Burnout_3  \\\n","7                            19           agree           agree  disagree   \n","8                            18  strongly agree           agree  disagree   \n","9                            55        disagree  strongly agree     agree   \n","10                           19           agree  strongly agree  disagree   \n","11                           33        disagree           agree  disagree   \n","\n","         Burnout_4 Burnout_5          Burnout_6       Burnout_7  \\\n","7         disagree     agree              agree  strongly agree   \n","8         disagree     agree  strongly disagree  strongly agree   \n","9   strongly agree  disagree              agree        disagree   \n","10        disagree     agree              agree           agree   \n","11           agree     agree              agree        disagree   \n","\n","         Burnout_8       Burnout_9 Burnout_10 Burnout_11      Burnout_12  \\\n","7         disagree           agree   disagree   disagree           agree   \n","8         disagree        disagree      agree      agree           agree   \n","9   strongly agree           agree   disagree      agree  strongly agree   \n","10           agree  strongly agree   disagree   disagree  strongly agree   \n","11        disagree           agree      agree   disagree        disagree   \n","\n","   Burnout_13 Burnout_14 Burnout_15      Burnout_16  \\\n","7    disagree      agree      agree           agree   \n","8    disagree      agree   disagree           agree   \n","9       agree      agree   disagree        disagree   \n","10   disagree      agree      agree  strongly agree   \n","11   disagree      agree   disagree           agree   \n","\n","   Time - Oldenburg_First Click Time - Oldenburg_Last Click  \\\n","7                         4.556                      59.569   \n","8                         8.711                      64.231   \n","9                         0.106                      75.918   \n","10                        15.08                      95.043   \n","11                         8.26                      68.408   \n","\n","   Time - Oldenburg_Page Submit Time - Oldenburg_Click Count  \\\n","7                        61.126                           17   \n","8                        65.033                           16   \n","9                        76.523                           33   \n","10                       96.469                           19   \n","11                       70.495                           19   \n","\n","                BFI_1                       BFI_2                       BFI_3  \\\n","7      Agree strongly  Neither agree nor disagree  Neither agree nor disagree   \n","8      Agree strongly  Neither agree nor disagree              Agree strongly   \n","9   Disagree a little              Agree a little              Agree a little   \n","10     Agree a little  Neither agree nor disagree              Agree strongly   \n","11  Disagree strongly  Neither agree nor disagree              Agree strongly   \n","\n","                         BFI_4                       BFI_5              BFI_6  \\\n","7               Agree a little              Agree a little  Disagree a little   \n","8            Disagree a little              Agree strongly  Disagree a little   \n","9               Agree a little           Disagree a little     Agree a little   \n","10  Neither agree nor disagree              Agree a little  Disagree a little   \n","11           Disagree a little  Neither agree nor disagree     Agree strongly   \n","\n","             BFI_7              BFI_8              BFI_9  \\\n","7   Agree a little     Agree a little     Agree a little   \n","8   Agree a little  Disagree a little     Agree a little   \n","9   Agree a little  Disagree a little  Disagree a little   \n","10  Agree strongly     Agree a little  Disagree strongly   \n","11  Agree strongly     Agree a little     Agree a little   \n","\n","                        BFI_10                      BFI_11  \\\n","7   Neither agree nor disagree              Agree strongly   \n","8               Agree strongly              Agree a little   \n","9   Neither agree nor disagree           Disagree strongly   \n","10              Agree strongly  Neither agree nor disagree   \n","11              Agree a little  Neither agree nor disagree   \n","\n","                        BFI_12          BFI_13                      BFI_14  \\\n","7   Neither agree nor disagree  Agree a little  Neither agree nor disagree   \n","8            Disagree a little  Agree strongly           Disagree a little   \n","9            Disagree a little  Agree a little              Agree a little   \n","10           Disagree strongly  Agree strongly              Agree strongly   \n","11           Disagree a little  Agree strongly              Agree a little   \n","\n","                        BFI_15             BFI_16                      BFI_17  \\\n","7   Neither agree nor disagree     Agree a little              Agree a little   \n","8               Agree strongly     Agree a little              Agree a little   \n","9            Disagree a little  Disagree a little  Neither agree nor disagree   \n","10              Agree a little     Agree a little              Agree strongly   \n","11              Agree strongly  Disagree a little              Agree strongly   \n","\n","               BFI_18                      BFI_19                      BFI_20  \\\n","7   Disagree a little  Neither agree nor disagree  Neither agree nor disagree   \n","8   Disagree a little  Neither agree nor disagree              Agree strongly   \n","9      Agree a little              Agree strongly  Neither agree nor disagree   \n","10  Disagree a little  Neither agree nor disagree              Agree a little   \n","11     Agree a little           Disagree a little              Agree strongly   \n","\n","               BFI_21          BFI_22             BFI_23  \\\n","7   Disagree a little  Agree a little  Disagree a little   \n","8   Disagree strongly  Agree a little  Disagree strongly   \n","9      Agree a little  Agree a little  Disagree a little   \n","10  Disagree a little  Agree strongly  Disagree a little   \n","11     Agree strongly  Agree a little  Disagree a little   \n","\n","                        BFI_24                      BFI_25  \\\n","7            Disagree strongly  Neither agree nor disagree   \n","8               Agree strongly              Agree strongly   \n","9            Disagree a little           Disagree a little   \n","10  Neither agree nor disagree              Agree a little   \n","11  Neither agree nor disagree           Disagree a little   \n","\n","                        BFI_26             BFI_27             BFI_28  \\\n","7               Agree a little     Agree a little  Disagree a little   \n","8               Agree a little  Disagree strongly     Agree a little   \n","9            Disagree a little  Disagree a little     Agree a little   \n","10              Agree a little  Disagree a little     Agree a little   \n","11  Neither agree nor disagree     Agree a little     Agree a little   \n","\n","               BFI_29                      BFI_30             BFI_31  \\\n","7      Agree a little           Disagree a little  Disagree a little   \n","8   Disagree a little  Neither agree nor disagree  Disagree a little   \n","9      Agree a little           Disagree a little     Agree a little   \n","10     Agree a little              Agree strongly  Disagree a little   \n","11  Disagree a little  Neither agree nor disagree     Agree strongly   \n","\n","            BFI_32          BFI_33             BFI_34             BFI_35  \\\n","7   Agree a little  Agree a little  Disagree a little     Agree a little   \n","8   Agree a little  Agree a little     Agree a little  Disagree strongly   \n","9   Agree a little  Agree a little  Disagree a little     Agree strongly   \n","10  Agree strongly  Agree strongly     Agree strongly     Agree strongly   \n","11  Agree a little  Agree a little     Agree a little     Agree strongly   \n","\n","               BFI_36                      BFI_37          BFI_38  \\\n","7      Agree a little           Disagree a little  Agree a little   \n","8      Agree strongly           Disagree a little  Agree a little   \n","9   Disagree a little              Agree a little  Agree strongly   \n","10  Disagree a little  Neither agree nor disagree  Agree a little   \n","11  Disagree strongly  Neither agree nor disagree  Agree a little   \n","\n","                        BFI_39                      BFI_40  \\\n","7               Agree a little              Agree a little   \n","8            Disagree a little              Agree strongly   \n","9               Agree a little  Neither agree nor disagree   \n","10  Neither agree nor disagree              Agree strongly   \n","11              Agree a little              Agree a little   \n","\n","                        BFI_41          BFI_42                      BFI_43  \\\n","7            Disagree a little  Agree a little              Agree a little   \n","8   Neither agree nor disagree  Agree a little  Neither agree nor disagree   \n","9   Neither agree nor disagree  Agree a little              Agree a little   \n","10           Disagree strongly  Agree strongly              Agree a little   \n","11  Neither agree nor disagree  Agree a little              Agree a little   \n","\n","                        BFI_44 Time - Big5_First Click Time - Big5_Last Click  \\\n","7   Neither agree nor disagree                   5.315                 79.735   \n","8            Disagree strongly                  10.906                 102.86   \n","9            Disagree a little                  20.816                 124.99   \n","10              Agree strongly                  10.078                 82.661   \n","11           Disagree a little                   6.745                159.811   \n","\n","   Time - Big5_Page Submit Time - Big5_Click Count  \\\n","7                   80.678                      47   \n","8                  103.573                      47   \n","9                   125.74                      92   \n","10                  83.558                      48   \n","11                  160.79                      64   \n","\n","   Time - AttnCheck 1.1_First Click Time - AttnCheck 1.1_Last Click  \\\n","7                            26.093                          26.093   \n","8                            14.673                          14.673   \n","9                            13.869                          14.442   \n","10                            8.549                           8.549   \n","11                           25.729                          25.729   \n","\n","   Time - AttnCheck 1.1_Page Submit Time - AttnCheck 1.1_Click Count  \\\n","7                            27.219                                1   \n","8                            20.077                                1   \n","9                            15.121                                2   \n","10                           13.689                                1   \n","11                           33.196                                1   \n","\n","                  Attn_Check_1_1 Time - AttnCheck 1.2_First Click  \\\n","7   During most of my adult life                              NaN   \n","8   During most of my adult life                              NaN   \n","9   During most of my adult life                              NaN   \n","10  During most of my adult life                              NaN   \n","11  During most of my adult life                              NaN   \n","\n","   Time - AttnCheck 1.2_Last Click Time - AttnCheck 1.2_Page Submit  \\\n","7                              NaN                              NaN   \n","8                              NaN                              NaN   \n","9                              NaN                              NaN   \n","10                             NaN                              NaN   \n","11                             NaN                              NaN   \n","\n","   Time - AttnCheck 1.2_Click Count Attn_Check_1_2  \\\n","7                               NaN            NaN   \n","8                               NaN            NaN   \n","9                               NaN            NaN   \n","10                              NaN            NaN   \n","11                              NaN            NaN   \n","\n","   Time - AttnCheck 1.3_First Click Time - AttnCheck 1.3_Last Click  \\\n","7                               NaN                             NaN   \n","8                               NaN                             NaN   \n","9                               NaN                             NaN   \n","10                              NaN                             NaN   \n","11                              NaN                             NaN   \n","\n","   Time - AttnCheck 1.3_Page Submit Time - AttnCheck 1.3_Click Count  \\\n","7                               NaN                              NaN   \n","8                               NaN                              NaN   \n","9                               NaN                              NaN   \n","10                              NaN                              NaN   \n","11                              NaN                              NaN   \n","\n","   Attn_Check_1_3 Time - AttnCheck 1.4_First Click  \\\n","7             NaN                              NaN   \n","8             NaN                              NaN   \n","9             NaN                              NaN   \n","10            NaN                              NaN   \n","11            NaN                              NaN   \n","\n","   Time - AttnCheck 1.4_Last Click Time - AttnCheck 1.4_Page Submit  \\\n","7                              NaN                              NaN   \n","8                              NaN                              NaN   \n","9                              NaN                              NaN   \n","10                             NaN                              NaN   \n","11                             NaN                              NaN   \n","\n","   Time - AttnCheck 1.4_Click Count Attn_Check_1_4       ADHD_1       ADHD_2  \\\n","7                               NaN            NaN  Quite a lot  Quite a lot   \n","8                               NaN            NaN     Somewhat   Moderately   \n","9                               NaN            NaN   Moderately    Very Much   \n","10                              NaN            NaN  Quite a lot   Moderately   \n","11                              NaN            NaN   Moderately     Somewhat   \n","\n","         ADHD_3      ADHD_4         ADHD_5         ADHD_6         ADHD_7  \\\n","7   Quite a lot  Moderately    Quite a lot    Quite a lot     Moderately   \n","8    Not at all  Not at all     Not at all  Just a little  Just a little   \n","9      Somewhat  Moderately    Quite a lot  Just a little       Somewhat   \n","10    Very Much    Somewhat       Somewhat     Moderately       Somewhat   \n","11     Somewhat    Somewhat  Just a little       Somewhat  Just a little   \n","\n","           ADHD_8         ADHD_9        ADHD_10        ADHD_11      ADHD_12  \\\n","7      Moderately      Very Much      Very Much    Quite a lot  Quite a lot   \n","8      Not at all     Not at all     Not at all     Not at all   Not at all   \n","9      Not at all       Somewhat       Somewhat    Quite a lot  Quite a lot   \n","10       Somewhat      Very Much     Moderately       Somewhat     Somewhat   \n","11  Just a little  Just a little  Just a little  Just a little   Not at all   \n","\n","        ADHD_13      ADHD_14      ADHD_15     ADHD_16      ADHD_17  \\\n","7   Quite a lot    Very Much  Quite a lot   Very Much  Quite a lot   \n","8    Moderately     Somewhat     Somewhat    Somewhat   Not at all   \n","9      Somewhat  Quite a lot   Moderately    Somewhat   Moderately   \n","10     Somewhat   Moderately    Very Much  Moderately    Very Much   \n","11   Not at all     Somewhat   Not at all    Somewhat   Moderately   \n","\n","       ADHD_18        ADHD_19        ADHD_20        ADHD_21        ADHD_22  \\\n","7    Very Much      Very Much      Very Much    Quite a lot     Moderately   \n","8   Moderately  Just a little     Not at all  Just a little     Not at all   \n","9     Somewhat  Just a little     Moderately     Moderately  Just a little   \n","10   Very Much    Quite a lot      Very Much      Very Much      Very Much   \n","11  Not at all     Not at all  Just a little  Just a little  Just a little   \n","\n","          ADHD_23        ADHD_24 Time - ADHD_First Click  \\\n","7     Quite a lot      Very Much                   2.867   \n","8   Just a little     Not at all                  10.749   \n","9      Moderately       Somewhat                  11.959   \n","10    Quite a lot     Moderately                   5.823   \n","11     Not at all  Just a little                   7.756   \n","\n","   Time - ADHD_Last Click Time - ADHD_Page Submit Time - ADHD_Click Count  \\\n","7                 203.441                 205.626                      26   \n","8                  93.825                  94.701                      26   \n","9                 229.894                  232.17                      55   \n","10                 68.158                  68.786                      27   \n","11                192.843                 193.662                      38   \n","\n","         STAI_1_1       STAI_1_2      STAI_1_3       STAI_1_4       STAI_1_5  \\\n","7    Very Much So   Very Much So    Not At All     Not At All  Moderately So   \n","8    Very Much So   Very Much So    Not At All       Somewhat  Moderately So   \n","9        Somewhat     Not At All  Very Much So  Moderately So     Not At All   \n","10       Somewhat       Somewhat  Very Much So  Moderately So       Somewhat   \n","11  Moderately So  Moderately So    Not At All     Not At All  Moderately So   \n","\n","      STAI_1_6       STAI_1_7       STAI_1_8      STAI_1_9      STAI_1_10  \\\n","7   Not At All     Not At All   Very Much So    Not At All  Moderately So   \n","8   Not At All     Not At All  Moderately So    Not At All  Moderately So   \n","9     Somewhat  Moderately So       Somewhat  Very Much So       Somewhat   \n","10    Somewhat  Moderately So     Not At All      Somewhat       Somewhat   \n","11  Not At All     Not At All       Somewhat    Not At All  Moderately So   \n","\n","        STAI_1_11     STAI_1_12      STAI_1_13      STAI_1_14      STAI_1_15  \\\n","7   Moderately So    Not At All     Not At All     Not At All  Moderately So   \n","8    Very Much So    Not At All     Not At All       Somewhat   Very Much So   \n","9        Somewhat  Very Much So  Moderately So  Moderately So     Not At All   \n","10   Very Much So      Somewhat   Very Much So       Somewhat       Somewhat   \n","11       Somewhat    Not At All     Not At All     Not At All  Moderately So   \n","\n","        STAI_1_16      STAI_1_17      STAI_1_18      STAI_1_19      STAI_1_20  \\\n","7   Moderately So     Not At All     Not At All  Moderately So  Moderately So   \n","8   Moderately So       Somewhat     Not At All       Somewhat  Moderately So   \n","9        Somewhat   Very Much So  Moderately So     Not At All       Somewhat   \n","10       Somewhat  Moderately So  Moderately So     Not At All       Somewhat   \n","11  Moderately So     Not At All     Not At All  Moderately So       Somewhat   \n","\n","         STAI_2_1      STAI_2_2      STAI_2_3       STAI_2_4       STAI_2_5  \\\n","7           Often  Almost Never         Often  Almost Always      Sometimes   \n","8   Almost Always  Almost Never         Often      Sometimes   Almost Never   \n","9    Almost Never         Often     Sometimes  Almost Always  Almost Always   \n","10          Often     Sometimes         Often      Sometimes   Almost Never   \n","11      Sometimes     Sometimes  Almost Never      Sometimes      Sometimes   \n","\n","     STAI_2_6      STAI_2_7      STAI_2_8      STAI_2_9     STAI_2_10  \\\n","7       Often  Almost Never  Almost Never  Almost Never     Sometimes   \n","8   Sometimes         Often  Almost Never  Almost Never         Often   \n","9   Sometimes     Sometimes         Often         Often  Almost Never   \n","10  Sometimes     Sometimes  Almost Never         Often         Often   \n","11  Sometimes         Often     Sometimes         Often     Sometimes   \n","\n","       STAI_2_11     STAI_2_12      STAI_2_13     STAI_2_14     STAI_2_15  \\\n","7   Almost Never         Often      Sometimes  Almost Never     Sometimes   \n","8   Almost Never  Almost Never  Almost Always         Often  Almost Never   \n","9   Almost Never         Often      Sometimes     Sometimes         Often   \n","10         Often  Almost Never      Sometimes         Often  Almost Never   \n","11     Sometimes     Sometimes      Sometimes         Often     Sometimes   \n","\n","        STAI_2_16      STAI_2_17     STAI_2_18     STAI_2_19     STAI_2_20  \\\n","7       Sometimes      Sometimes         Often  Almost Never         Often   \n","8   Almost Always   Almost Never  Almost Never         Often  Almost Never   \n","9       Sometimes  Almost Always         Often     Sometimes         Often   \n","10      Sometimes          Often     Sometimes     Sometimes  Almost Never   \n","11          Often      Sometimes         Often     Sometimes     Sometimes   \n","\n","   Time - STAI_First Click Time - STAI_Last Click Time - STAI_Page Submit  \\\n","7                    4.935                  74.92                  76.276   \n","8                   12.326                107.099                 108.663   \n","9                   21.976                 144.96                 145.586   \n","10                  31.185                179.468                 181.967   \n","11                   4.577                116.245                 117.446   \n","\n","   Time - STAI_Click Count Maslach_1 Maslach_2 Maslach_3 Maslach_4 Maslach_5  \\\n","7                       45       NaN       NaN       NaN       NaN       NaN   \n","8                       41       NaN       NaN       NaN       NaN       NaN   \n","9                       71       NaN       NaN       NaN       NaN       NaN   \n","10                      44       NaN       NaN       NaN       NaN       NaN   \n","11                      47       NaN       NaN       NaN       NaN       NaN   \n","\n","   Maslach_6 Maslach_7 Maslach_8 Maslach_9 Maslach_10 Maslach_11 Maslach_12  \\\n","7        NaN       NaN       NaN       NaN        NaN        NaN        NaN   \n","8        NaN       NaN       NaN       NaN        NaN        NaN        NaN   \n","9        NaN       NaN       NaN       NaN        NaN        NaN        NaN   \n","10       NaN       NaN       NaN       NaN        NaN        NaN        NaN   \n","11       NaN       NaN       NaN       NaN        NaN        NaN        NaN   \n","\n","   Maslach_13 Maslach_14 Maslach_15 Maslach_16 Timing - Maslach _First Click  \\\n","7         NaN        NaN        NaN        NaN                           NaN   \n","8         NaN        NaN        NaN        NaN                           NaN   \n","9         NaN        NaN        NaN        NaN                           NaN   \n","10        NaN        NaN        NaN        NaN                           NaN   \n","11        NaN        NaN        NaN        NaN                           NaN   \n","\n","   Timing - Maslach _Last Click Timing - Maslach _Page Submit  \\\n","7                           NaN                           NaN   \n","8                           NaN                           NaN   \n","9                           NaN                           NaN   \n","10                          NaN                           NaN   \n","11                          NaN                           NaN   \n","\n","   Timing - Maslach _Click Count Time - AttnCheck 2.1_First Click  \\\n","7                            NaN                           15.202   \n","8                            NaN                           18.204   \n","9                            NaN                            6.041   \n","10                           NaN                            9.391   \n","11                           NaN                           17.676   \n","\n","   Time - AttnCheck 2.1_Last Click Time - AttnCheck 2.1_Page Submit  \\\n","7                           15.202                           16.335   \n","8                           18.204                           20.046   \n","9                            6.564                            7.064   \n","10                           9.391                           11.706   \n","11                          17.676                           22.292   \n","\n","   Time - AttnCheck 2.1_Click Count     Attn_Check_2_1  \\\n","7                                 1  In the last month   \n","8                                 1  In the last month   \n","9                                 2  In the last month   \n","10                                1  In the last month   \n","11                                1  In the last month   \n","\n","   Time - AttnCheck 2.2_First Click Time - AttnCheck 2.2_Last Click  \\\n","7                               NaN                             NaN   \n","8                               NaN                             NaN   \n","9                               NaN                             NaN   \n","10                              NaN                             NaN   \n","11                              NaN                             NaN   \n","\n","   Time - AttnCheck 2.2_Page Submit Time - AttnCheck 2.2_Click Count  \\\n","7                               NaN                              NaN   \n","8                               NaN                              NaN   \n","9                               NaN                              NaN   \n","10                              NaN                              NaN   \n","11                              NaN                              NaN   \n","\n","   Attn_Check_2_2 Time - AttnCheck 2.3_First Click  \\\n","7             NaN                              NaN   \n","8             NaN                              NaN   \n","9             NaN                              NaN   \n","10            NaN                              NaN   \n","11            NaN                              NaN   \n","\n","   Time - AttnCheck 2.3_Last Click Time - AttnCheck 2.3_Page Submit  \\\n","7                              NaN                              NaN   \n","8                              NaN                              NaN   \n","9                              NaN                              NaN   \n","10                             NaN                              NaN   \n","11                             NaN                              NaN   \n","\n","   Time - AttnCheck 2.3_Click Count Attn_Check_2_3  \\\n","7                               NaN            NaN   \n","8                               NaN            NaN   \n","9                               NaN            NaN   \n","10                              NaN            NaN   \n","11                              NaN            NaN   \n","\n","   Time - AttnCheck 2.4_First Click Time - AttnCheck 2.4_Last Click  \\\n","7                               NaN                             NaN   \n","8                               NaN                             NaN   \n","9                               NaN                             NaN   \n","10                              NaN                             NaN   \n","11                              NaN                             NaN   \n","\n","   Time - AttnCheck 2.4_Page Submit Time - AttnCheck 2.4_Click Count  \\\n","7                               NaN                              NaN   \n","8                               NaN                              NaN   \n","9                               NaN                              NaN   \n","10                              NaN                              NaN   \n","11                              NaN                              NaN   \n","\n","   Attn_Check_2_4                         OCD_1_1  \\\n","7             NaN                     None at all   \n","8             NaN       Less than 1 hour each day   \n","9             NaN       Less than 1 hour each day   \n","10            NaN  Between 3 and 8 hours each day   \n","11            NaN                     None at all   \n","\n","                            OCD_1_2                         OCD_1_3  \\\n","7                       None at all  Not at all distressed/anxious    \n","8                       None at all      Mildly distressed/anxious    \n","9   A moderate amount of avoidance       Mildly distressed/anxious    \n","10  A moderate amount of avoidance   Moderately distressed/anxious    \n","11                      None at all  Not at all distressed/anxious    \n","\n","                                              OCD_1_4                OCD_1_5  \\\n","7                              No disruption at all.   Not at all difficult    \n","8                              No disruption at all.   Not at all difficult    \n","9   A little disruption, but I mostly function well.     A little difficult    \n","10  Many things are disrupted, but I can still man...  Moderately difficult    \n","11                             No disruption at all.   Not at all difficult    \n","\n","   Time - OCD 1_First Click Time - OCD 1_Last Click Time - OCD 1_Page Submit  \\\n","7                    14.949                  34.539                   41.026   \n","8                    71.533                 100.116                  100.955   \n","9                     2.989                  31.411                   32.101   \n","10                   15.571                  35.807                   38.233   \n","11                   20.843                  47.968                   50.955   \n","\n","   Time - OCD 1_Click Count                     OCD_2_1  \\\n","7                         5                None at all    \n","8                         6  Less than 1 hour each day    \n","9                        19  Less than 1 hour each day    \n","10                        5  Less than 1 hour each day    \n","11                       11  Less than 1 hour each day    \n","\n","                           OCD_2_2                        OCD_2_3  \\\n","7                      None at all  Not at all distressed/anxious   \n","8                      None at all  Not at all distressed/anxious   \n","9   A moderate amount of avoidance  Moderately distressed/anxious   \n","10       A great deal of avoidance  Moderately distressed/anxious   \n","11                     None at all  Not at all distressed/anxious   \n","\n","                                              OCD_2_4               OCD_2_5  \\\n","7                               No disruption at all.  Not at all difficult   \n","8                               No disruption at all.  Not at all difficult   \n","9   Many things are disrupted, but I can still man...  Moderately difficult   \n","10  Many things are disrupted, but I can still man...  Moderately difficult   \n","11   A little disruption, but I mostly function well.    A little difficult   \n","\n","   Time - OCD 2_First Click Time - OCD 2_Last Click Time - OCD 2_Page Submit  \\\n","7                     6.182                  12.555                   14.255   \n","8                     14.86                   25.09                   27.836   \n","9                     3.035                  41.591                   41.956   \n","10                   22.398                  37.475                   39.976   \n","11                   18.945                  68.514                   69.642   \n","\n","   Time - OCD 2_Click Count                          OCD_3_1  \\\n","7                         5        Less than 1 hour each day   \n","8                         5                      None at all   \n","9                        18        Less than 1 hour each day   \n","10                        6  Between 1 and 3 hours each day    \n","11                       13        Less than 1 hour each day   \n","\n","                       OCD_3_2                         OCD_3_3  \\\n","7          A little avoidance        Mildly distressed/anxious   \n","8                  None at all  Not at all distressed/anxious    \n","9          A little avoidance        Mildly distressed/anxious   \n","10  A great deal of avoidance   Moderately distressed/anxious    \n","11         A little avoidance        Mildly distressed/anxious   \n","\n","                                              OCD_3_4                OCD_3_5  \\\n","7   Many things are disrupted, but I can still man...    A little difficult    \n","8                              No disruption at all.   Not at all difficult    \n","9   A little disruption, but I mostly function well.     A little difficult    \n","10  A little disruption, but I mostly function well.     A little difficult    \n","11  A little disruption, but I mostly function well.     A little difficult    \n","\n","   Time - OCD 3_First Click Time - OCD 3_Last Click Time - OCD 3_Page Submit  \\\n","7                     8.067                  18.833                   20.967   \n","8                    10.196                  18.163                   19.552   \n","9                     8.555                  19.743                   20.034   \n","10                    6.806                    22.3                     24.5   \n","11                   27.905                  52.198                   53.527   \n","\n","   Time - OCD 3_Click Count                     OCD_4_1              OCD_4_2  \\\n","7                         5  Less than 1 hour each day   A little avoidance    \n","8                         5                None at all          None at all    \n","9                        16  Less than 1 hour each day   A little avoidance    \n","10                        6  Less than 1 hour each day   A little avoidance    \n","11                       10                None at all          None at all    \n","\n","                           OCD_4_3  \\\n","7       Mildly distressed/anxious    \n","8   Not at all distressed/anxious    \n","9   Moderately distressed/anxious    \n","10      Mildly distressed/anxious    \n","11  Not at all distressed/anxious    \n","\n","                                              OCD_4_4                OCD_4_5  \\\n","7   A little disruption, but I mostly function well.     A little difficult    \n","8                              No disruption at all.   Not at all difficult    \n","9   Many things are disrupted, but I can still man...    A little difficult    \n","10  A little disruption, but I mostly function well.     A little difficult    \n","11                             No disruption at all.   Not at all difficult    \n","\n","   Time - OCD 4_First Click Time - OCD 4_Last Click Time - OCD 4_Page Submit  \\\n","7                    10.687                  18.605                   19.742   \n","8                     8.036                  15.482                   16.849   \n","9                    18.881                  26.971                   27.624   \n","10                    16.12                  27.804                   29.345   \n","11                   13.642                  35.709                     36.7   \n","\n","   Time - OCD 4_Click Count                 BIS_1          BIS_2  \\\n","7                         6                 Often   Occasionally   \n","8                         5  Almost always/Always   Occasionally   \n","9                        14                 Often  Rarely/Never    \n","10                        5                 Often          Often   \n","11                       12          Occasionally   Occasionally   \n","\n","            BIS_3          BIS_4          BIS_5         BIS_6          BIS_7  \\\n","7           Often   Occasionally  Rarely/Never   Occasionally   Occasionally   \n","8           Often          Often  Rarely/Never          Often   Occasionally   \n","9   Rarely/Never   Rarely/Never    Occasionally         Often          Often   \n","10          Often   Occasionally  Rarely/Never          Often          Often   \n","11   Occasionally   Occasionally   Occasionally         Often  Rarely/Never    \n","\n","           BIS_8         BIS_9                BIS_10                BIS_11  \\\n","7          Often         Often                 Often  Almost always/Always   \n","8          Often         Often                 Often          Occasionally   \n","9          Often  Occasionally          Occasionally                 Often   \n","10  Occasionally  Occasionally  Almost always/Always                 Often   \n","11         Often  Occasionally          Occasionally         Rarely/Never    \n","\n","          BIS_12        BIS_13        BIS_14                BIS_15  \\\n","7          Often         Often  Occasionally                 Often   \n","8          Often         Often  Occasionally  Almost always/Always   \n","9          Often         Often  Occasionally         Rarely/Never    \n","10  Occasionally  Occasionally         Often                 Often   \n","11  Occasionally  Occasionally  Occasionally          Occasionally   \n","\n","           BIS_16        BIS_17         BIS_18         BIS_19        BIS_20  \\\n","7           Often  Occasionally          Often          Often  Occasionally   \n","8   Rarely/Never   Occasionally   Occasionally   Occasionally         Often   \n","9   Rarely/Never   Occasionally  Rarely/Never   Rarely/Never          Often   \n","10  Rarely/Never          Often   Occasionally          Often  Occasionally   \n","11  Rarely/Never   Occasionally          Often   Occasionally  Occasionally   \n","\n","           BIS_21        BIS_22         BIS_23                BIS_24  \\\n","7           Often         Often          Often                 Often   \n","8   Rarely/Never   Occasionally   Occasionally          Occasionally   \n","9   Rarely/Never   Occasionally   Occasionally          Occasionally   \n","10   Occasionally  Occasionally  Rarely/Never   Almost always/Always   \n","11  Rarely/Never          Often  Rarely/Never          Rarely/Never    \n","\n","           BIS_25                BIS_26         BIS_27         BIS_28  \\\n","7    Occasionally          Occasionally          Often   Occasionally   \n","8    Occasionally          Occasionally   Occasionally   Occasionally   \n","9    Occasionally                 Often  Rarely/Never           Often   \n","10   Occasionally  Almost always/Always          Often          Often   \n","11  Rarely/Never           Occasionally   Occasionally  Rarely/Never    \n","\n","          BIS_29         BIS_30 Time - BIS_First Click Time - BIS_Last Click  \\\n","7          Often          Often                  2.936                39.138   \n","8          Often          Often                  3.397                76.541   \n","9          Often          Often                  2.519                75.162   \n","10  Occasionally  Rarely/Never                   2.734                56.287   \n","11  Occasionally          Often                  4.119               120.034   \n","\n","   Time - BIS_Page Submit Time - BIS_Click Count Q618_First Click  \\\n","7                  40.491                     33            8.987   \n","8                  77.301                     32           13.288   \n","9                  75.538                     59            4.046   \n","10                  57.11                     34             1.57   \n","11                121.091                     42            14.32   \n","\n","   Q618_Last Click Q618_Page Submit Q618_Click Count  \\\n","7            8.987           11.441                1   \n","8           13.288            14.97                1   \n","9            4.464            4.892                2   \n","10          87.874           89.073                2   \n","11           14.32           16.536                1   \n","\n","                  Attn_Check_3_1 Q620_First Click Q620_Last Click  \\\n","7   During most of my adult life              NaN             NaN   \n","8   During most of my adult life              NaN             NaN   \n","9   During most of my adult life              NaN             NaN   \n","10  During most of my adult life              NaN             NaN   \n","11  During most of my adult life              NaN             NaN   \n","\n","   Q620_Page Submit Q620_Click Count Attn_Check_3_2 Q622_First Click  \\\n","7               NaN              NaN            NaN              NaN   \n","8               NaN              NaN            NaN              NaN   \n","9               NaN              NaN            NaN              NaN   \n","10              NaN              NaN            NaN              NaN   \n","11              NaN              NaN            NaN              NaN   \n","\n","   Q622_Last Click Q622_Page Submit Q622_Click Count Attn_Check_3_3  \\\n","7              NaN              NaN              NaN            NaN   \n","8              NaN              NaN              NaN            NaN   \n","9              NaN              NaN              NaN            NaN   \n","10             NaN              NaN              NaN            NaN   \n","11             NaN              NaN              NaN            NaN   \n","\n","   Q624_First Click Q624_Last Click Q624_Page Submit Q624_Click Count  \\\n","7               NaN             NaN              NaN              NaN   \n","8               NaN             NaN              NaN              NaN   \n","9               NaN             NaN              NaN              NaN   \n","10              NaN             NaN              NaN              NaN   \n","11              NaN             NaN              NaN              NaN   \n","\n","   Attn_Check_3_4                ASQ_1                ASQ_2  \\\n","7             NaN    Slightly Disagree  Definitely Disagree   \n","8             NaN       Slightly Agree  Definitely Disagree   \n","9             NaN    Slightly Disagree     Definitely Agree   \n","10            NaN  Definitely Disagree     Definitely Agree   \n","11            NaN    Slightly Disagree       Slightly Agree   \n","\n","                  ASQ_3              ASQ_4                ASQ_5  \\\n","7   Definitely Disagree  Slightly Disagree  Definitely Disagree   \n","8        Slightly Agree     Slightly Agree    Slightly Disagree   \n","9   Definitely Disagree     Slightly Agree     Definitely Agree   \n","10     Definitely Agree   Definitely Agree     Definitely Agree   \n","11     Definitely Agree     Slightly Agree       Slightly Agree   \n","\n","                  ASQ_6                ASQ_7              ASQ_8  \\\n","7     Slightly Disagree  Definitely Disagree  Slightly Disagree   \n","8   Definitely Disagree    Slightly Disagree     Slightly Agree   \n","9      Definitely Agree    Slightly Disagree  Slightly Disagree   \n","10     Definitely Agree     Definitely Agree     Slightly Agree   \n","11     Definitely Agree  Definitely Disagree  Slightly Disagree   \n","\n","                  ASQ_9               ASQ_10               ASQ_11  \\\n","7   Definitely Disagree    Slightly Disagree       Slightly Agree   \n","8   Definitely Disagree       Slightly Agree       Slightly Agree   \n","9      Definitely Agree    Slightly Disagree  Definitely Disagree   \n","10       Slightly Agree     Definitely Agree    Slightly Disagree   \n","11    Slightly Disagree  Definitely Disagree  Definitely Disagree   \n","\n","               ASQ_12               ASQ_13               ASQ_14  \\\n","7   Slightly Disagree  Definitely Disagree    Slightly Disagree   \n","8   Slightly Disagree    Slightly Disagree       Slightly Agree   \n","9      Slightly Agree       Slightly Agree  Definitely Disagree   \n","10   Definitely Agree     Definitely Agree     Definitely Agree   \n","11  Slightly Disagree     Definitely Agree    Slightly Disagree   \n","\n","                 ASQ_15               ASQ_16               ASQ_17  \\\n","7     Slightly Disagree  Definitely Disagree    Slightly Disagree   \n","8        Slightly Agree    Slightly Disagree       Slightly Agree   \n","9   Definitely Disagree       Slightly Agree    Slightly Disagree   \n","10    Slightly Disagree     Definitely Agree  Definitely Disagree   \n","11    Slightly Disagree    Slightly Disagree  Definitely Disagree   \n","\n","               ASQ_18               ASQ_19             ASQ_20  \\\n","7   Slightly Disagree    Slightly Disagree     Slightly Agree   \n","8   Slightly Disagree       Slightly Agree  Slightly Disagree   \n","9      Slightly Agree     Definitely Agree  Slightly Disagree   \n","10   Definitely Agree    Slightly Disagree     Slightly Agree   \n","11  Slightly Disagree  Definitely Disagree  Slightly Disagree   \n","\n","               ASQ_21               ASQ_22               ASQ_23  \\\n","7   Slightly Disagree  Definitely Disagree  Definitely Disagree   \n","8   Slightly Disagree    Slightly Disagree       Slightly Agree   \n","9   Slightly Disagree       Slightly Agree     Definitely Agree   \n","10  Slightly Disagree    Slightly Disagree     Definitely Agree   \n","11  Slightly Disagree     Definitely Agree       Slightly Agree   \n","\n","                 ASQ_24               ASQ_25             ASQ_26  \\\n","7     Slightly Disagree    Slightly Disagree  Slightly Disagree   \n","8   Definitely Disagree    Slightly Disagree  Slightly Disagree   \n","9        Slightly Agree    Slightly Disagree     Slightly Agree   \n","10    Slightly Disagree  Definitely Disagree   Definitely Agree   \n","11    Slightly Disagree  Definitely Disagree   Definitely Agree   \n","\n","                 ASQ_27               ASQ_28             ASQ_29  \\\n","7   Definitely Disagree    Slightly Disagree  Slightly Disagree   \n","8        Slightly Agree       Slightly Agree  Slightly Disagree   \n","9     Slightly Disagree  Definitely Disagree  Slightly Disagree   \n","10  Definitely Disagree    Slightly Disagree     Slightly Agree   \n","11  Definitely Disagree       Slightly Agree   Definitely Agree   \n","\n","                 ASQ_30               ASQ_31             ASQ_32  \\\n","7   Definitely Disagree  Definitely Disagree  Slightly Disagree   \n","8     Slightly Disagree       Slightly Agree     Slightly Agree   \n","9     Slightly Disagree       Slightly Agree  Slightly Disagree   \n","10  Definitely Disagree  Definitely Disagree  Slightly Disagree   \n","11       Slightly Agree    Slightly Disagree  Slightly Disagree   \n","\n","               ASQ_33             ASQ_34               ASQ_35  \\\n","7   Slightly Disagree  Slightly Disagree  Definitely Disagree   \n","8   Slightly Disagree     Slightly Agree    Slightly Disagree   \n","9   Slightly Disagree  Slightly Disagree    Slightly Disagree   \n","10   Definitely Agree  Slightly Disagree       Slightly Agree   \n","11  Slightly Disagree  Slightly Disagree       Slightly Agree   \n","\n","                 ASQ_36               ASQ_37               ASQ_38  \\\n","7   Definitely Disagree    Slightly Disagree       Slightly Agree   \n","8        Slightly Agree    Slightly Disagree       Slightly Agree   \n","9     Slightly Disagree       Slightly Agree  Definitely Disagree   \n","10  Definitely Disagree  Definitely Disagree    Slightly Disagree   \n","11    Slightly Disagree    Slightly Disagree  Definitely Disagree   \n","\n","               ASQ_39               ASQ_40               ASQ_41  \\\n","7   Slightly Disagree  Definitely Disagree    Slightly Disagree   \n","8   Slightly Disagree       Slightly Agree       Slightly Agree   \n","9    Definitely Agree    Slightly Disagree     Definitely Agree   \n","10     Slightly Agree     Definitely Agree     Definitely Agree   \n","11  Slightly Disagree     Definitely Agree  Definitely Disagree   \n","\n","               ASQ_42               ASQ_43               ASQ_44  \\\n","7   Slightly Disagree  Definitely Disagree  Definitely Disagree   \n","8      Slightly Agree       Slightly Agree     Definitely Agree   \n","9      Slightly Agree       Slightly Agree    Slightly Disagree   \n","10   Definitely Agree     Definitely Agree    Slightly Disagree   \n","11  Slightly Disagree    Slightly Disagree  Definitely Disagree   \n","\n","                 ASQ_45               ASQ_46               ASQ_47  \\\n","7   Definitely Disagree    Slightly Disagree    Slightly Disagree   \n","8     Slightly Disagree  Definitely Disagree       Slightly Agree   \n","9        Slightly Agree       Slightly Agree  Definitely Disagree   \n","10       Slightly Agree     Definitely Agree    Slightly Disagree   \n","11    Slightly Disagree       Slightly Agree  Definitely Disagree   \n","\n","                 ASQ_48               ASQ_49               ASQ_50  \\\n","7   Definitely Disagree  Definitely Disagree    Slightly Disagree   \n","8        Slightly Agree       Slightly Agree       Slightly Agree   \n","9     Slightly Disagree    Slightly Disagree  Definitely Disagree   \n","10    Slightly Disagree       Slightly Agree     Definitely Agree   \n","11       Slightly Agree       Slightly Agree    Slightly Disagree   \n","\n","   Time - ASQ_First Click Time - ASQ_Last Click Time - ASQ_Page Submit  \\\n","7                   2.598                 64.64                 66.888   \n","8                   5.646               178.845                180.278   \n","9                  14.367               160.449                160.965   \n","10                  2.567               105.461                106.835   \n","11                  5.713               261.527                262.484   \n","\n","   Time - ASQ_Click Count Wordle_2_First Click Wordle_2_Last Click  \\\n","7                      54                  NaN                 NaN   \n","8                      54                  NaN                 NaN   \n","9                     101                  NaN                 NaN   \n","10                     53                  NaN                 NaN   \n","11                     69                  NaN                 NaN   \n","\n","   Wordle_2_Page Submit Wordle_2_Click Count Wordle_3 Wordle_5 Wordle_6  \\\n","7                   NaN                  NaN      NaN      NaN      NaN   \n","8                   NaN                  NaN      NaN      NaN      NaN   \n","9                   NaN                  NaN      NaN      NaN      NaN   \n","10                  NaN                  NaN      NaN      NaN      NaN   \n","11                  NaN                  NaN      NaN      NaN      NaN   \n","\n","   Wordle_7 Wordle_9 Wordle_10 Wordle_11 Wordle_12 Wordle_13 Wordle_14  \\\n","7       NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n","8       NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n","9       NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n","10      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n","11      NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n","\n","   Wordle_15_First Click Wordle_15_Last Click Wordle_15_Page Submit  \\\n","7                    NaN                  NaN                   NaN   \n","8                    NaN                  NaN                   NaN   \n","9                    NaN                  NaN                   NaN   \n","10                   NaN                  NaN                   NaN   \n","11                   NaN                  NaN                   NaN   \n","\n","   Wordle_15_Click Count Second_Readiness_1_1 Second_Readiness_2_1  \\\n","7                    NaN                  NaN                  NaN   \n","8                    NaN                  NaN                  NaN   \n","9                    NaN                  NaN                  NaN   \n","10                   NaN                  NaN                  NaN   \n","11                   NaN                  NaN                  NaN   \n","\n","   Second_Readiness_3 Second_Readiness_4_1 Second_Readiness_5  \\\n","7                 NaN                  NaN                NaN   \n","8                 NaN                  NaN                NaN   \n","9                 NaN                  NaN                NaN   \n","10                NaN                  NaN                NaN   \n","11                NaN                  NaN                NaN   \n","\n","   time_second_readi_First Click time_second_readi_Last Click  \\\n","7                            NaN                          NaN   \n","8                            NaN                          NaN   \n","9                            NaN                          NaN   \n","10                           NaN                          NaN   \n","11                           NaN                          NaN   \n","\n","   time_second_readi_Page Submit time_second_readi_Click Count  \\\n","7                            NaN                           NaN   \n","8                            NaN                           NaN   \n","9                            NaN                           NaN   \n","10                           NaN                           NaN   \n","11                           NaN                           NaN   \n","\n","        Grit Scale_1       Grit Scale_6       Grit Scale_2       Grit Scale_3  \\\n","7   Somewhat like me   Somewhat like me   Not much like me   Not much like me   \n","8     Mostly like me  Very much like me   Somewhat like me  Very much like me   \n","9     Mostly like me   Not much like me     Mostly like me     Mostly like me   \n","10  Somewhat like me     Mostly like me  Very much like me  Very much like me   \n","11  Somewhat like me   Somewhat like me   Somewhat like me     Mostly like me   \n","\n","         Grit Scale_4      Grit Scale_7       Grit Scale_5       Grit Scale_8  \\\n","7    Somewhat like me  Somewhat like me   Not much like me   Not much like me   \n","8    Not much like me    Mostly like me   Somewhat like me  Very much like me   \n","9      Mostly like me  Not much like me     Mostly like me     Mostly like me   \n","10  Very much like me  Somewhat like me  Very much like me   Somewhat like me   \n","11   Somewhat like me  Not much like me   Somewhat like me   Somewhat like me   \n","\n","         Grit Scale_9     Grit Scale_10 Time - Grit_First Click  \\\n","7    Somewhat like me  Somewhat like me                   8.306   \n","8    Somewhat like me    Mostly like me                  10.351   \n","9      Mostly like me    Mostly like me                   1.193   \n","10  Very much like me  Somewhat like me                  48.463   \n","11     Mostly like me  Somewhat like me                   8.342   \n","\n","   Time - Grit_Last Click Time - Grit_Page Submit Time - Grit_Click Count  \\\n","7                  20.016                  21.455                      10   \n","8                  42.154                  43.164                      10   \n","9                  39.378                  40.656                      23   \n","10                 69.019                  70.126                      13   \n","11                 52.762                   53.77                      11   \n","\n","   Time - Ts and Ls_First Click Time - Ts and Ls_Last Click  \\\n","7                           NaN                         NaN   \n","8                           NaN                         NaN   \n","9                           NaN                         NaN   \n","10                          NaN                         NaN   \n","11                          NaN                         NaN   \n","\n","   Time - Ts and Ls_Page Submit Time - Ts and Ls_Click Count  \\\n","7                           NaN                          NaN   \n","8                           NaN                          NaN   \n","9                           NaN                          NaN   \n","10                          NaN                          NaN   \n","11                          NaN                          NaN   \n","\n","                PROLIFIC_PID                  STUDY_ID  \\\n","7   5ad4a9f30f5d3900016a4d8b  65bbf618f68237c8f85dd107   \n","8   610b4e7c62e3c559c069bc8e  65bbf618f68237c8f85dd107   \n","9   5cfd45060dffe10017eb8aad  65bbf618f68237c8f85dd107   \n","10  6108b3ff82db698c577e6165  65bbf618f68237c8f85dd107   \n","11  601b492280b3ce4fa542774f  65bbf618f68237c8f85dd107   \n","\n","                  SESSION_ID mTurkCode Q_TotalDuration   id  \n","7   65bc0bb38f716cd35c0289cb       NaN             889  NaN  \n","8   65bc0b1f1c3f3a916ad40fc7       NaN            1319  NaN  \n","9   65bc0b71043a3bec5bb4fce6       NaN            1294  NaN  \n","10  65bc0b2fc27f6c4538c35973       NaN            1622  NaN  \n","11  65bc0a8f5ad093922eb4fbcf       NaN            1659  NaN  "],"text/html":["\n","  <div id=\"df-384ae20f-2b74-4bda-a020-8306a58875d8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>StartDate</th>\n","      <th>EndDate</th>\n","      <th>Status</th>\n","      <th>IPAddress</th>\n","      <th>Progress</th>\n","      <th>Duration (in seconds)</th>\n","      <th>Finished</th>\n","      <th>RecordedDate</th>\n","      <th>ResponseId</th>\n","      <th>RecipientLastName</th>\n","      <th>RecipientFirstName</th>\n","      <th>RecipientEmail</th>\n","      <th>ExternalReference</th>\n","      <th>LocationLatitude</th>\n","      <th>LocationLongitude</th>\n","      <th>DistributionChannel</th>\n","      <th>UserLanguage</th>\n","      <th>Q_BallotBoxStuffing</th>\n","      <th>Q5</th>\n","      <th>Time Prolific ID_First Click</th>\n","      <th>Time Prolific ID_Last Click</th>\n","      <th>Time Prolific ID_Page Submit</th>\n","      <th>Time Prolific ID_Click Count</th>\n","      <th>Time - Inf Consent_First Click</th>\n","      <th>Time - Inf Consent_Last Click</th>\n","      <th>Time - Inf Consent_Page Submit</th>\n","      <th>Time - Inf Consent_Click Count</th>\n","      <th>Time - Intro/MturkID_First Click</th>\n","      <th>Time - Intro/MturkID_Last Click</th>\n","      <th>Time - Intro/MturkID_Page Submit</th>\n","      <th>Time - Intro/MturkID_Click Count</th>\n","      <th>Demos_1_1</th>\n","      <th>Demos_1_2</th>\n","      <th>Demos_2</th>\n","      <th>Demos_3</th>\n","      <th>Demos_4</th>\n","      <th>Demos_5</th>\n","      <th>Demos_6_1</th>\n","      <th>Time - Demo1_First Click</th>\n","      <th>Time - Demo1_Last Click</th>\n","      <th>Time - Demo1_Page Submit</th>\n","      <th>Time - Demo1_Click Count</th>\n","      <th>Demos_7</th>\n","      <th>Demos_8</th>\n","      <th>Time - Demo2_First Click</th>\n","      <th>Time - Demo2_Last Click</th>\n","      <th>Time - Demo2_Page Submit</th>\n","      <th>Time - Demo2_Click Count</th>\n","      <th>Demos_9</th>\n","      <th>Demos_10</th>\n","      <th>Demos_11</th>\n","      <th>Time - Demo3_First Click</th>\n","      <th>Time - Demo3_Last Click</th>\n","      <th>Time - Demo3_Page Submit</th>\n","      <th>Time - Demo3_Click Count</th>\n","      <th>Demos_12</th>\n","      <th>Demos_13</th>\n","      <th>Time - Demo4_First Click</th>\n","      <th>Time - Demo4_Last Click</th>\n","      <th>Time - Demo4_Page Submit</th>\n","      <th>Time - Demo4_Click Count</th>\n","      <th>Demos_14_1</th>\n","      <th>Demos_15_1</th>\n","      <th>Demos_16</th>\n","      <th>Demos_17</th>\n","      <th>Demos_18</th>\n","      <th>Time - Demo5_First Click</th>\n","      <th>Time - Demo5_Last Click</th>\n","      <th>Time - Demo5_Page Submit</th>\n","      <th>Time - Demo5_Click Count</th>\n","      <th>Readiness_1</th>\n","      <th>Readiness_2_1</th>\n","      <th>Readiness_3</th>\n","      <th>Readiness_4_1</th>\n","      <th>Readiness_5</th>\n","      <th>Readiness_6</th>\n","      <th>Readiness_7</th>\n","      <th>Readiness_8</th>\n","      <th>Readiness_9</th>\n","      <th>Readiness_10_1</th>\n","      <th>Readiness_11_1</th>\n","      <th>Readiness_12</th>\n","      <th>Readiness_13_1</th>\n","      <th>Readiness_14_1</th>\n","      <th>Readiness_15</th>\n","      <th>Readiness_16</th>\n","      <th>Time - Readiness_First Click</th>\n","      <th>Time - Readiness_Last Click</th>\n","      <th>Time - Readiness_Page Submit</th>\n","      <th>Time - Readiness_Click Count</th>\n","      <th>Burnout_1</th>\n","      <th>Burnout_2</th>\n","      <th>Burnout_3</th>\n","      <th>Burnout_4</th>\n","      <th>Burnout_5</th>\n","      <th>Burnout_6</th>\n","      <th>Burnout_7</th>\n","      <th>Burnout_8</th>\n","      <th>Burnout_9</th>\n","      <th>Burnout_10</th>\n","      <th>Burnout_11</th>\n","      <th>Burnout_12</th>\n","      <th>Burnout_13</th>\n","      <th>Burnout_14</th>\n","      <th>Burnout_15</th>\n","      <th>Burnout_16</th>\n","      <th>Time - Oldenburg_First Click</th>\n","      <th>Time - Oldenburg_Last Click</th>\n","      <th>Time - Oldenburg_Page Submit</th>\n","      <th>Time - Oldenburg_Click Count</th>\n","      <th>BFI_1</th>\n","      <th>BFI_2</th>\n","      <th>BFI_3</th>\n","      <th>BFI_4</th>\n","      <th>BFI_5</th>\n","      <th>BFI_6</th>\n","      <th>BFI_7</th>\n","      <th>BFI_8</th>\n","      <th>BFI_9</th>\n","      <th>BFI_10</th>\n","      <th>BFI_11</th>\n","      <th>BFI_12</th>\n","      <th>BFI_13</th>\n","      <th>BFI_14</th>\n","      <th>BFI_15</th>\n","      <th>BFI_16</th>\n","      <th>BFI_17</th>\n","      <th>BFI_18</th>\n","      <th>BFI_19</th>\n","      <th>BFI_20</th>\n","      <th>BFI_21</th>\n","      <th>BFI_22</th>\n","      <th>BFI_23</th>\n","      <th>BFI_24</th>\n","      <th>BFI_25</th>\n","      <th>BFI_26</th>\n","      <th>BFI_27</th>\n","      <th>BFI_28</th>\n","      <th>BFI_29</th>\n","      <th>BFI_30</th>\n","      <th>BFI_31</th>\n","      <th>BFI_32</th>\n","      <th>BFI_33</th>\n","      <th>BFI_34</th>\n","      <th>BFI_35</th>\n","      <th>BFI_36</th>\n","      <th>BFI_37</th>\n","      <th>BFI_38</th>\n","      <th>BFI_39</th>\n","      <th>BFI_40</th>\n","      <th>BFI_41</th>\n","      <th>BFI_42</th>\n","      <th>BFI_43</th>\n","      <th>BFI_44</th>\n","      <th>Time - Big5_First Click</th>\n","      <th>Time - Big5_Last Click</th>\n","      <th>Time - Big5_Page Submit</th>\n","      <th>Time - Big5_Click Count</th>\n","      <th>Time - AttnCheck 1.1_First Click</th>\n","      <th>Time - AttnCheck 1.1_Last Click</th>\n","      <th>Time - AttnCheck 1.1_Page Submit</th>\n","      <th>Time - AttnCheck 1.1_Click Count</th>\n","      <th>Attn_Check_1_1</th>\n","      <th>Time - AttnCheck 1.2_First Click</th>\n","      <th>Time - AttnCheck 1.2_Last Click</th>\n","      <th>Time - AttnCheck 1.2_Page Submit</th>\n","      <th>Time - AttnCheck 1.2_Click Count</th>\n","      <th>Attn_Check_1_2</th>\n","      <th>Time - AttnCheck 1.3_First Click</th>\n","      <th>Time - AttnCheck 1.3_Last Click</th>\n","      <th>Time - AttnCheck 1.3_Page Submit</th>\n","      <th>Time - AttnCheck 1.3_Click Count</th>\n","      <th>Attn_Check_1_3</th>\n","      <th>Time - AttnCheck 1.4_First Click</th>\n","      <th>Time - AttnCheck 1.4_Last Click</th>\n","      <th>Time - AttnCheck 1.4_Page Submit</th>\n","      <th>Time - AttnCheck 1.4_Click Count</th>\n","      <th>Attn_Check_1_4</th>\n","      <th>ADHD_1</th>\n","      <th>ADHD_2</th>\n","      <th>ADHD_3</th>\n","      <th>ADHD_4</th>\n","      <th>ADHD_5</th>\n","      <th>ADHD_6</th>\n","      <th>ADHD_7</th>\n","      <th>ADHD_8</th>\n","      <th>ADHD_9</th>\n","      <th>ADHD_10</th>\n","      <th>ADHD_11</th>\n","      <th>ADHD_12</th>\n","      <th>ADHD_13</th>\n","      <th>ADHD_14</th>\n","      <th>ADHD_15</th>\n","      <th>ADHD_16</th>\n","      <th>ADHD_17</th>\n","      <th>ADHD_18</th>\n","      <th>ADHD_19</th>\n","      <th>ADHD_20</th>\n","      <th>ADHD_21</th>\n","      <th>ADHD_22</th>\n","      <th>ADHD_23</th>\n","      <th>ADHD_24</th>\n","      <th>Time - ADHD_First Click</th>\n","      <th>Time - ADHD_Last Click</th>\n","      <th>Time - ADHD_Page Submit</th>\n","      <th>Time - ADHD_Click Count</th>\n","      <th>STAI_1_1</th>\n","      <th>STAI_1_2</th>\n","      <th>STAI_1_3</th>\n","      <th>STAI_1_4</th>\n","      <th>STAI_1_5</th>\n","      <th>STAI_1_6</th>\n","      <th>STAI_1_7</th>\n","      <th>STAI_1_8</th>\n","      <th>STAI_1_9</th>\n","      <th>STAI_1_10</th>\n","      <th>STAI_1_11</th>\n","      <th>STAI_1_12</th>\n","      <th>STAI_1_13</th>\n","      <th>STAI_1_14</th>\n","      <th>STAI_1_15</th>\n","      <th>STAI_1_16</th>\n","      <th>STAI_1_17</th>\n","      <th>STAI_1_18</th>\n","      <th>STAI_1_19</th>\n","      <th>STAI_1_20</th>\n","      <th>STAI_2_1</th>\n","      <th>STAI_2_2</th>\n","      <th>STAI_2_3</th>\n","      <th>STAI_2_4</th>\n","      <th>STAI_2_5</th>\n","      <th>STAI_2_6</th>\n","      <th>STAI_2_7</th>\n","      <th>STAI_2_8</th>\n","      <th>STAI_2_9</th>\n","      <th>STAI_2_10</th>\n","      <th>STAI_2_11</th>\n","      <th>STAI_2_12</th>\n","      <th>STAI_2_13</th>\n","      <th>STAI_2_14</th>\n","      <th>STAI_2_15</th>\n","      <th>STAI_2_16</th>\n","      <th>STAI_2_17</th>\n","      <th>STAI_2_18</th>\n","      <th>STAI_2_19</th>\n","      <th>STAI_2_20</th>\n","      <th>Time - STAI_First Click</th>\n","      <th>Time - STAI_Last Click</th>\n","      <th>Time - STAI_Page Submit</th>\n","      <th>Time - STAI_Click Count</th>\n","      <th>Maslach_1</th>\n","      <th>Maslach_2</th>\n","      <th>Maslach_3</th>\n","      <th>Maslach_4</th>\n","      <th>Maslach_5</th>\n","      <th>Maslach_6</th>\n","      <th>Maslach_7</th>\n","      <th>Maslach_8</th>\n","      <th>Maslach_9</th>\n","      <th>Maslach_10</th>\n","      <th>Maslach_11</th>\n","      <th>Maslach_12</th>\n","      <th>Maslach_13</th>\n","      <th>Maslach_14</th>\n","      <th>Maslach_15</th>\n","      <th>Maslach_16</th>\n","      <th>Timing - Maslach _First Click</th>\n","      <th>Timing - Maslach _Last Click</th>\n","      <th>Timing - Maslach _Page Submit</th>\n","      <th>Timing - Maslach _Click Count</th>\n","      <th>Time - AttnCheck 2.1_First Click</th>\n","      <th>Time - AttnCheck 2.1_Last Click</th>\n","      <th>Time - AttnCheck 2.1_Page Submit</th>\n","      <th>Time - AttnCheck 2.1_Click Count</th>\n","      <th>Attn_Check_2_1</th>\n","      <th>Time - AttnCheck 2.2_First Click</th>\n","      <th>Time - AttnCheck 2.2_Last Click</th>\n","      <th>Time - AttnCheck 2.2_Page Submit</th>\n","      <th>Time - AttnCheck 2.2_Click Count</th>\n","      <th>Attn_Check_2_2</th>\n","      <th>Time - AttnCheck 2.3_First Click</th>\n","      <th>Time - AttnCheck 2.3_Last Click</th>\n","      <th>Time - AttnCheck 2.3_Page Submit</th>\n","      <th>Time - AttnCheck 2.3_Click Count</th>\n","      <th>Attn_Check_2_3</th>\n","      <th>Time - AttnCheck 2.4_First Click</th>\n","      <th>Time - AttnCheck 2.4_Last Click</th>\n","      <th>Time - AttnCheck 2.4_Page Submit</th>\n","      <th>Time - AttnCheck 2.4_Click Count</th>\n","      <th>Attn_Check_2_4</th>\n","      <th>OCD_1_1</th>\n","      <th>OCD_1_2</th>\n","      <th>OCD_1_3</th>\n","      <th>OCD_1_4</th>\n","      <th>OCD_1_5</th>\n","      <th>Time - OCD 1_First Click</th>\n","      <th>Time - OCD 1_Last Click</th>\n","      <th>Time - OCD 1_Page Submit</th>\n","      <th>Time - OCD 1_Click Count</th>\n","      <th>OCD_2_1</th>\n","      <th>OCD_2_2</th>\n","      <th>OCD_2_3</th>\n","      <th>OCD_2_4</th>\n","      <th>OCD_2_5</th>\n","      <th>Time - OCD 2_First Click</th>\n","      <th>Time - OCD 2_Last Click</th>\n","      <th>Time - OCD 2_Page Submit</th>\n","      <th>Time - OCD 2_Click Count</th>\n","      <th>OCD_3_1</th>\n","      <th>OCD_3_2</th>\n","      <th>OCD_3_3</th>\n","      <th>OCD_3_4</th>\n","      <th>OCD_3_5</th>\n","      <th>Time - OCD 3_First Click</th>\n","      <th>Time - OCD 3_Last Click</th>\n","      <th>Time - OCD 3_Page Submit</th>\n","      <th>Time - OCD 3_Click Count</th>\n","      <th>OCD_4_1</th>\n","      <th>OCD_4_2</th>\n","      <th>OCD_4_3</th>\n","      <th>OCD_4_4</th>\n","      <th>OCD_4_5</th>\n","      <th>Time - OCD 4_First Click</th>\n","      <th>Time - OCD 4_Last Click</th>\n","      <th>Time - OCD 4_Page Submit</th>\n","      <th>Time - OCD 4_Click Count</th>\n","      <th>BIS_1</th>\n","      <th>BIS_2</th>\n","      <th>BIS_3</th>\n","      <th>BIS_4</th>\n","      <th>BIS_5</th>\n","      <th>BIS_6</th>\n","      <th>BIS_7</th>\n","      <th>BIS_8</th>\n","      <th>BIS_9</th>\n","      <th>BIS_10</th>\n","      <th>BIS_11</th>\n","      <th>BIS_12</th>\n","      <th>BIS_13</th>\n","      <th>BIS_14</th>\n","      <th>BIS_15</th>\n","      <th>BIS_16</th>\n","      <th>BIS_17</th>\n","      <th>BIS_18</th>\n","      <th>BIS_19</th>\n","      <th>BIS_20</th>\n","      <th>BIS_21</th>\n","      <th>BIS_22</th>\n","      <th>BIS_23</th>\n","      <th>BIS_24</th>\n","      <th>BIS_25</th>\n","      <th>BIS_26</th>\n","      <th>BIS_27</th>\n","      <th>BIS_28</th>\n","      <th>BIS_29</th>\n","      <th>BIS_30</th>\n","      <th>Time - BIS_First Click</th>\n","      <th>Time - BIS_Last Click</th>\n","      <th>Time - BIS_Page Submit</th>\n","      <th>Time - BIS_Click Count</th>\n","      <th>Q618_First Click</th>\n","      <th>Q618_Last Click</th>\n","      <th>Q618_Page Submit</th>\n","      <th>Q618_Click Count</th>\n","      <th>Attn_Check_3_1</th>\n","      <th>Q620_First Click</th>\n","      <th>Q620_Last Click</th>\n","      <th>Q620_Page Submit</th>\n","      <th>Q620_Click Count</th>\n","      <th>Attn_Check_3_2</th>\n","      <th>Q622_First Click</th>\n","      <th>Q622_Last Click</th>\n","      <th>Q622_Page Submit</th>\n","      <th>Q622_Click Count</th>\n","      <th>Attn_Check_3_3</th>\n","      <th>Q624_First Click</th>\n","      <th>Q624_Last Click</th>\n","      <th>Q624_Page Submit</th>\n","      <th>Q624_Click Count</th>\n","      <th>Attn_Check_3_4</th>\n","      <th>ASQ_1</th>\n","      <th>ASQ_2</th>\n","      <th>ASQ_3</th>\n","      <th>ASQ_4</th>\n","      <th>ASQ_5</th>\n","      <th>ASQ_6</th>\n","      <th>ASQ_7</th>\n","      <th>ASQ_8</th>\n","      <th>ASQ_9</th>\n","      <th>ASQ_10</th>\n","      <th>ASQ_11</th>\n","      <th>ASQ_12</th>\n","      <th>ASQ_13</th>\n","      <th>ASQ_14</th>\n","      <th>ASQ_15</th>\n","      <th>ASQ_16</th>\n","      <th>ASQ_17</th>\n","      <th>ASQ_18</th>\n","      <th>ASQ_19</th>\n","      <th>ASQ_20</th>\n","      <th>ASQ_21</th>\n","      <th>ASQ_22</th>\n","      <th>ASQ_23</th>\n","      <th>ASQ_24</th>\n","      <th>ASQ_25</th>\n","      <th>ASQ_26</th>\n","      <th>ASQ_27</th>\n","      <th>ASQ_28</th>\n","      <th>ASQ_29</th>\n","      <th>ASQ_30</th>\n","      <th>ASQ_31</th>\n","      <th>ASQ_32</th>\n","      <th>ASQ_33</th>\n","      <th>ASQ_34</th>\n","      <th>ASQ_35</th>\n","      <th>ASQ_36</th>\n","      <th>ASQ_37</th>\n","      <th>ASQ_38</th>\n","      <th>ASQ_39</th>\n","      <th>ASQ_40</th>\n","      <th>ASQ_41</th>\n","      <th>ASQ_42</th>\n","      <th>ASQ_43</th>\n","      <th>ASQ_44</th>\n","      <th>ASQ_45</th>\n","      <th>ASQ_46</th>\n","      <th>ASQ_47</th>\n","      <th>ASQ_48</th>\n","      <th>ASQ_49</th>\n","      <th>ASQ_50</th>\n","      <th>Time - ASQ_First Click</th>\n","      <th>Time - ASQ_Last Click</th>\n","      <th>Time - ASQ_Page Submit</th>\n","      <th>Time - ASQ_Click Count</th>\n","      <th>Wordle_2_First Click</th>\n","      <th>Wordle_2_Last Click</th>\n","      <th>Wordle_2_Page Submit</th>\n","      <th>Wordle_2_Click Count</th>\n","      <th>Wordle_3</th>\n","      <th>Wordle_5</th>\n","      <th>Wordle_6</th>\n","      <th>Wordle_7</th>\n","      <th>Wordle_9</th>\n","      <th>Wordle_10</th>\n","      <th>Wordle_11</th>\n","      <th>Wordle_12</th>\n","      <th>Wordle_13</th>\n","      <th>Wordle_14</th>\n","      <th>Wordle_15_First Click</th>\n","      <th>Wordle_15_Last Click</th>\n","      <th>Wordle_15_Page Submit</th>\n","      <th>Wordle_15_Click Count</th>\n","      <th>Second_Readiness_1_1</th>\n","      <th>Second_Readiness_2_1</th>\n","      <th>Second_Readiness_3</th>\n","      <th>Second_Readiness_4_1</th>\n","      <th>Second_Readiness_5</th>\n","      <th>time_second_readi_First Click</th>\n","      <th>time_second_readi_Last Click</th>\n","      <th>time_second_readi_Page Submit</th>\n","      <th>time_second_readi_Click Count</th>\n","      <th>Grit Scale_1</th>\n","      <th>Grit Scale_6</th>\n","      <th>Grit Scale_2</th>\n","      <th>Grit Scale_3</th>\n","      <th>Grit Scale_4</th>\n","      <th>Grit Scale_7</th>\n","      <th>Grit Scale_5</th>\n","      <th>Grit Scale_8</th>\n","      <th>Grit Scale_9</th>\n","      <th>Grit Scale_10</th>\n","      <th>Time - Grit_First Click</th>\n","      <th>Time - Grit_Last Click</th>\n","      <th>Time - Grit_Page Submit</th>\n","      <th>Time - Grit_Click Count</th>\n","      <th>Time - Ts and Ls_First Click</th>\n","      <th>Time - Ts and Ls_Last Click</th>\n","      <th>Time - Ts and Ls_Page Submit</th>\n","      <th>Time - Ts and Ls_Click Count</th>\n","      <th>PROLIFIC_PID</th>\n","      <th>STUDY_ID</th>\n","      <th>SESSION_ID</th>\n","      <th>mTurkCode</th>\n","      <th>Q_TotalDuration</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>2024-02-01 14:23:11</td>\n","      <td>2024-02-01 14:38:01</td>\n","      <td>IP Address</td>\n","      <td>63.119.86.210</td>\n","      <td>100</td>\n","      <td>889</td>\n","      <td>True</td>\n","      <td>2024-02-01 14:38:02</td>\n","      <td>R_1MANoWmYyLjw5O6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>40.8806</td>\n","      <td>-74.1456</td>\n","      <td>anonymous</td>\n","      <td>EN</td>\n","      <td>NaN</td>\n","      <td>5ad4a9f30f5d3900016a4d8b</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.282</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.078</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.782</td>\n","      <td>0</td>\n","      <td>33</td>\n","      <td>0</td>\n","      <td>Female</td>\n","      <td>College</td>\n","      <td>Full-time</td>\n","      <td>No</td>\n","      <td>6</td>\n","      <td>1.31</td>\n","      <td>28.285</td>\n","      <td>32.63</td>\n","      <td>7</td>\n","      <td>Health and Medical</td>\n","      <td>In-person office or work environment</td>\n","      <td>7.894</td>\n","      <td>9.334</td>\n","      <td>10.84</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>60-119 minutes</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11.935</td>\n","      <td>0</td>\n","      <td>Divorced</td>\n","      <td>Yes</td>\n","      <td>6.642</td>\n","      <td>8.945</td>\n","      <td>9.947</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>Right</td>\n","      <td>Normal (do not require contacts, glasses, etc....</td>\n","      <td>No</td>\n","      <td>1.287</td>\n","      <td>8.983</td>\n","      <td>9.979</td>\n","      <td>5</td>\n","      <td>Yes</td>\n","      <td>8</td>\n","      <td>10 pm</td>\n","      <td>8</td>\n","      <td>10 pm</td>\n","      <td>10</td>\n","      <td>No</td>\n","      <td>I didn't nap today</td>\n","      <td>I didn't nap today</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>I have not used any nicotine products today</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>No</td>\n","      <td>Never</td>\n","      <td>2.173</td>\n","      <td>68.086</td>\n","      <td>69.581</td>\n","      <td>19</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>4.556</td>\n","      <td>59.569</td>\n","      <td>61.126</td>\n","      <td>17</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>5.315</td>\n","      <td>79.735</td>\n","      <td>80.678</td>\n","      <td>47</td>\n","      <td>26.093</td>\n","      <td>26.093</td>\n","      <td>27.219</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>Moderately</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>Quite a lot</td>\n","      <td>Very Much</td>\n","      <td>2.867</td>\n","      <td>203.441</td>\n","      <td>205.626</td>\n","      <td>26</td>\n","      <td>Very Much So</td>\n","      <td>Very Much So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Very Much So</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Almost Always</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>4.935</td>\n","      <td>74.92</td>\n","      <td>76.276</td>\n","      <td>45</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>15.202</td>\n","      <td>15.202</td>\n","      <td>16.335</td>\n","      <td>1</td>\n","      <td>In the last month</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>14.949</td>\n","      <td>34.539</td>\n","      <td>41.026</td>\n","      <td>5</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>6.182</td>\n","      <td>12.555</td>\n","      <td>14.255</td>\n","      <td>5</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>Many things are disrupted, but I can still man...</td>\n","      <td>A little difficult</td>\n","      <td>8.067</td>\n","      <td>18.833</td>\n","      <td>20.967</td>\n","      <td>5</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>10.687</td>\n","      <td>18.605</td>\n","      <td>19.742</td>\n","      <td>6</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Almost always/Always</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>2.936</td>\n","      <td>39.138</td>\n","      <td>40.491</td>\n","      <td>33</td>\n","      <td>8.987</td>\n","      <td>8.987</td>\n","      <td>11.441</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>2.598</td>\n","      <td>64.64</td>\n","      <td>66.888</td>\n","      <td>54</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Not much like me</td>\n","      <td>Not much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Not much like me</td>\n","      <td>Not much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>8.306</td>\n","      <td>20.016</td>\n","      <td>21.455</td>\n","      <td>10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5ad4a9f30f5d3900016a4d8b</td>\n","      <td>65bbf618f68237c8f85dd107</td>\n","      <td>65bc0bb38f716cd35c0289cb</td>\n","      <td>NaN</td>\n","      <td>889</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2024-02-01 14:20:37</td>\n","      <td>2024-02-01 14:42:37</td>\n","      <td>IP Address</td>\n","      <td>128.197.29.239</td>\n","      <td>100</td>\n","      <td>1319</td>\n","      <td>True</td>\n","      <td>2024-02-01 14:42:37</td>\n","      <td>R_6U3AK02VLDajycS</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>42.3464</td>\n","      <td>-71.0975</td>\n","      <td>anonymous</td>\n","      <td>EN</td>\n","      <td>NaN</td>\n","      <td>610b4e7c62e3c559c069bc8e</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12.119</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13.2</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>5</td>\n","      <td>Male</td>\n","      <td>Masters</td>\n","      <td>Full-time</td>\n","      <td>No</td>\n","      <td>9</td>\n","      <td>1.003</td>\n","      <td>34.203</td>\n","      <td>36.366</td>\n","      <td>9</td>\n","      <td>Social and Life Sciences</td>\n","      <td>In-person office or work environment</td>\n","      <td>0.894</td>\n","      <td>24.021</td>\n","      <td>25.051</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>30-59 minutes</td>\n","      <td>1.884</td>\n","      <td>6.138</td>\n","      <td>8.493</td>\n","      <td>2</td>\n","      <td>In a relationship</td>\n","      <td>No</td>\n","      <td>1.35</td>\n","      <td>4.143</td>\n","      <td>5.234</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Right</td>\n","      <td>Normal (do not require contacts, glasses, etc....</td>\n","      <td>No</td>\n","      <td>1.343</td>\n","      <td>5.024</td>\n","      <td>6.064</td>\n","      <td>3</td>\n","      <td>No</td>\n","      <td>8</td>\n","      <td>11 pm</td>\n","      <td>10</td>\n","      <td>9 pm</td>\n","      <td>8</td>\n","      <td>No</td>\n","      <td>I didn't nap today</td>\n","      <td>I didn't nap today</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>I have not used any nicotine products today</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>No</td>\n","      <td>Rarely</td>\n","      <td>3.68</td>\n","      <td>130.544</td>\n","      <td>131.696</td>\n","      <td>18</td>\n","      <td>strongly agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>strongly disagree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>8.711</td>\n","      <td>64.231</td>\n","      <td>65.033</td>\n","      <td>16</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree strongly</td>\n","      <td>10.906</td>\n","      <td>102.86</td>\n","      <td>103.573</td>\n","      <td>47</td>\n","      <td>14.673</td>\n","      <td>14.673</td>\n","      <td>20.077</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Not at all</td>\n","      <td>Moderately</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>10.749</td>\n","      <td>93.825</td>\n","      <td>94.701</td>\n","      <td>26</td>\n","      <td>Very Much So</td>\n","      <td>Very Much So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Very Much So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Moderately So</td>\n","      <td>Somewhat</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Moderately So</td>\n","      <td>Almost Always</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Almost Always</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Almost Always</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>12.326</td>\n","      <td>107.099</td>\n","      <td>108.663</td>\n","      <td>41</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>18.204</td>\n","      <td>18.204</td>\n","      <td>20.046</td>\n","      <td>1</td>\n","      <td>In the last month</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>None at all</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>71.533</td>\n","      <td>100.116</td>\n","      <td>100.955</td>\n","      <td>6</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>14.86</td>\n","      <td>25.09</td>\n","      <td>27.836</td>\n","      <td>5</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>10.196</td>\n","      <td>18.163</td>\n","      <td>19.552</td>\n","      <td>5</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>8.036</td>\n","      <td>15.482</td>\n","      <td>16.849</td>\n","      <td>5</td>\n","      <td>Almost always/Always</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Almost always/Always</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>3.397</td>\n","      <td>76.541</td>\n","      <td>77.301</td>\n","      <td>32</td>\n","      <td>13.288</td>\n","      <td>13.288</td>\n","      <td>14.97</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>5.646</td>\n","      <td>178.845</td>\n","      <td>180.278</td>\n","      <td>54</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Mostly like me</td>\n","      <td>Very much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Very much like me</td>\n","      <td>Not much like me</td>\n","      <td>Mostly like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Very much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Mostly like me</td>\n","      <td>10.351</td>\n","      <td>42.154</td>\n","      <td>43.164</td>\n","      <td>10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>610b4e7c62e3c559c069bc8e</td>\n","      <td>65bbf618f68237c8f85dd107</td>\n","      <td>65bc0b1f1c3f3a916ad40fc7</td>\n","      <td>NaN</td>\n","      <td>1319</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2024-02-01 14:22:00</td>\n","      <td>2024-02-01 14:43:34</td>\n","      <td>IP Address</td>\n","      <td>173.21.155.28</td>\n","      <td>100</td>\n","      <td>1294</td>\n","      <td>True</td>\n","      <td>2024-02-01 14:43:35</td>\n","      <td>R_1BRx0GHWVMPUJ3p</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>33.3987</td>\n","      <td>-111.5013</td>\n","      <td>anonymous</td>\n","      <td>EN</td>\n","      <td>NaN</td>\n","      <td>5cfd45060dffe10017eb8aad</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.8</td>\n","      <td>0</td>\n","      <td>3.17</td>\n","      <td>3.17</td>\n","      <td>4.653</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15.219</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>Female</td>\n","      <td>College</td>\n","      <td>Full-time</td>\n","      <td>Yes</td>\n","      <td>7</td>\n","      <td>1.504</td>\n","      <td>13.67</td>\n","      <td>14.459</td>\n","      <td>17</td>\n","      <td>Education, Teaching and Training</td>\n","      <td>Remote or working from home</td>\n","      <td>0.86</td>\n","      <td>3.335</td>\n","      <td>4.059</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.796</td>\n","      <td>4.516</td>\n","      <td>5.116</td>\n","      <td>4</td>\n","      <td>Single</td>\n","      <td>No</td>\n","      <td>1.342</td>\n","      <td>3</td>\n","      <td>3.809</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Right</td>\n","      <td>Normal (do not require contacts, glasses, etc....</td>\n","      <td>No</td>\n","      <td>2.38</td>\n","      <td>22.261</td>\n","      <td>23.285</td>\n","      <td>8</td>\n","      <td>Yes</td>\n","      <td>5</td>\n","      <td>8 pm</td>\n","      <td>7</td>\n","      <td>8 pm</td>\n","      <td>4</td>\n","      <td>No</td>\n","      <td>I didn't nap today</td>\n","      <td>I didn't nap today</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>I have not used any nicotine products today</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Sometimes</td>\n","      <td>1.953</td>\n","      <td>62.698</td>\n","      <td>63.345</td>\n","      <td>55</td>\n","      <td>disagree</td>\n","      <td>strongly agree</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>strongly agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>0.106</td>\n","      <td>75.918</td>\n","      <td>76.523</td>\n","      <td>33</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>20.816</td>\n","      <td>124.99</td>\n","      <td>125.74</td>\n","      <td>92</td>\n","      <td>13.869</td>\n","      <td>14.442</td>\n","      <td>15.121</td>\n","      <td>2</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Moderately</td>\n","      <td>Very Much</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Quite a lot</td>\n","      <td>Just a little</td>\n","      <td>Somewhat</td>\n","      <td>Not at all</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Quite a lot</td>\n","      <td>Quite a lot</td>\n","      <td>Somewhat</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Just a little</td>\n","      <td>Moderately</td>\n","      <td>Moderately</td>\n","      <td>Just a little</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>11.959</td>\n","      <td>229.894</td>\n","      <td>232.17</td>\n","      <td>55</td>\n","      <td>Somewhat</td>\n","      <td>Not At All</td>\n","      <td>Very Much So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Moderately So</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Almost Always</td>\n","      <td>Almost Always</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Almost Always</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>21.976</td>\n","      <td>144.96</td>\n","      <td>145.586</td>\n","      <td>71</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6.041</td>\n","      <td>6.564</td>\n","      <td>7.064</td>\n","      <td>2</td>\n","      <td>In the last month</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A moderate amount of avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>2.989</td>\n","      <td>31.411</td>\n","      <td>32.101</td>\n","      <td>19</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A moderate amount of avoidance</td>\n","      <td>Moderately distressed/anxious</td>\n","      <td>Many things are disrupted, but I can still man...</td>\n","      <td>Moderately difficult</td>\n","      <td>3.035</td>\n","      <td>41.591</td>\n","      <td>41.956</td>\n","      <td>18</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>8.555</td>\n","      <td>19.743</td>\n","      <td>20.034</td>\n","      <td>16</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Moderately distressed/anxious</td>\n","      <td>Many things are disrupted, but I can still man...</td>\n","      <td>A little difficult</td>\n","      <td>18.881</td>\n","      <td>26.971</td>\n","      <td>27.624</td>\n","      <td>14</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>2.519</td>\n","      <td>75.162</td>\n","      <td>75.538</td>\n","      <td>59</td>\n","      <td>4.046</td>\n","      <td>4.464</td>\n","      <td>4.892</td>\n","      <td>2</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>14.367</td>\n","      <td>160.449</td>\n","      <td>160.965</td>\n","      <td>101</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Mostly like me</td>\n","      <td>Not much like me</td>\n","      <td>Mostly like me</td>\n","      <td>Mostly like me</td>\n","      <td>Mostly like me</td>\n","      <td>Not much like me</td>\n","      <td>Mostly like me</td>\n","      <td>Mostly like me</td>\n","      <td>Mostly like me</td>\n","      <td>Mostly like me</td>\n","      <td>1.193</td>\n","      <td>39.378</td>\n","      <td>40.656</td>\n","      <td>23</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5cfd45060dffe10017eb8aad</td>\n","      <td>65bbf618f68237c8f85dd107</td>\n","      <td>65bc0b71043a3bec5bb4fce6</td>\n","      <td>NaN</td>\n","      <td>1294</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2024-02-01 14:20:58</td>\n","      <td>2024-02-01 14:48:00</td>\n","      <td>IP Address</td>\n","      <td>76.135.144.47</td>\n","      <td>100</td>\n","      <td>1622</td>\n","      <td>True</td>\n","      <td>2024-02-01 14:48:01</td>\n","      <td>R_6O1WyW2hbyUfpdp</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>48.799</td>\n","      <td>-122.4499</td>\n","      <td>anonymous</td>\n","      <td>EN</td>\n","      <td>NaN</td>\n","      <td>6108b3ff82db698c577e6165</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.978</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>423.985</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15.041</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>6</td>\n","      <td>Prefer not to respond</td>\n","      <td>Some College</td>\n","      <td>Part-time</td>\n","      <td>No</td>\n","      <td>8</td>\n","      <td>1.182</td>\n","      <td>23.4</td>\n","      <td>24.774</td>\n","      <td>11</td>\n","      <td>Sales and Marketing</td>\n","      <td>In-person office or work environment</td>\n","      <td>1.42</td>\n","      <td>15.167</td>\n","      <td>16.571</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>15-29 minutes</td>\n","      <td>1.725</td>\n","      <td>4.904</td>\n","      <td>5.914</td>\n","      <td>4</td>\n","      <td>Single</td>\n","      <td>No</td>\n","      <td>1.111</td>\n","      <td>2.382</td>\n","      <td>3.798</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Right</td>\n","      <td>Normal (do not require contacts, glasses, etc....</td>\n","      <td>No</td>\n","      <td>1.147</td>\n","      <td>5.077</td>\n","      <td>6.158</td>\n","      <td>3</td>\n","      <td>Yes</td>\n","      <td>8</td>\n","      <td>1 am</td>\n","      <td>8</td>\n","      <td>1 am</td>\n","      <td>3</td>\n","      <td>No</td>\n","      <td>I didn't nap today</td>\n","      <td>I didn't nap today</td>\n","      <td>40</td>\n","      <td>0</td>\n","      <td>I have not used any nicotine products today</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>No</td>\n","      <td>Never</td>\n","      <td>2.2</td>\n","      <td>102.401</td>\n","      <td>103.838</td>\n","      <td>19</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>strongly agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>strongly agree</td>\n","      <td>15.08</td>\n","      <td>95.043</td>\n","      <td>96.469</td>\n","      <td>19</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>10.078</td>\n","      <td>82.661</td>\n","      <td>83.558</td>\n","      <td>48</td>\n","      <td>8.549</td>\n","      <td>8.549</td>\n","      <td>13.689</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>Very Much</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Very Much</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Very Much</td>\n","      <td>Moderately</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Very Much</td>\n","      <td>Quite a lot</td>\n","      <td>Moderately</td>\n","      <td>5.823</td>\n","      <td>68.158</td>\n","      <td>68.786</td>\n","      <td>27</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Moderately So</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Somewhat</td>\n","      <td>Very Much So</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>31.185</td>\n","      <td>179.468</td>\n","      <td>181.967</td>\n","      <td>44</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.391</td>\n","      <td>9.391</td>\n","      <td>11.706</td>\n","      <td>1</td>\n","      <td>In the last month</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Between 3 and 8 hours each day</td>\n","      <td>A moderate amount of avoidance</td>\n","      <td>Moderately distressed/anxious</td>\n","      <td>Many things are disrupted, but I can still man...</td>\n","      <td>Moderately difficult</td>\n","      <td>15.571</td>\n","      <td>35.807</td>\n","      <td>38.233</td>\n","      <td>5</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A great deal of avoidance</td>\n","      <td>Moderately distressed/anxious</td>\n","      <td>Many things are disrupted, but I can still man...</td>\n","      <td>Moderately difficult</td>\n","      <td>22.398</td>\n","      <td>37.475</td>\n","      <td>39.976</td>\n","      <td>6</td>\n","      <td>Between 1 and 3 hours each day</td>\n","      <td>A great deal of avoidance</td>\n","      <td>Moderately distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>6.806</td>\n","      <td>22.3</td>\n","      <td>24.5</td>\n","      <td>6</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>16.12</td>\n","      <td>27.804</td>\n","      <td>29.345</td>\n","      <td>5</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Almost always/Always</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Almost always/Always</td>\n","      <td>Occasionally</td>\n","      <td>Almost always/Always</td>\n","      <td>Often</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>2.734</td>\n","      <td>56.287</td>\n","      <td>57.11</td>\n","      <td>34</td>\n","      <td>1.57</td>\n","      <td>87.874</td>\n","      <td>89.073</td>\n","      <td>2</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>2.567</td>\n","      <td>105.461</td>\n","      <td>106.835</td>\n","      <td>53</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Somewhat like me</td>\n","      <td>Mostly like me</td>\n","      <td>Very much like me</td>\n","      <td>Very much like me</td>\n","      <td>Very much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Very much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Very much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>48.463</td>\n","      <td>69.019</td>\n","      <td>70.126</td>\n","      <td>13</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6108b3ff82db698c577e6165</td>\n","      <td>65bbf618f68237c8f85dd107</td>\n","      <td>65bc0b2fc27f6c4538c35973</td>\n","      <td>NaN</td>\n","      <td>1622</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2024-02-01 14:22:49</td>\n","      <td>2024-02-01 14:50:29</td>\n","      <td>IP Address</td>\n","      <td>24.160.82.249</td>\n","      <td>100</td>\n","      <td>1659</td>\n","      <td>True</td>\n","      <td>2024-02-01 14:50:30</td>\n","      <td>R_1fjqyGX6HmWWiKB</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27.9786</td>\n","      <td>-82.7015</td>\n","      <td>anonymous</td>\n","      <td>EN</td>\n","      <td>NaN</td>\n","      <td>601b492280b3ce4fa542774f</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.613</td>\n","      <td>0</td>\n","      <td>7.572</td>\n","      <td>7.572</td>\n","      <td>9.146</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45.655</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>4</td>\n","      <td>Male</td>\n","      <td>High School</td>\n","      <td>Part-time</td>\n","      <td>No</td>\n","      <td>6</td>\n","      <td>1.702</td>\n","      <td>42.567</td>\n","      <td>44.681</td>\n","      <td>14</td>\n","      <td>Transportation and Moving</td>\n","      <td>In-person office or work environment</td>\n","      <td>30.244</td>\n","      <td>32.98</td>\n","      <td>34.054</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>Less than 15 minutes</td>\n","      <td>9.186</td>\n","      <td>25.552</td>\n","      <td>26.667</td>\n","      <td>8</td>\n","      <td>Single</td>\n","      <td>No</td>\n","      <td>1.439</td>\n","      <td>3.44</td>\n","      <td>4.924</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Right</td>\n","      <td>Normal (do not require contacts, glasses, etc....</td>\n","      <td>No</td>\n","      <td>1.337</td>\n","      <td>5.821</td>\n","      <td>6.701</td>\n","      <td>4</td>\n","      <td>Yes</td>\n","      <td>9</td>\n","      <td>1 am</td>\n","      <td>8</td>\n","      <td>2 am</td>\n","      <td>7</td>\n","      <td>No</td>\n","      <td>I didn't nap today</td>\n","      <td>I didn't nap today</td>\n","      <td>71</td>\n","      <td>6</td>\n","      <td>30 minutes-1 hour</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>Never</td>\n","      <td>2.809</td>\n","      <td>108.916</td>\n","      <td>109.901</td>\n","      <td>33</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>disagree</td>\n","      <td>agree</td>\n","      <td>8.26</td>\n","      <td>68.408</td>\n","      <td>70.495</td>\n","      <td>19</td>\n","      <td>Disagree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree strongly</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree strongly</td>\n","      <td>Disagree strongly</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Neither agree nor disagree</td>\n","      <td>Agree a little</td>\n","      <td>Agree a little</td>\n","      <td>Disagree a little</td>\n","      <td>6.745</td>\n","      <td>159.811</td>\n","      <td>160.79</td>\n","      <td>64</td>\n","      <td>25.729</td>\n","      <td>25.729</td>\n","      <td>33.196</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Moderately</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Somewhat</td>\n","      <td>Just a little</td>\n","      <td>Somewhat</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Somewhat</td>\n","      <td>Not at all</td>\n","      <td>Somewhat</td>\n","      <td>Moderately</td>\n","      <td>Not at all</td>\n","      <td>Not at all</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Just a little</td>\n","      <td>Not at all</td>\n","      <td>Just a little</td>\n","      <td>7.756</td>\n","      <td>192.843</td>\n","      <td>193.662</td>\n","      <td>38</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Somewhat</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Somewhat</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Moderately So</td>\n","      <td>Not At All</td>\n","      <td>Not At All</td>\n","      <td>Moderately So</td>\n","      <td>Somewhat</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Almost Never</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Often</td>\n","      <td>Sometimes</td>\n","      <td>Sometimes</td>\n","      <td>4.577</td>\n","      <td>116.245</td>\n","      <td>117.446</td>\n","      <td>47</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>17.676</td>\n","      <td>17.676</td>\n","      <td>22.292</td>\n","      <td>1</td>\n","      <td>In the last month</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>20.843</td>\n","      <td>47.968</td>\n","      <td>50.955</td>\n","      <td>11</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>18.945</td>\n","      <td>68.514</td>\n","      <td>69.642</td>\n","      <td>13</td>\n","      <td>Less than 1 hour each day</td>\n","      <td>A little avoidance</td>\n","      <td>Mildly distressed/anxious</td>\n","      <td>A little disruption, but I mostly function well.</td>\n","      <td>A little difficult</td>\n","      <td>27.905</td>\n","      <td>52.198</td>\n","      <td>53.527</td>\n","      <td>10</td>\n","      <td>None at all</td>\n","      <td>None at all</td>\n","      <td>Not at all distressed/anxious</td>\n","      <td>No disruption at all.</td>\n","      <td>Not at all difficult</td>\n","      <td>13.642</td>\n","      <td>35.709</td>\n","      <td>36.7</td>\n","      <td>12</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Often</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Occasionally</td>\n","      <td>Rarely/Never</td>\n","      <td>Occasionally</td>\n","      <td>Often</td>\n","      <td>4.119</td>\n","      <td>120.034</td>\n","      <td>121.091</td>\n","      <td>42</td>\n","      <td>14.32</td>\n","      <td>14.32</td>\n","      <td>16.536</td>\n","      <td>1</td>\n","      <td>During most of my adult life</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Definitely Disagree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Agree</td>\n","      <td>Slightly Disagree</td>\n","      <td>5.713</td>\n","      <td>261.527</td>\n","      <td>262.484</td>\n","      <td>69</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Mostly like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Not much like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Somewhat like me</td>\n","      <td>Mostly like me</td>\n","      <td>Somewhat like me</td>\n","      <td>8.342</td>\n","      <td>52.762</td>\n","      <td>53.77</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>601b492280b3ce4fa542774f</td>\n","      <td>65bbf618f68237c8f85dd107</td>\n","      <td>65bc0a8f5ad093922eb4fbcf</td>\n","      <td>NaN</td>\n","      <td>1659</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-384ae20f-2b74-4bda-a020-8306a58875d8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-384ae20f-2b74-4bda-a020-8306a58875d8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-384ae20f-2b74-4bda-a020-8306a58875d8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-083224b5-4b53-417a-a901-51cc14c4d97c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-083224b5-4b53-417a-a901-51cc14c4d97c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-083224b5-4b53-417a-a901-51cc14c4d97c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"s1_filtered_data"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# df_to_check = filtered_data.copy()\n","\n","# # Define MBI subscale items\n","# exhaustion_items = [f'Maslach_{i}' for i in [1, 2, 3, 4, 6]]  # Exhaustion (5 items)\n","# cynicism_items = [f'Maslach_{i}' for i in [8, 9, 13, 14, 15]]  # Cynicism (5 items)\n","# professional_efficacy_items = [f'Maslach_{i}' for i in [5, 7, 10, 11, 12, 16]]  # Professional Efficacy (6 items)\n","\n","# # Combine all required MBI columns\n","# maslach_columns = exhaustion_items + cynicism_items + professional_efficacy_items\n","\n","# # Calculate the number of missing fields for each person\n","# df_to_check['Missing_Fields_Count'] = df_to_check[maslach_columns].isna().sum(axis=1)\n","\n","# # Count the total number of people with any missing fields\n","# total_people_with_missing_fields = (df_to_check['Missing_Fields_Count'] > 0).sum()\n","\n","# # Count the total number of people missing all columns\n","# total_people_missing_all_fields = (df_to_check['Missing_Fields_Count'] == len(maslach_columns)).sum()\n","\n","# # Get a summary of missing fields for each person\n","# missing_summary = df_to_check[df_to_check['Missing_Fields_Count'] > 0][['PROLIFIC_PID', 'Missing_Fields_Count']]\n","\n","# # Print results\n","# print(f\"Total number of people with missing MBI fields: {total_people_with_missing_fields}\")\n","# print(f\"Total number of people missing all MBI fields: {total_people_missing_all_fields}\")\n","# print(\"Details of missing fields for each person:\")\n","# print(missing_summary)\n"],"metadata":{"id":"3JWlV-oneham"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1oxhhIoAdwMp"},"source":["# Define Survey Scoring Functions\n","Add your scoring code as a function here"]},{"cell_type":"markdown","metadata":{"id":"IhDlgOeLitE2"},"source":["## General helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhUyiWBwey4X"},"outputs":[],"source":["# Hashing Ids\n","def hash_id(participant_id):\n","    \"\"\"Hashes the participant ID using SHA-256.\"\"\"\n","    hash_object = hashlib.sha256()\n","    hash_object.update(participant_id.encode())\n","    return hash_object.hexdigest()\n","\n","## add in some code to generate to column list with prolific ID and hashed ID\n","s1_hash_match = pd.DataFrame(s1_prolific_combined_df['Participant id'])\n","s1_hash_match['hashed id'] = s1_prolific_combined_df['Participant id'].apply(hash_id)\n","\n","s1_hash_match.head()\n","hashmatchpath = '/content/drive/My Drive/battery_survey_scoring/analyses/J_hashmatch.csv'\n","s1_hash_match.to_csv(hashmatchpath, index=False)\n","\n"]},{"cell_type":"code","source":["def add_metadata_as_multiindex(data, metadata_row):\n","    \"\"\"\n","    Add a metadata row as a secondary header (multi-index for columns).\n","\n","    Args:\n","        data (pd.DataFrame): The DataFrame containing the data.\n","        metadata_row (list or pd.Series): The metadata row to use as a secondary header.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame with a multi-index for columns.\n","    \"\"\"\n","\n","    # Ensure metadata_row aligns with data columns\n","    metadata_df = pd.DataFrame([metadata_row], columns=data.columns)\n","\n","    # Combine the original column headers and metadata\n","    multi_index = pd.MultiIndex.from_tuples(\n","        zip(data.columns, metadata_df.iloc[0]),\n","        names=[\"Original Header\", \"Metadata\"]\n","    )\n","\n","    # Assign the MultiIndex to the columns\n","    data.columns = multi_index\n","\n","    return data\n"],"metadata":{"id":"wM6LrXgRq9il"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Session 1 overview tab"],"metadata":{"id":"7BK-Jj7O_FlP"}},{"cell_type":"code","source":["\n","# Compute local start time and end time\n","# Initialize timezone finder\n","tf = TimezoneFinder()\n","\n","# Conversion function\n","def convert_times_with_timezone(start_utc, end_utc, lat, lon):\n","    try:\n","        # Find the timezone name\n","        tz_name = tf.timezone_at(lat=lat, lng=lon)\n","        if tz_name is None:\n","            return pd.NaT, pd.NaT, None\n","\n","        # Define timezone\n","        local_tz = pytz.timezone(tz_name)\n","\n","        # Convert UTC to localized time\n","        start_local = pd.to_datetime(start_utc, utc=True).astimezone(local_tz)\n","        end_local = pd.to_datetime(end_utc, utc=True).astimezone(local_tz)\n","\n","        return start_local, end_local, tz_name\n","    except:\n","        return pd.NaT, pd.NaT, None\n"],"metadata":{"id":"XChnVcQoII0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prolific S1 Overview\n","def score_overview(df, path):\n","    column_mapping = {\n","        'Participant id': 'Subject_ID',\n","        'Started at': 'StartTime',\n","        'Time taken': 'Duration',\n","    }\n","\n","    df.rename(columns=column_mapping, inplace=True)\n","    df['Subject_ID'] = df['Subject_ID'].apply(hash_id)\n","\n","    # Convert seconds to timedelta (NaNs will become NaT)\n","    df['Duration_HM'] = pd.to_timedelta(df['Duration'], unit='s')\n","\n","    # Format as H:MM, safely skipping NaTs\n","    df['Duration_HM'] = df['Duration_HM'].apply(\n","        lambda x: f\"{int(x.total_seconds() // 3600)}:{int((x.total_seconds() % 3600) // 60):02d}\"\n","        if pd.notnull(x) else None\n","    )\n","\n","    #add separate start/end date and time\n","    # Clean column names first\n","    df.columns = df.columns.str.strip()\n","    # Convert to datetime only once\n","    df['StartTime'] = pd.to_datetime(df['StartTime'], utc=True, errors='coerce')\n","    df['Completed at'] = pd.to_datetime(df['Completed at'], utc=True, errors='coerce')\n","    # Split into date and time\n","    df['UTC_start_date'] = df['StartTime'].dt.date\n","    df['UTC_start_time'] = df['StartTime'].dt.strftime('%H:%M:%S')  # avoids microseconds\n","    df['UTC_completed_date'] = df['Completed at'].dt.date\n","    df['UTC_completed_time'] = df['Completed at'].dt.strftime('%H:%M:%S')\n","\n","    #compute local start and end time\n","    # Apply conversion\n","    df[['LocalStartTimestamp', 'LocalEndTimestamp','TimeZone']] = df.apply(\n","        lambda row: pd.Series(convert_times_with_timezone(\n","            pd.to_datetime(row[\"StartTime\"]),\n","            pd.to_datetime(row[\"Completed at\"]),\n","            pd.to_numeric(row[\"LocationLatitude\"]),\n","            pd.to_numeric(row[\"LocationLongitude\"])\n","        )),\n","        axis=1\n","    )\n","\n","    # Split into date and time\n","    df['local_start_date'] = df['LocalStartTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_start_time'] = df['LocalStartTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    df['local_end_date'] = df['LocalEndTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_end_time'] = df['LocalEndTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    # Define column order: your key columns first, then the rest\n","    preferred_order = ['Subject_ID', 'UTC_start_time','TimeZone','local_start_time','Duration', 'Duration_HM','local_end_time']\n","    other_columns = [col for col in df.columns if col not in preferred_order]\n","    all_columns = preferred_order + other_columns\n","\n","    # Reorder columns and save\n","    scored_data = df[all_columns].copy()\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data\n"],"metadata":{"id":"cD_gR1so_OhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["overview_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Overview.csv'\n","scored_overview_data = score_overview(s1_prolific_combined_df, overview_path)\n","scored_overview_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"WCEDVsrKJUXW","executionInfo":{"status":"ok","timestamp":1760028211677,"user_tz":240,"elapsed":2239,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"d325fb52-7198-44e0-e3a5-6314e429a075"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          Subject_ID UTC_start_time  \\\n","0  be53040ff6aad99b863cf7f3f8e50d29f416b4606a4536...       16:00:38   \n","1  d4d9418fb0eec5ce257fe190e797a78dc5d034baded6a7...       16:01:08   \n","2  84eaf750fa9c82ffc49185677a168b1ade690ee1946d40...       16:02:47   \n","3  d5bbb37b5a8d78d00749e85f10df5feb5769db24342eb2...       16:07:55   \n","4  b4ed0383c0d4839b014cdf9ddf0f68197919709e5b6805...       16:05:36   \n","\n","           TimeZone local_start_time  Duration Duration_HM local_end_time  \\\n","0   America/Chicago         11:00:38    4165.0        1:09       12:10:02   \n","1  America/New_York         12:01:08    3717.0        1:01       13:03:04   \n","2  America/New_York         12:02:47    5042.0        1:24       13:26:48   \n","3   America/Chicago         11:07:55    2423.0        0:40       11:48:18   \n","4   America/Chicago         11:05:36    2637.0        0:43       11:49:32   \n","\n","              Submission id    Status Custom study tncs accepted at  \\\n","0  6622951a094ac4f560513eef  APPROVED                Not Applicable   \n","1  6622953cc6838027d30c66a2  APPROVED                Not Applicable   \n","2  662295961c2b637cfaffd40e  APPROVED                Not Applicable   \n","3  66229610df4c42742ec29049  APPROVED                Not Applicable   \n","4  662296495b6d8c6ae1391297  APPROVED                Not Applicable   \n","\n","                         StartTime                     Completed at  \\\n","0 2024-04-19 16:00:38.804000+00:00 2024-04-19 17:10:02.980000+00:00   \n","1 2024-04-19 16:01:08.048000+00:00 2024-04-19 17:03:04.462000+00:00   \n","2 2024-04-19 16:02:47.071000+00:00 2024-04-19 17:26:48.547000+00:00   \n","3 2024-04-19 16:07:55.521000+00:00 2024-04-19 16:48:18.136000+00:00   \n","4 2024-04-19 16:05:36.187000+00:00 2024-04-19 16:49:32.216000+00:00   \n","\n","                   Reviewed at                  Archived at Completion code  \\\n","0  2024-04-20T19:48:07.203000Z  2024-04-19T17:10:03.887204Z        CPWVVLXI   \n","1  2024-04-20T19:48:50.229000Z  2024-04-19T17:03:45.965762Z        CPWVVLXI   \n","2  2024-04-20T19:48:51.402000Z  2024-04-19T17:28:10.459274Z        CPWVVLXI   \n","3  2024-04-20T19:48:53.344000Z  2024-04-19T16:48:19.530952Z        CPWVVLXI   \n","4  2024-04-20T19:48:52.336000Z  2024-04-19T16:49:41.079800Z        CPWVVLXI   \n","\n","   Total approvals Age     Sex Ethnicity simplified Country of birth  \\\n","0              305  24  Female                Asian    United States   \n","1              297  63    Male                Black    United States   \n","2             4079  38    Male                White    United States   \n","3             1693  33    Male                White    United States   \n","4              116  25  Female                Black    United States   \n","\n","  Country of residence    Nationality Language Student status  \\\n","0        United States  United States  English             No   \n","1        United States  United States  English            Yes   \n","2        United States  United States  English   DATA_EXPIRED   \n","3        United States  United States  English   DATA_EXPIRED   \n","4        United States  United States  English            Yes   \n","\n","  Employment status LocationLatitude LocationLongitude UTC_start_date  \\\n","0         Part-Time          37.6257          -97.3142     2024-04-19   \n","1         Full-Time          39.7954          -86.2658     2024-04-19   \n","2      DATA_EXPIRED          40.7575          -74.9967     2024-04-19   \n","3      DATA_EXPIRED          41.5883          -87.4593     2024-04-19   \n","4         Full-Time          41.7124          -87.7478     2024-04-19   \n","\n","  UTC_completed_date UTC_completed_time               LocalStartTimestamp  \\\n","0         2024-04-19           17:10:02  2024-04-19 11:00:38.804000-05:00   \n","1         2024-04-19           17:03:04  2024-04-19 12:01:08.048000-04:00   \n","2         2024-04-19           17:26:48  2024-04-19 12:02:47.071000-04:00   \n","3         2024-04-19           16:48:18  2024-04-19 11:07:55.521000-05:00   \n","4         2024-04-19           16:49:32  2024-04-19 11:05:36.187000-05:00   \n","\n","                  LocalEndTimestamp local_start_date local_end_date  \n","0  2024-04-19 12:10:02.980000-05:00       2024-04-19     2024-04-19  \n","1  2024-04-19 13:03:04.462000-04:00       2024-04-19     2024-04-19  \n","2  2024-04-19 13:26:48.547000-04:00       2024-04-19     2024-04-19  \n","3  2024-04-19 11:48:18.136000-05:00       2024-04-19     2024-04-19  \n","4  2024-04-19 11:49:32.216000-05:00       2024-04-19     2024-04-19  "],"text/html":["\n","  <div id=\"df-5ef8e861-063c-4b55-9a21-1213e52313c8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject_ID</th>\n","      <th>UTC_start_time</th>\n","      <th>TimeZone</th>\n","      <th>local_start_time</th>\n","      <th>Duration</th>\n","      <th>Duration_HM</th>\n","      <th>local_end_time</th>\n","      <th>Submission id</th>\n","      <th>Status</th>\n","      <th>Custom study tncs accepted at</th>\n","      <th>StartTime</th>\n","      <th>Completed at</th>\n","      <th>Reviewed at</th>\n","      <th>Archived at</th>\n","      <th>Completion code</th>\n","      <th>Total approvals</th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>Ethnicity simplified</th>\n","      <th>Country of birth</th>\n","      <th>Country of residence</th>\n","      <th>Nationality</th>\n","      <th>Language</th>\n","      <th>Student status</th>\n","      <th>Employment status</th>\n","      <th>LocationLatitude</th>\n","      <th>LocationLongitude</th>\n","      <th>UTC_start_date</th>\n","      <th>UTC_completed_date</th>\n","      <th>UTC_completed_time</th>\n","      <th>LocalStartTimestamp</th>\n","      <th>LocalEndTimestamp</th>\n","      <th>local_start_date</th>\n","      <th>local_end_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>be53040ff6aad99b863cf7f3f8e50d29f416b4606a4536...</td>\n","      <td>16:00:38</td>\n","      <td>America/Chicago</td>\n","      <td>11:00:38</td>\n","      <td>4165.0</td>\n","      <td>1:09</td>\n","      <td>12:10:02</td>\n","      <td>6622951a094ac4f560513eef</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-04-19 16:00:38.804000+00:00</td>\n","      <td>2024-04-19 17:10:02.980000+00:00</td>\n","      <td>2024-04-20T19:48:07.203000Z</td>\n","      <td>2024-04-19T17:10:03.887204Z</td>\n","      <td>CPWVVLXI</td>\n","      <td>305</td>\n","      <td>24</td>\n","      <td>Female</td>\n","      <td>Asian</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Part-Time</td>\n","      <td>37.6257</td>\n","      <td>-97.3142</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","      <td>17:10:02</td>\n","      <td>2024-04-19 11:00:38.804000-05:00</td>\n","      <td>2024-04-19 12:10:02.980000-05:00</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d4d9418fb0eec5ce257fe190e797a78dc5d034baded6a7...</td>\n","      <td>16:01:08</td>\n","      <td>America/New_York</td>\n","      <td>12:01:08</td>\n","      <td>3717.0</td>\n","      <td>1:01</td>\n","      <td>13:03:04</td>\n","      <td>6622953cc6838027d30c66a2</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-04-19 16:01:08.048000+00:00</td>\n","      <td>2024-04-19 17:03:04.462000+00:00</td>\n","      <td>2024-04-20T19:48:50.229000Z</td>\n","      <td>2024-04-19T17:03:45.965762Z</td>\n","      <td>CPWVVLXI</td>\n","      <td>297</td>\n","      <td>63</td>\n","      <td>Male</td>\n","      <td>Black</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>Yes</td>\n","      <td>Full-Time</td>\n","      <td>39.7954</td>\n","      <td>-86.2658</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","      <td>17:03:04</td>\n","      <td>2024-04-19 12:01:08.048000-04:00</td>\n","      <td>2024-04-19 13:03:04.462000-04:00</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84eaf750fa9c82ffc49185677a168b1ade690ee1946d40...</td>\n","      <td>16:02:47</td>\n","      <td>America/New_York</td>\n","      <td>12:02:47</td>\n","      <td>5042.0</td>\n","      <td>1:24</td>\n","      <td>13:26:48</td>\n","      <td>662295961c2b637cfaffd40e</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-04-19 16:02:47.071000+00:00</td>\n","      <td>2024-04-19 17:26:48.547000+00:00</td>\n","      <td>2024-04-20T19:48:51.402000Z</td>\n","      <td>2024-04-19T17:28:10.459274Z</td>\n","      <td>CPWVVLXI</td>\n","      <td>4079</td>\n","      <td>38</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>40.7575</td>\n","      <td>-74.9967</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","      <td>17:26:48</td>\n","      <td>2024-04-19 12:02:47.071000-04:00</td>\n","      <td>2024-04-19 13:26:48.547000-04:00</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d5bbb37b5a8d78d00749e85f10df5feb5769db24342eb2...</td>\n","      <td>16:07:55</td>\n","      <td>America/Chicago</td>\n","      <td>11:07:55</td>\n","      <td>2423.0</td>\n","      <td>0:40</td>\n","      <td>11:48:18</td>\n","      <td>66229610df4c42742ec29049</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-04-19 16:07:55.521000+00:00</td>\n","      <td>2024-04-19 16:48:18.136000+00:00</td>\n","      <td>2024-04-20T19:48:53.344000Z</td>\n","      <td>2024-04-19T16:48:19.530952Z</td>\n","      <td>CPWVVLXI</td>\n","      <td>1693</td>\n","      <td>33</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>41.5883</td>\n","      <td>-87.4593</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","      <td>16:48:18</td>\n","      <td>2024-04-19 11:07:55.521000-05:00</td>\n","      <td>2024-04-19 11:48:18.136000-05:00</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b4ed0383c0d4839b014cdf9ddf0f68197919709e5b6805...</td>\n","      <td>16:05:36</td>\n","      <td>America/Chicago</td>\n","      <td>11:05:36</td>\n","      <td>2637.0</td>\n","      <td>0:43</td>\n","      <td>11:49:32</td>\n","      <td>662296495b6d8c6ae1391297</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-04-19 16:05:36.187000+00:00</td>\n","      <td>2024-04-19 16:49:32.216000+00:00</td>\n","      <td>2024-04-20T19:48:52.336000Z</td>\n","      <td>2024-04-19T16:49:41.079800Z</td>\n","      <td>CPWVVLXI</td>\n","      <td>116</td>\n","      <td>25</td>\n","      <td>Female</td>\n","      <td>Black</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>Yes</td>\n","      <td>Full-Time</td>\n","      <td>41.7124</td>\n","      <td>-87.7478</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","      <td>16:49:32</td>\n","      <td>2024-04-19 11:05:36.187000-05:00</td>\n","      <td>2024-04-19 11:49:32.216000-05:00</td>\n","      <td>2024-04-19</td>\n","      <td>2024-04-19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ef8e861-063c-4b55-9a21-1213e52313c8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5ef8e861-063c-4b55-9a21-1213e52313c8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5ef8e861-063c-4b55-9a21-1213e52313c8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-e0ec4fce-2ac3-4277-8001-b0a388e9f086\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0ec4fce-2ac3-4277-8001-b0a388e9f086')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-e0ec4fce-2ac3-4277-8001-b0a388e9f086 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"scored_overview_data"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Session 2 Overview"],"metadata":{"id":"rCg2rxiJhbUx"}},{"cell_type":"code","source":["# Prolific S2 Overview\n","def score_overview_s2(df, path):\n","    column_mapping = {\n","        'Participant id': 'Subject_ID',\n","        'Started at': 'StartTime',\n","        'Time taken': 'Duration'\n","    }\n","\n","    df.rename(columns=column_mapping, inplace=True)\n","    df['Subject_ID'] = df['Subject_ID'].apply(hash_id)\n","\n","    # Convert seconds to timedelta (NaNs will become NaT)\n","    df['Duration_HM'] = pd.to_timedelta(df['Duration'], unit='s')\n","\n","    # Format as H:MM, safely skipping NaTs\n","    df['Duration_HM'] = df['Duration_HM'].apply(\n","        lambda x: f\"{int(x.total_seconds() // 3600)}:{int((x.total_seconds() % 3600) // 60):02d}\"\n","        if pd.notnull(x) else None\n","    )\n","    #add separate start/end date and time\n","    # Clean column names first\n","    df.columns = df.columns.str.strip()\n","\n","    # Convert to datetime only once\n","    df['StartTime'] = pd.to_datetime(df['StartTime'], utc=True, errors='coerce')\n","    df['Completed at'] = pd.to_datetime(df['Completed at'], utc=True, errors='coerce')\n","    # Split into date and time\n","    df['UTC_start_date'] = df['StartTime'].dt.date\n","    df['UTC_start_time'] = df['StartTime'].dt.strftime('%H:%M:%S')  # avoids microseconds\n","    df['UTC_completed_date'] = df['Completed at'].dt.date\n","    df['UTC_completed_time'] = df['Completed at'].dt.strftime('%H:%M:%S')\n","\n","    #compute local start and end time\n","    df[['LocalStartTimestamp', 'LocalEndTimestamp','TimeZone']] = df.apply(\n","        lambda row: pd.Series(convert_times_with_timezone(\n","            pd.to_datetime(row[\"StartTime\"]),\n","            pd.to_datetime(row[\"Completed at\"]),\n","            pd.to_numeric(row[\"LocationLatitude\"]),\n","            pd.to_numeric(row[\"LocationLongitude\"])\n","        )),\n","        axis=1\n","    )\n","\n","    # Split into date and time\n","    df['local_start_date'] = df['LocalStartTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_start_time'] = df['LocalStartTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    df['local_end_date'] = df['LocalEndTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_end_time'] = df['LocalEndTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    # Define column order: your key columns first, then the rest\n","    preferred_order = ['Subject_ID', 'UTC_start_time','TimeZone','local_start_time','Duration', 'Duration_HM','local_end_time']\n","    other_columns = [col for col in df.columns if col not in preferred_order]\n","    all_columns = preferred_order + other_columns\n","\n","    # Reorder columns and save\n","    scored_data = df[all_columns].copy()\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data\n"],"metadata":{"id":"tSM9Varyha_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["overview_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_s2_scored_Overview.csv'\n","scored_s2_overview_data = score_overview_s2(s2_prolific_data, overview_s2_path)\n","scored_s2_overview_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"GUX0GYxyP5nZ","executionInfo":{"status":"ok","timestamp":1760028213409,"user_tz":240,"elapsed":1729,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"051b2afe-8c7d-437f-bf0f-e08e8128f4c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          Subject_ID UTC_start_time  \\\n","0  5491be349322a63b7c89117da4ee0faf02286c5fd842f5...       19:29:03   \n","1  e669610ef97f0ca9ba5d806965f18112ffd0414d305067...       20:08:18   \n","2  16d2a19f9de26f3a1edb80ad8955cdee1e2e3064de06d8...       20:24:28   \n","3  f1243d85b295b6a732788259818b41a7fb85648984e109...       23:55:25   \n","4  cfa469757fbf745cab8d15526dae40b11ab7c74ea96f3d...       19:03:46   \n","\n","              TimeZone local_start_time  Duration Duration_HM local_end_time  \\\n","0     America/New_York         15:29:03    2137.0        0:35       16:04:39   \n","1     America/New_York         16:08:18    1974.0        0:32       16:41:12   \n","2  America/Los_Angeles         13:24:28    2211.0        0:36       14:01:19   \n","3     America/New_York         19:55:25    1481.0        0:24       20:20:05   \n","4     America/New_York         15:03:46    2427.0        0:40       15:44:12   \n","\n","              Submission id    Status Custom study tncs accepted at  \\\n","0  66b127ee588fe37bc50c59ac  APPROVED                Not Applicable   \n","1  66b130eb36d7af3e0a84884b  APPROVED                Not Applicable   \n","2  66b134ea5d20af4031b61fc9  APPROVED                Not Applicable   \n","3  66b1665ecb0528d8b87923aa  APPROVED                Not Applicable   \n","4  66b27392575c0244aa82461d  APPROVED                Not Applicable   \n","\n","                         StartTime                     Completed at  \\\n","0 2024-08-05 19:29:03.395000+00:00 2024-08-05 20:04:39.618000+00:00   \n","1 2024-08-05 20:08:18.933000+00:00 2024-08-05 20:41:12.748000+00:00   \n","2 2024-08-05 20:24:28.165000+00:00 2024-08-05 21:01:19.045000+00:00   \n","3 2024-08-05 23:55:25.303000+00:00 2024-08-06 00:20:05.489000+00:00   \n","4 2024-08-06 19:03:46.102000+00:00 2024-08-06 19:44:12.268000+00:00   \n","\n","                   Reviewed at                  Archived at Completion code  \\\n","0  2024-08-13T19:02:18.622000Z  2024-08-05T20:04:41.477747Z        C155IWZT   \n","1  2024-08-13T19:02:19.284000Z  2024-08-05T20:41:13.369588Z        C155IWZT   \n","2  2024-08-13T19:02:19.703000Z  2024-08-05T21:01:19.583453Z        C155IWZT   \n","3  2024-08-13T19:02:19.996000Z  2024-08-06T00:21:01.175010Z        C155IWZT   \n","4  2024-08-13T19:02:20.323000Z  2024-08-06T19:44:12.888845Z        C155IWZT   \n","\n","   Total approvals Age     Sex Ethnicity simplified Country of birth  \\\n","0              619  41  Female                White   United Kingdom   \n","1             1554  23  Female                Mixed    United States   \n","2             2468  32    Male                White    United States   \n","3             1769  32    Male                White    United States   \n","4             3831  64  Female                White    United States   \n","\n","  Country of residence    Nationality Language Student status  \\\n","0        United States  United States  English             No   \n","1        United States  United States  English             No   \n","2        United States  United States  English   DATA_EXPIRED   \n","3        United States  United States  English   DATA_EXPIRED   \n","4        United States  United States  English             No   \n","\n","              Employment status LocationLatitude LocationLongitude  \\\n","0                     Part-Time          27.2636          -82.5171   \n","1                     Full-Time          42.1043          -71.6549   \n","2                  DATA_EXPIRED          45.5375         -122.5989   \n","3                  DATA_EXPIRED           40.782          -73.9953   \n","4  Unemployed (and job seeking)          28.6529          -81.2106   \n","\n","  UTC_start_date UTC_completed_date UTC_completed_time  \\\n","0     2024-08-05         2024-08-05           20:04:39   \n","1     2024-08-05         2024-08-05           20:41:12   \n","2     2024-08-05         2024-08-05           21:01:19   \n","3     2024-08-05         2024-08-06           00:20:05   \n","4     2024-08-06         2024-08-06           19:44:12   \n","\n","                LocalStartTimestamp                 LocalEndTimestamp  \\\n","0  2024-08-05 15:29:03.395000-04:00  2024-08-05 16:04:39.618000-04:00   \n","1  2024-08-05 16:08:18.933000-04:00  2024-08-05 16:41:12.748000-04:00   \n","2  2024-08-05 13:24:28.165000-07:00  2024-08-05 14:01:19.045000-07:00   \n","3  2024-08-05 19:55:25.303000-04:00  2024-08-05 20:20:05.489000-04:00   \n","4  2024-08-06 15:03:46.102000-04:00  2024-08-06 15:44:12.268000-04:00   \n","\n","  local_start_date local_end_date  \n","0       2024-08-05     2024-08-05  \n","1       2024-08-05     2024-08-05  \n","2       2024-08-05     2024-08-05  \n","3       2024-08-05     2024-08-05  \n","4       2024-08-06     2024-08-06  "],"text/html":["\n","  <div id=\"df-03921dbe-ad76-4cd5-9361-90f11be3a895\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject_ID</th>\n","      <th>UTC_start_time</th>\n","      <th>TimeZone</th>\n","      <th>local_start_time</th>\n","      <th>Duration</th>\n","      <th>Duration_HM</th>\n","      <th>local_end_time</th>\n","      <th>Submission id</th>\n","      <th>Status</th>\n","      <th>Custom study tncs accepted at</th>\n","      <th>StartTime</th>\n","      <th>Completed at</th>\n","      <th>Reviewed at</th>\n","      <th>Archived at</th>\n","      <th>Completion code</th>\n","      <th>Total approvals</th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>Ethnicity simplified</th>\n","      <th>Country of birth</th>\n","      <th>Country of residence</th>\n","      <th>Nationality</th>\n","      <th>Language</th>\n","      <th>Student status</th>\n","      <th>Employment status</th>\n","      <th>LocationLatitude</th>\n","      <th>LocationLongitude</th>\n","      <th>UTC_start_date</th>\n","      <th>UTC_completed_date</th>\n","      <th>UTC_completed_time</th>\n","      <th>LocalStartTimestamp</th>\n","      <th>LocalEndTimestamp</th>\n","      <th>local_start_date</th>\n","      <th>local_end_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5491be349322a63b7c89117da4ee0faf02286c5fd842f5...</td>\n","      <td>19:29:03</td>\n","      <td>America/New_York</td>\n","      <td>15:29:03</td>\n","      <td>2137.0</td>\n","      <td>0:35</td>\n","      <td>16:04:39</td>\n","      <td>66b127ee588fe37bc50c59ac</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-08-05 19:29:03.395000+00:00</td>\n","      <td>2024-08-05 20:04:39.618000+00:00</td>\n","      <td>2024-08-13T19:02:18.622000Z</td>\n","      <td>2024-08-05T20:04:41.477747Z</td>\n","      <td>C155IWZT</td>\n","      <td>619</td>\n","      <td>41</td>\n","      <td>Female</td>\n","      <td>White</td>\n","      <td>United Kingdom</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Part-Time</td>\n","      <td>27.2636</td>\n","      <td>-82.5171</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","      <td>20:04:39</td>\n","      <td>2024-08-05 15:29:03.395000-04:00</td>\n","      <td>2024-08-05 16:04:39.618000-04:00</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>e669610ef97f0ca9ba5d806965f18112ffd0414d305067...</td>\n","      <td>20:08:18</td>\n","      <td>America/New_York</td>\n","      <td>16:08:18</td>\n","      <td>1974.0</td>\n","      <td>0:32</td>\n","      <td>16:41:12</td>\n","      <td>66b130eb36d7af3e0a84884b</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-08-05 20:08:18.933000+00:00</td>\n","      <td>2024-08-05 20:41:12.748000+00:00</td>\n","      <td>2024-08-13T19:02:19.284000Z</td>\n","      <td>2024-08-05T20:41:13.369588Z</td>\n","      <td>C155IWZT</td>\n","      <td>1554</td>\n","      <td>23</td>\n","      <td>Female</td>\n","      <td>Mixed</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Full-Time</td>\n","      <td>42.1043</td>\n","      <td>-71.6549</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","      <td>20:41:12</td>\n","      <td>2024-08-05 16:08:18.933000-04:00</td>\n","      <td>2024-08-05 16:41:12.748000-04:00</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16d2a19f9de26f3a1edb80ad8955cdee1e2e3064de06d8...</td>\n","      <td>20:24:28</td>\n","      <td>America/Los_Angeles</td>\n","      <td>13:24:28</td>\n","      <td>2211.0</td>\n","      <td>0:36</td>\n","      <td>14:01:19</td>\n","      <td>66b134ea5d20af4031b61fc9</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-08-05 20:24:28.165000+00:00</td>\n","      <td>2024-08-05 21:01:19.045000+00:00</td>\n","      <td>2024-08-13T19:02:19.703000Z</td>\n","      <td>2024-08-05T21:01:19.583453Z</td>\n","      <td>C155IWZT</td>\n","      <td>2468</td>\n","      <td>32</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>45.5375</td>\n","      <td>-122.5989</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","      <td>21:01:19</td>\n","      <td>2024-08-05 13:24:28.165000-07:00</td>\n","      <td>2024-08-05 14:01:19.045000-07:00</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>f1243d85b295b6a732788259818b41a7fb85648984e109...</td>\n","      <td>23:55:25</td>\n","      <td>America/New_York</td>\n","      <td>19:55:25</td>\n","      <td>1481.0</td>\n","      <td>0:24</td>\n","      <td>20:20:05</td>\n","      <td>66b1665ecb0528d8b87923aa</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-08-05 23:55:25.303000+00:00</td>\n","      <td>2024-08-06 00:20:05.489000+00:00</td>\n","      <td>2024-08-13T19:02:19.996000Z</td>\n","      <td>2024-08-06T00:21:01.175010Z</td>\n","      <td>C155IWZT</td>\n","      <td>1769</td>\n","      <td>32</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>40.782</td>\n","      <td>-73.9953</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-06</td>\n","      <td>00:20:05</td>\n","      <td>2024-08-05 19:55:25.303000-04:00</td>\n","      <td>2024-08-05 20:20:05.489000-04:00</td>\n","      <td>2024-08-05</td>\n","      <td>2024-08-05</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cfa469757fbf745cab8d15526dae40b11ab7c74ea96f3d...</td>\n","      <td>19:03:46</td>\n","      <td>America/New_York</td>\n","      <td>15:03:46</td>\n","      <td>2427.0</td>\n","      <td>0:40</td>\n","      <td>15:44:12</td>\n","      <td>66b27392575c0244aa82461d</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2024-08-06 19:03:46.102000+00:00</td>\n","      <td>2024-08-06 19:44:12.268000+00:00</td>\n","      <td>2024-08-13T19:02:20.323000Z</td>\n","      <td>2024-08-06T19:44:12.888845Z</td>\n","      <td>C155IWZT</td>\n","      <td>3831</td>\n","      <td>64</td>\n","      <td>Female</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Unemployed (and job seeking)</td>\n","      <td>28.6529</td>\n","      <td>-81.2106</td>\n","      <td>2024-08-06</td>\n","      <td>2024-08-06</td>\n","      <td>19:44:12</td>\n","      <td>2024-08-06 15:03:46.102000-04:00</td>\n","      <td>2024-08-06 15:44:12.268000-04:00</td>\n","      <td>2024-08-06</td>\n","      <td>2024-08-06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03921dbe-ad76-4cd5-9361-90f11be3a895')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03921dbe-ad76-4cd5-9361-90f11be3a895 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03921dbe-ad76-4cd5-9361-90f11be3a895');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-db70f1d5-eece-4143-b1e2-c978f46f6368\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db70f1d5-eece-4143-b1e2-c978f46f6368')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-db70f1d5-eece-4143-b1e2-c978f46f6368 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"scored_s2_overview_data"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Session 3 Overview"],"metadata":{"id":"Jhb8dmYKloL6"}},{"cell_type":"code","source":["# Prolific S3 Overview\n","def score_overview_s3(df, path):\n","    column_mapping = {\n","        'Participant id': 'Subject_ID',\n","        'Started at': 'StartTime',\n","        'Time taken': 'Duration'\n","    }\n","\n","    df.rename(columns=column_mapping, inplace=True)\n","    df['Subject_ID'] = df['Subject_ID'].apply(hash_id)\n","\n","    # Convert seconds to timedelta (NaNs will become NaT)\n","    df['Duration_HM'] = pd.to_timedelta(df['Duration'], unit='s')\n","\n","    # Format as H:MM, safely skipping NaTs\n","    df['Duration_HM'] = df['Duration_HM'].apply(\n","        lambda x: f\"{int(x.total_seconds() // 3600)}:{int((x.total_seconds() % 3600) // 60):02d}\"\n","        if pd.notnull(x) else None\n","    )\n","    #add separate start/end date and time\n","    # Clean column names first\n","    df.columns = df.columns.str.strip()\n","\n","    # Convert to datetime only once\n","    df['StartTime'] = pd.to_datetime(df['StartTime'], utc=True, errors='coerce')\n","    df['Completed at'] = pd.to_datetime(df['Completed at'], utc=True, errors='coerce')\n","    # Split into date and time\n","    df['UTC_start_date'] = df['StartTime'].dt.date\n","    df['UTC_start_time'] = df['StartTime'].dt.strftime('%H:%M:%S')  # avoids microseconds\n","    df['UTC_completed_date'] = df['Completed at'].dt.date\n","    df['UTC_completed_time'] = df['Completed at'].dt.strftime('%H:%M:%S')\n","\n","    #compute local start and end time\n","    df[['LocalStartTimestamp', 'LocalEndTimestamp','TimeZone']] = df.apply(\n","        lambda row: pd.Series(convert_times_with_timezone(\n","            pd.to_datetime(row[\"StartTime\"]),\n","            pd.to_datetime(row[\"Completed at\"]),\n","            pd.to_numeric(row[\"LocationLatitude\"]),\n","            pd.to_numeric(row[\"LocationLongitude\"])\n","        )),\n","        axis=1\n","    )\n","\n","    # Split into date and time\n","    df['local_start_date'] = df['LocalStartTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_start_time'] = df['LocalStartTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    df['local_end_date'] = df['LocalEndTimestamp'].apply(lambda x: x.date() if pd.notna(x) else None)\n","    df['local_end_time'] = df['LocalEndTimestamp'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notna(x) else None)\n","\n","    # Define column order: your key columns first, then the rest\n","    preferred_order = ['Subject_ID', 'UTC_start_time','TimeZone','local_start_time','Duration', 'Duration_HM','local_end_time']\n","    other_columns = [col for col in df.columns if col not in preferred_order]\n","    all_columns = preferred_order + other_columns\n","\n","    # Reorder columns and save\n","    scored_data = df[all_columns].copy()\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data\n"],"metadata":{"id":"BqbGc9K6lqp2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["overview_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/s3_scored_Overview.csv'\n","scored_s3_overview_data = score_overview_s3(s3_prolific_data, overview_s3_path)\n","scored_s3_overview_data.head()"],"metadata":{"id":"95uat84smNTP","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"ok","timestamp":1760028214804,"user_tz":240,"elapsed":1303,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"a5d296f5-2b11-466c-aee8-469fc21dd82c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          Subject_ID UTC_start_time  \\\n","0  86fc1d8847013641c93cd55a837fa60d53bbc47cf9dd9e...       17:58:07   \n","1  5491be349322a63b7c89117da4ee0faf02286c5fd842f5...       18:14:39   \n","2  4cfed6385f23dfffce02e960dd35c1d841f3c8575c49f7...       18:17:20   \n","3  d34667864fcf10241fdc239a8ff71c13679fdff80ad5ec...       23:18:52   \n","4  16d2a19f9de26f3a1edb80ad8955cdee1e2e3064de06d8...       01:27:04   \n","\n","              TimeZone local_start_time  Duration Duration_HM local_end_time  \\\n","0      America/Chicago         12:58:07    4172.0        1:09       14:07:38   \n","1     America/New_York         14:14:39    2028.0        0:33       14:48:27   \n","2  America/Los_Angeles         11:17:20    1534.0        0:25       11:42:53   \n","3     America/New_York         19:18:52    1495.0        0:24       19:43:46   \n","4  America/Los_Angeles         18:27:04    5774.0        1:36       20:03:17   \n","\n","              Submission id    Status Custom study tncs accepted at  \\\n","0  67ec292f9c94fc1b07c69e89  APPROVED                Not Applicable   \n","1  67ec2d013a4e15c62893b5b4  APPROVED                Not Applicable   \n","2  67ec2d93a314c03478d66738  APPROVED                Not Applicable   \n","3  67ec7458081c3f989526eb05  APPROVED                Not Applicable   \n","4  67ec925d77dea5e0d024dd8d  APPROVED                Not Applicable   \n","\n","                         StartTime                     Completed at  \\\n","0 2025-04-01 17:58:07.012000+00:00 2025-04-01 19:07:38.128000+00:00   \n","1 2025-04-01 18:14:39.923000+00:00 2025-04-01 18:48:27.751000+00:00   \n","2 2025-04-01 18:17:20.203000+00:00 2025-04-01 18:42:53.218000+00:00   \n","3 2025-04-01 23:18:52.485000+00:00 2025-04-01 23:43:46.859000+00:00   \n","4 2025-04-02 01:27:04.895000+00:00 2025-04-02 03:03:17.963000+00:00   \n","\n","                   Reviewed at                  Archived at Completion code  \\\n","0  2025-04-07T21:06:26.181000Z  2025-04-01T19:07:39.520466Z        C155IWZT   \n","1  2025-04-07T21:06:26.701000Z  2025-04-01T18:48:28.419875Z        C155IWZT   \n","2  2025-04-07T21:06:27.053000Z  2025-04-01T18:42:54.682159Z        C155IWZT   \n","3  2025-04-07T21:06:27.385000Z  2025-04-01T23:43:47.661857Z        C155IWZT   \n","4  2025-04-07T21:06:27.708000Z  2025-04-02T03:03:18.725073Z        C155IWZT   \n","\n","   Total approvals Age     Sex Ethnicity simplified Country of birth  \\\n","0             2250  45    Male                White    United States   \n","1             1467  41  Female                White   United Kingdom   \n","2             2543  35  Female                Mixed     Saint Helena   \n","3             8271  38    Male                White    United States   \n","4             2992  32    Male                White    United States   \n","\n","  Country of residence    Nationality Language Student status  \\\n","0        United States  United States  English             No   \n","1        United States  United States  English   DATA_EXPIRED   \n","2        United States  United States  English             No   \n","3        United States  United States  English             No   \n","4        United States  United States  English   DATA_EXPIRED   \n","\n","                                   Employment status LocationLatitude  \\\n","0                       Unemployed (and job seeking)          32.9074   \n","1                                       DATA_EXPIRED          27.2636   \n","2  Not in paid work (e.g. homemaker', 'retired or...          35.4145   \n","3                                          Part-Time          26.1188   \n","4                                       DATA_EXPIRED          45.5136   \n","\n","  LocationLongitude UTC_start_date UTC_completed_date UTC_completed_time  \\\n","0          -97.4257     2025-04-01         2025-04-01           19:07:38   \n","1          -82.5171     2025-04-01         2025-04-01           18:48:27   \n","2         -119.0403     2025-04-01         2025-04-01           18:42:53   \n","3          -81.5215     2025-04-01         2025-04-01           23:43:46   \n","4         -122.5946     2025-04-02         2025-04-02           03:03:17   \n","\n","                LocalStartTimestamp                 LocalEndTimestamp  \\\n","0  2025-04-01 12:58:07.012000-05:00  2025-04-01 14:07:38.128000-05:00   \n","1  2025-04-01 14:14:39.923000-04:00  2025-04-01 14:48:27.751000-04:00   \n","2  2025-04-01 11:17:20.203000-07:00  2025-04-01 11:42:53.218000-07:00   \n","3  2025-04-01 19:18:52.485000-04:00  2025-04-01 19:43:46.859000-04:00   \n","4  2025-04-01 18:27:04.895000-07:00  2025-04-01 20:03:17.963000-07:00   \n","\n","  local_start_date local_end_date  \n","0       2025-04-01     2025-04-01  \n","1       2025-04-01     2025-04-01  \n","2       2025-04-01     2025-04-01  \n","3       2025-04-01     2025-04-01  \n","4       2025-04-01     2025-04-01  "],"text/html":["\n","  <div id=\"df-b78c7cc0-bf82-4f06-b475-a44302056b2b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject_ID</th>\n","      <th>UTC_start_time</th>\n","      <th>TimeZone</th>\n","      <th>local_start_time</th>\n","      <th>Duration</th>\n","      <th>Duration_HM</th>\n","      <th>local_end_time</th>\n","      <th>Submission id</th>\n","      <th>Status</th>\n","      <th>Custom study tncs accepted at</th>\n","      <th>StartTime</th>\n","      <th>Completed at</th>\n","      <th>Reviewed at</th>\n","      <th>Archived at</th>\n","      <th>Completion code</th>\n","      <th>Total approvals</th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>Ethnicity simplified</th>\n","      <th>Country of birth</th>\n","      <th>Country of residence</th>\n","      <th>Nationality</th>\n","      <th>Language</th>\n","      <th>Student status</th>\n","      <th>Employment status</th>\n","      <th>LocationLatitude</th>\n","      <th>LocationLongitude</th>\n","      <th>UTC_start_date</th>\n","      <th>UTC_completed_date</th>\n","      <th>UTC_completed_time</th>\n","      <th>LocalStartTimestamp</th>\n","      <th>LocalEndTimestamp</th>\n","      <th>local_start_date</th>\n","      <th>local_end_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>86fc1d8847013641c93cd55a837fa60d53bbc47cf9dd9e...</td>\n","      <td>17:58:07</td>\n","      <td>America/Chicago</td>\n","      <td>12:58:07</td>\n","      <td>4172.0</td>\n","      <td>1:09</td>\n","      <td>14:07:38</td>\n","      <td>67ec292f9c94fc1b07c69e89</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2025-04-01 17:58:07.012000+00:00</td>\n","      <td>2025-04-01 19:07:38.128000+00:00</td>\n","      <td>2025-04-07T21:06:26.181000Z</td>\n","      <td>2025-04-01T19:07:39.520466Z</td>\n","      <td>C155IWZT</td>\n","      <td>2250</td>\n","      <td>45</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Unemployed (and job seeking)</td>\n","      <td>32.9074</td>\n","      <td>-97.4257</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","      <td>19:07:38</td>\n","      <td>2025-04-01 12:58:07.012000-05:00</td>\n","      <td>2025-04-01 14:07:38.128000-05:00</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5491be349322a63b7c89117da4ee0faf02286c5fd842f5...</td>\n","      <td>18:14:39</td>\n","      <td>America/New_York</td>\n","      <td>14:14:39</td>\n","      <td>2028.0</td>\n","      <td>0:33</td>\n","      <td>14:48:27</td>\n","      <td>67ec2d013a4e15c62893b5b4</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2025-04-01 18:14:39.923000+00:00</td>\n","      <td>2025-04-01 18:48:27.751000+00:00</td>\n","      <td>2025-04-07T21:06:26.701000Z</td>\n","      <td>2025-04-01T18:48:28.419875Z</td>\n","      <td>C155IWZT</td>\n","      <td>1467</td>\n","      <td>41</td>\n","      <td>Female</td>\n","      <td>White</td>\n","      <td>United Kingdom</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>27.2636</td>\n","      <td>-82.5171</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","      <td>18:48:27</td>\n","      <td>2025-04-01 14:14:39.923000-04:00</td>\n","      <td>2025-04-01 14:48:27.751000-04:00</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4cfed6385f23dfffce02e960dd35c1d841f3c8575c49f7...</td>\n","      <td>18:17:20</td>\n","      <td>America/Los_Angeles</td>\n","      <td>11:17:20</td>\n","      <td>1534.0</td>\n","      <td>0:25</td>\n","      <td>11:42:53</td>\n","      <td>67ec2d93a314c03478d66738</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2025-04-01 18:17:20.203000+00:00</td>\n","      <td>2025-04-01 18:42:53.218000+00:00</td>\n","      <td>2025-04-07T21:06:27.053000Z</td>\n","      <td>2025-04-01T18:42:54.682159Z</td>\n","      <td>C155IWZT</td>\n","      <td>2543</td>\n","      <td>35</td>\n","      <td>Female</td>\n","      <td>Mixed</td>\n","      <td>Saint Helena</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Not in paid work (e.g. homemaker', 'retired or...</td>\n","      <td>35.4145</td>\n","      <td>-119.0403</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","      <td>18:42:53</td>\n","      <td>2025-04-01 11:17:20.203000-07:00</td>\n","      <td>2025-04-01 11:42:53.218000-07:00</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>d34667864fcf10241fdc239a8ff71c13679fdff80ad5ec...</td>\n","      <td>23:18:52</td>\n","      <td>America/New_York</td>\n","      <td>19:18:52</td>\n","      <td>1495.0</td>\n","      <td>0:24</td>\n","      <td>19:43:46</td>\n","      <td>67ec7458081c3f989526eb05</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2025-04-01 23:18:52.485000+00:00</td>\n","      <td>2025-04-01 23:43:46.859000+00:00</td>\n","      <td>2025-04-07T21:06:27.385000Z</td>\n","      <td>2025-04-01T23:43:47.661857Z</td>\n","      <td>C155IWZT</td>\n","      <td>8271</td>\n","      <td>38</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>No</td>\n","      <td>Part-Time</td>\n","      <td>26.1188</td>\n","      <td>-81.5215</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","      <td>23:43:46</td>\n","      <td>2025-04-01 19:18:52.485000-04:00</td>\n","      <td>2025-04-01 19:43:46.859000-04:00</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16d2a19f9de26f3a1edb80ad8955cdee1e2e3064de06d8...</td>\n","      <td>01:27:04</td>\n","      <td>America/Los_Angeles</td>\n","      <td>18:27:04</td>\n","      <td>5774.0</td>\n","      <td>1:36</td>\n","      <td>20:03:17</td>\n","      <td>67ec925d77dea5e0d024dd8d</td>\n","      <td>APPROVED</td>\n","      <td>Not Applicable</td>\n","      <td>2025-04-02 01:27:04.895000+00:00</td>\n","      <td>2025-04-02 03:03:17.963000+00:00</td>\n","      <td>2025-04-07T21:06:27.708000Z</td>\n","      <td>2025-04-02T03:03:18.725073Z</td>\n","      <td>C155IWZT</td>\n","      <td>2992</td>\n","      <td>32</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>United States</td>\n","      <td>English</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>DATA_EXPIRED</td>\n","      <td>45.5136</td>\n","      <td>-122.5946</td>\n","      <td>2025-04-02</td>\n","      <td>2025-04-02</td>\n","      <td>03:03:17</td>\n","      <td>2025-04-01 18:27:04.895000-07:00</td>\n","      <td>2025-04-01 20:03:17.963000-07:00</td>\n","      <td>2025-04-01</td>\n","      <td>2025-04-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78c7cc0-bf82-4f06-b475-a44302056b2b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b78c7cc0-bf82-4f06-b475-a44302056b2b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b78c7cc0-bf82-4f06-b475-a44302056b2b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-8a346873-9c5e-4e1a-8942-2e53ae21dba9\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a346873-9c5e-4e1a-8942-2e53ae21dba9')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-8a346873-9c5e-4e1a-8942-2e53ae21dba9 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"scored_s3_overview_data"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"l3mMaxWliwnW"},"source":["## AQ\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTfitoA1duPt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def score_aq(df, path):\n","    # helper to build item names\n","    def asq_column(i):\n","        return f'ASQ_{i}'\n","\n","    # 5 overall subscores\n","    default_subscales = {\n","        'AQ_Social_Skill':        [1,11,13,15,22,36,44,45,47,48],\n","        'AQ_Attention_Switching': [2, 4,10,16,25,32,34,37,43,46],\n","        'AQ_Attention_To_Detail': [5, 6, 9,12,19,23,28,29,30,49],\n","        'AQ_Communication':       [7,17,18,26,27,31,33,35,38,39],\n","        'AQ_Imagination':         [3, 8,14,20,21,24,40,41,42,50]\n","    }\n","\n","    # AQ-Short subscores\n","    asq_short_subscales = {\n","        'AQ_Short_Social_Skill':        [1,15,36,45,50],\n","        'AQ_Short_Routine':             [2,25,34,46],\n","        'AQ_Short_Switching':           [4,10,32,37],\n","        'AQ_Short_Imagination':         [3, 8,14,20,36,42,45,50],\n","        'AQ_Short_Numbers_and_Patterns':[6,9,19,23,41]\n","    }\n","\n","    # three-factor subscores\n","    three_factor_subscales = {\n","        'AQ_Three_Factor_Sociability':        [7,11,17,28,31,42,50],\n","        'AQ_Three_Factor_Mentalizing':        [2,15,23,29,30,32],\n","        'AQ_Three_Factor_Detail_Orientation': [3,5,12,25,26,33,38]\n","    }\n","\n","    # macro definitions\n","    macro_1_questions = [1,2,4,5,6,7,9,12,13,16,18,19,20,21,22,23,26,33,35,39,41,42,43,45,46]\n","    macro_2_questions = [3,8,10,11,14,15,17,24,25,27,28,29,30,31,32,34,36,37,38,40,44,47,48,49,50]\n","\n","    # score each ASQ_\n","    def apply_asq_macros(row):\n","        out = {}\n","        for i in macro_1_questions:\n","            out[asq_column(i)] = int(row[asq_column(i)] in [\"Definitely Agree\",\"Slightly Agree\"])\n","        for i in macro_2_questions:\n","            out[asq_column(i)] = int(row[asq_column(i)] in [\"Definitely Disagree\",\"Slightly Disagree\"])\n","        return pd.Series(out)\n","\n","    # subscale‐sum helper (min_count=1 → all‐NA = NaN)\n","    def calculate_subscale_scores(df_, subs):\n","        for name, qs in subs.items():\n","            cols = [asq_column(i) for i in qs]\n","            df_[name] = df_[cols].sum(axis=1, min_count=1)\n","\n","    # flags\n","    def flag_sparse_data(df_, qcols, min_ans=25):\n","        return df_[qcols].notna().sum(axis=1) < min_ans\n","    def flag_zero_std_data(df_, qcols):\n","        return df_[qcols].std(axis=1, skipna=True) == 0\n","\n","    # ---- begin scoring ----\n","\n","    # score the 50 items\n","    scored_data = df.apply(apply_asq_macros, axis=1)\n","\n","    # define the 50 columns\n","    question_columns = [asq_column(i) for i in range(1,51)]\n","\n","    # blank counts on *original* 50\n","    scored_data['Blank_Count']      = df[question_columns].isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / len(question_columns)\n","\n","    # flags\n","    scored_data['AQ_exclude_sparse']   = flag_sparse_data(scored_data, question_columns)\n","    scored_data['AQ_exclude_zero_std'] = flag_zero_std_data(scored_data, question_columns)\n","\n","    # blank out all 50 if excluded\n","    mask = scored_data['AQ_exclude_sparse'] | scored_data['AQ_exclude_zero_std']\n","    scored_data.loc[mask, question_columns] = np.nan\n","\n","    # compute all subscores\n","    calculate_subscale_scores(scored_data, default_subscales)\n","    calculate_subscale_scores(scored_data, asq_short_subscales)\n","    calculate_subscale_scores(scored_data, three_factor_subscales)\n","\n","    # classic total\n","    scored_data['AQ_Total_Score'] = scored_data[question_columns].sum(axis=1, min_count=1)\n","\n","    # SD of the 50 scored items\n","    scored_data['AQ_Item_SD'] = scored_data[question_columns].std(axis=1, skipna=True)\n","\n","    # short‐form total (sum of first four AQ-Short subs)\n","    short_parts = [\n","        'AQ_Short_Social_Skill',\n","        'AQ_Short_Routine',\n","        'AQ_Short_Switching',\n","        'AQ_Short_Imagination'\n","    ]\n","    scored_data['AQ_Short_Total_Score'] = scored_data[short_parts].sum(axis=1, min_count=1)\n","\n","    # bring in hashed ID\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # reorder exactly as requested\n","    classic_order = [\n","        'AQ_Imagination',\n","        'AQ_Attention_Switching',\n","        'AQ_Social_Skill',\n","        'AQ_Communication',\n","        'AQ_Attention_To_Detail',\n","        'AQ_Total_Score'\n","    ]\n","    three_order = list(three_factor_subscales.keys())\n","    short_order = [\n","        'AQ_Short_Social_Skill',\n","        'AQ_Short_Routine',\n","        'AQ_Short_Switching',\n","        'AQ_Short_Imagination',\n","        'AQ_Short_Total_Score',\n","        'AQ_Short_Numbers_and_Patterns'\n","    ]\n","\n","    final_cols = (\n","        ['Subject_ID']\n","      + question_columns\n","      + classic_order\n","      + three_order\n","      + short_order\n","      + ['AQ_Item_SD','Blank_Count','Blank_Percentage',\n","         'AQ_exclude_sparse','AQ_exclude_zero_std']\n","    )\n","    scored_data = scored_data[final_cols]\n","\n","    # build the 3-level header so you can see which are reversed\n","    metadata_texts = s1_metadata_row\n","\n","    level0 = scored_data.columns\n","    level1 = [metadata_texts[c] if c in metadata_texts.index else \"\"\n","              for c in level0]\n","    level2 = []\n","    for c in level0:\n","        if c.startswith(\"ASQ_\"):\n","            q = int(c.split(\"_\",1)[1])\n","            level2.append(\"Reversed\" if q in macro_2_questions else \"Normal\")\n","        else:\n","            level2.append(\"\")\n","\n","    scored_data.columns = pd.MultiIndex.from_tuples(\n","        list(zip(level0, level1, level2)),\n","        names=[\"Variable\",\"Label\",\"Scoring\"]\n","    )\n","\n","    # save and return\n","    scored_data.to_csv(path, index=False)\n","    return scored_data"]},{"cell_type":"markdown","metadata":{"id":"HaJupDX9i3Vf"},"source":["## BIS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmdvwtuhfPz-"},"outputs":[],"source":["# Barrett Impulsivity Scale\n","def score_bis(df, path):\n","\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"Rarely/Never\": 1,\n","        \"Occasionally\": 2,\n","        \"Often\": 3,\n","        \"Almost always/Always\": 4\n","    }\n","\n","    # Function to clean and map scores\n","    def map_scores(value):\n","        # Clean the string to remove leading/trailing whitespaces\n","        value = str(value).strip()\n","        # Return the mapped score or NaN if the value is not found\n","        return answer_scores.get(value, np.nan)\n","\n","    # Function to reverse score the BIS items\n","    def BIS_reverse_score(value):\n","        if pd.isna(value):\n","            return value  # Preserve NaN values\n","        return 5 - value\n","\n","    # Other commands to score the BIS survey\n","    bis_columns = [f'BIS_{i}' for i in range(1, 31)]\n","    n_items = len(bis_columns)\n","\n","    scored_data = df[bis_columns].copy()\n","\n","    # Apply mapping and cleaning\n","    scored_data = scored_data.applymap(map_scores)\n","\n","    # Apply reverse scoring\n","    reverse_scored_items = [1, 7, 8, 9, 10, 12, 13, 15, 20, 29, 30]\n","    reverse_columns = [f'BIS_{item}' for item in reverse_scored_items]\n","    scored_data[reverse_columns] = scored_data[reverse_columns].applymap(BIS_reverse_score)\n","\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Subscale item lists\n","    attentional_items   = ['BIS_5','BIS_6','BIS_9','BIS_11','BIS_20','BIS_24','BIS_26','BIS_28']\n","    motor_items         = ['BIS_2','BIS_3','BIS_4','BIS_16','BIS_17','BIS_19','BIS_21','BIS_22','BIS_23','BIS_25','BIS_30']\n","    nonplanning_items   = ['BIS_2','BIS_7','BIS_8','BIS_10','BIS_12','BIS_13','BIS_14','BIS_15','BIS_18','BIS_27','BIS_29']\n","\n","    # Conditional-sum helper\n","    def cond_sum(row, items):\n","        return row[items].sum() if row['Blank_Count'] <= n_items/2 else np.nan\n","\n","    # Compute subscales only if ≥ half answered\n","    scored_data['BIS_Attentional_Scores'] = scored_data.apply(lambda r: cond_sum(r, attentional_items), axis=1)\n","    scored_data['BIS_Motor_Scores']       = scored_data.apply(lambda r: cond_sum(r, motor_items), axis=1)\n","    scored_data['BIS_Nonplanning_Scores'] = scored_data.apply(lambda r: cond_sum(r, nonplanning_items), axis=1)\n","\n","    # Conditional final, SD, and questions-not-answered\n","    scored_data['BIS_Final_Score'] = scored_data.apply(\n","        lambda r: r[bis_columns].sum(min_count=1) if r['Blank_Count'] <= n_items/2 else np.nan,\n","        axis=1\n","    )\n","    scored_data['BIS_SD_of_Answers'] = scored_data.apply(\n","        lambda r: r[bis_columns].std() if r['Blank_Count'] <= n_items/2 else np.nan,\n","        axis=1\n","    )\n","    scored_data['BIS_Questions_Not_Answered'] = scored_data['Blank_Count']\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"iehtXP4LUgUc"},"source":["## Big Five Inventory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x08t5l0oUk20"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_bfi(df, path):\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"Disagree strongly\": 1,\n","        \"Disagree a little\": 2,\n","        \"Neither agree nor disagree\": 3,\n","        \"Agree a little\": 4,\n","        \"Agree strongly\": 5\n","    }\n","\n","    # Function to clean and map scores\n","    def map_scores(value):\n","        # Clean the string to remove leading/trailing whitespaces\n","        value = str(value).strip()\n","        # Return the mapped score or NaN if the value is not found\n","        return answer_scores.get(value, np.nan)\n","\n","    # Function to reverse score the BFI items\n","    def BFI_reverse_score(value):\n","        if pd.isna(value):\n","            return value  # Preserve NaN values\n","        return 6 - value\n","\n","    # List of BFI items\n","    bfi_columns = [f'BFI_{i}' for i in range(1, 45)]  # Adjust the range according to the number of items in BFI\n","    n_items = len(bfi_columns)\n","\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[bfi_columns].copy()\n","\n","    # Apply mapping and cleaning\n","    scored_data = scored_data.applymap(map_scores)\n","\n","    # Apply reverse scoring\n","    #reverse_scored_items = [1, 6, 11, 16, 21, 26, 31, 36]  # Adjust the list according to BFI reverse-scored items\n","    reverse_scored_items = [6, 21, 31, 2,12,27,37,8,18,23,43,9,24,34,35,41]\n","    reverse_columns = [f'BFI_{item}' for item in reverse_scored_items]\n","    scored_data[reverse_columns] = scored_data[reverse_columns].applymap(BFI_reverse_score)\n","    scored_data_columns = scored_data.copy()\n","\n","\n","    # Blank count & percentage\n","    scored_data['Blank_Count']      = scored_data[bfi_columns].isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Define your trait‐to‐item mappings\n","    traits = {\n","        'BFI_Extraversion': [1, 6, 11, 16, 21, 26, 31, 36],\n","        'BFI_Agreeableness': [2, 7, 12, 17, 22, 27, 32, 37, 42],\n","        'BFI_Conscientiousness': [3, 8, 13, 18, 23, 28, 33, 38, 43],\n","        'BFI_Neuroticism': [4, 9, 14, 19, 24, 29, 34, 39],\n","        'BFI_Openness': [5, 10, 15, 20, 25, 30, 35, 40, 41, 44]\n","    }\n","\n","    # Conditional subscale scoring (only if ≥ half answered)\n","    for trait, indices in traits.items():\n","        cols = [f'BFI_{i}' for i in indices]\n","        scored_data[trait] = scored_data.apply(\n","            lambda row: row[cols].mean()\n","                        if row['Blank_Count'] <= n_items/2\n","                        else np.nan,\n","            axis=1\n","        )\n","\n","    # Conditional final and SD scores using the original cleaned item-only DataFrame\n","    scored_data['BFI_Final_Score'] = scored_data.apply(\n","        lambda row: scored_data_columns.loc[row.name, bfi_columns].mean()\n","                    if row['Blank_Count'] <= n_items / 2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    scored_data['BFI_SD_of_Answers'] = scored_data.apply(\n","        lambda row: scored_data_columns.loc[row.name, bfi_columns].std()\n","                    if row['Blank_Count'] <= n_items / 2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    scored_data['BFI_Questions_Not_Answered'] = scored_data['Blank_Count']\n","\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","    return output_data\n"]},{"cell_type":"markdown","metadata":{"id":"MQv4XK36hno5"},"source":["## ADHD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbAw_FGwhrwn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# ADHD survey scoring\n","def score_adhd(df, path):\n","\n","    # Numeric mapping (no entry for “Prefer not to respond” here)\n","    answer_scores = {\n","        \"Not at all\": 0,\n","        \"Just a little\": 1,\n","        \"Somewhat\": 2,\n","        \"Moderately\": 3,\n","        \"Quite a lot\": 4,\n","        \"Very Much\": 5\n","    }\n","\n","    # Mapping fn for numeric responses\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip(), np.nan)\n","\n","    # Column list + count\n","    adhd_columns = [f'ADHD_{i}' for i in range(1, 24)]\n","    n_items = len(adhd_columns)\n","\n","    # Raw text, then map numeric\n","    scored_data = df[adhd_columns].copy()\n","    scored_data = scored_data.applymap(map_scores)\n","\n","    # Put “Prefer not to respond” back in for anyone who chose it\n","    for col in adhd_columns:\n","        mask = df[col].astype(str).str.strip() == \"Prefer not to respond\"\n","        scored_data.loc[mask, col] = \"Prefer not to respond\"\n","\n","    # Count blanks (only true NaNs) and percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Compute total, coercing non-numeric back to NaN for the sum\n","    def compute_total(row):\n","        if row['Blank_Count'] <= n_items/2:\n","            vals = pd.to_numeric(row[adhd_columns], errors='coerce')\n","            return vals.sum(min_count=1)\n","        else:\n","            return np.nan\n","\n","    scored_data['ADHD_Total_Score'] = scored_data.apply(compute_total, axis=1)\n","\n","    # Compute SD of the numeric items\n","    #    (non-numerics become NaN via to_numeric)\n","    scored_data['ADHD_Item_SD'] = scored_data[adhd_columns]\\\n","        .apply(lambda row: pd.to_numeric(row, errors='coerce').std(skipna=True), axis=1)\n","\n","    # Add hashed PROLIFIC_PID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s1_prolific_id].apply(hash_id)\n","    )\n","\n","    # Add metadata as a multi-index and save\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"eo3l0vtFsFkW"},"source":["## STAI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hnyIiWWIsHnG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","\n","# STAI scoring\n","def score_stai(df, path):\n","    # Mapping of text answers to scores for the state scale (questions 1-20)\n","    state_answer_scores = {\n","        \"Not At All\": 1,\n","        \"Somewhat\": 2,\n","        \"Moderately So\": 3,\n","        \"Very Much So\": 4\n","    }\n","\n","    # Mapping of text answers to scores for the trait scale (questions 21-40)\n","    trait_answer_scores = {\n","        \"Almost Never\": 1,\n","        \"Sometimes\": 2,\n","        \"Often\": 3,\n","        \"Almost Always\": 4\n","    }\n","\n","    # Function to clean and map scores for state questions\n","    def map_state_scores(value):\n","        value = str(value).strip()\n","        return state_answer_scores.get(value, np.nan)\n","\n","    # Function to clean and map scores for trait questions\n","    def map_trait_scores(value):\n","        value = str(value).strip()\n","        return trait_answer_scores.get(value, np.nan)\n","\n","    # List of STAI items\n","    state_columns = [f'STAI_1_{i}' for i in range(1, 21)]\n","    trait_columns = [f'STAI_2_{i}' for i in range(1, 21)]\n","    n_state = len(state_columns)\n","    n_trait = len(trait_columns)\n","\n","    # Create a copy of the relevant columns\n","    state_scored_data = df[state_columns].copy()\n","    trait_scored_data = df[trait_columns].copy()\n","\n","    # Apply mapping and cleaning\n","    state_scored_data = state_scored_data.applymap(map_state_scores)\n","    trait_scored_data = trait_scored_data.applymap(map_trait_scores)\n","\n","    # Count blanks & percentage\n","    state_scored_data[\"STAI_State_Blank_Count\"]      = state_scored_data.isna().sum(axis=1)\n","    state_scored_data[\"STAI_State_Blank_Percentage\"] = state_scored_data[\"STAI_State_Blank_Count\"] / n_state\n","    trait_scored_data[\"STAI_Trait_Blank_Count\"]      = trait_scored_data.isna().sum(axis=1)\n","    trait_scored_data[\"STAI_Trait_Blank_Percentage\"] = trait_scored_data[\"STAI_Trait_Blank_Count\"] / n_trait\n","\n","    # Conditional mean & SD functions\n","    def cond_mean(row, items, blank_field, n):\n","        if row[blank_field] <= n/2:\n","            return row[items].mean()\n","        return np.nan\n","\n","    def cond_sd(row, items, blank_field, n):\n","        if row[blank_field] <= n/2:\n","            return row[items].std()\n","        return np.nan\n","\n","    # 7) Compute State & Trait metrics only when ≥ half answered\n","    state_scored_data[\"STAI_State_Mean\"] = state_scored_data.apply(\n","        lambda r: cond_mean(r, state_columns, \"STAI_State_Blank_Count\", n_state),\n","        axis=1\n","    )\n","    state_scored_data[\"STAI_State_SD\"] = state_scored_data.apply(\n","        lambda r: cond_sd(r, state_columns, \"STAI_State_Blank_Count\", n_state),\n","        axis=1\n","    )\n","    trait_scored_data[\"STAI_Trait_Mean\"] = trait_scored_data.apply(\n","        lambda r: cond_mean(r, trait_columns, \"STAI_Trait_Blank_Count\", n_trait),\n","        axis=1\n","    )\n","    trait_scored_data[\"STAI_Trait_SD\"] = trait_scored_data.apply(\n","        lambda r: cond_sd(r, trait_columns, \"STAI_Trait_Blank_Count\", n_trait),\n","        axis=1\n","    )\n","\n","    # 8) Combine and total questions skipped\n","    scored_data = pd.concat([state_scored_data, trait_scored_data], axis=1)\n","    scored_data[\"STAI_Questions_Not_Answered\"] = (\n","        scored_data[\"STAI_State_Blank_Count\"] +\n","        scored_data[\"STAI_Trait_Blank_Count\"]\n","    )\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","    output_data.to_csv(path, index=False)\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"ajaDAACk3Pz7"},"source":["## OCD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELrK_eCp3Sb8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","import re\n","\n","# OCD survey scoring\n","def score_ocd(df, path):\n","\n","    # Mapping of text answers to 0–4\n","    answer_scores_1_5 = {\n","        \"None at all\": 0,\n","        \"Less than 1 hour each day\": 1,\n","        \"Between 1 and 3 hours each day\": 2,\n","        \"Between 3 and 8 hours each day\": 3,\n","        \"8 hours or more each day\": 4,\n","\n","        \"A little avoidance\": 1,\n","        \"A moderate amount of avoidance\": 2,\n","        \"A great deal of avoidance\": 3,\n","        \"Extreme avoidance of nearly all things\": 4,\n","\n","        \"Not at all distressed/anxious\": 0,\n","        \"Mildly distressed/anxious\": 1,\n","        \"Moderately distressed/anxious\": 2,\n","        \"Severely distressed/anxious\": 3,\n","        \"Extremely distressed/anxious\": 4,\n","\n","        \"No disruption at all.\": 0,\n","        \"A little disruption, but I mostly function well.\": 1,\n","        \"Many things are disrupted, but I can still manage.\": 2,\n","        \"My life is disrupted in many ways and I have trouble managing.\": 3,\n","        \"My life is completely disrupted and I cannot function at all.\": 4,\n","\n","        \"Not at all difficult\": 0,\n","        \"A little difficult\": 1,\n","        \"Moderately difficult\": 2,\n","        \"Very difficult\": 3,\n","        \"Extremely difficult\": 4\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores_1_5.get(str(value).strip(), np.nan)\n","\n","    # Define items & count\n","    ocd_columns = [f'OCD_{i}_{j}' for i in range(1, 5) for j in range(1, 6)]\n","    n_items     = len(ocd_columns)\n","\n","    # Score items\n","    scored_data = df[ocd_columns].copy().applymap(map_scores)\n","\n","    # Blank counts & percentages\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Total score (only if ≥ half answered)\n","    def cond_sum(row, cols):\n","        return row[cols].sum() if row['Blank_Count'] <= n_items/2 else np.nan\n","\n","    scored_data['OCD_Total_Score'] = scored_data.apply(lambda r: cond_sum(r, ocd_columns), axis=1)\n","\n","    # Subscale scores\n","    subs = {\n","      'OCD_1_5_Score':   [f'OCD_1_{i}' for i in range(1, 6)],\n","      'OCD_6_10_Score':  [f'OCD_2_{i}' for i in range(1, 6)],\n","      'OCD_11_15_Score': [f'OCD_3_{i}' for i in range(1, 6)],\n","      'OCD_16_20_Score': [f'OCD_4_{i}' for i in range(1, 6)],\n","    }\n","    for name, cols in subs.items():\n","        scored_data[name] = scored_data.apply(lambda r: cond_sum(r, cols), axis=1)\n","\n","    # Standard deviation of the numeric items\n","    scored_data['OCD_Item_SD'] = scored_data[ocd_columns]\\\n","        .std(axis=1, skipna=True)\n","\n","    # Hash ID & metadata, then save\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","    output = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Mel: Add Subscale scores\n","    # Extract the main/outer level index\n","    main_level = scored_data.columns.get_level_values(0)\n","\n","    main_level = (\n","        main_level\n","        .str.replace(r'^OCD_1_(\\d+)', r'OCD_germs_\\1', regex=True)\n","        .str.replace(r'^OCD_2_(\\d+)', r'OCD_harm_\\1', regex=True)\n","        .str.replace(r'^OCD_3_(\\d+)', r'OCD_thoughts_\\1', regex=True)\n","        .str.replace(r'^OCD_4_(\\d+)', r'OCD_symmetry_\\1', regex=True)\n","    )\n","    # Reassign back to the MultiIndex\n","    scored_data.columns = pd.MultiIndex.from_arrays([main_level] + [scored_data.columns.get_level_values(i) for i in range(1, scored_data.columns.nlevels)])\n","\n","    output.to_csv(path, index=False)\n","    return output"]},{"cell_type":"code","source":[],"metadata":{"id":"AcxV8uvQMez7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7fy9zx8JSmU"},"source":["## Grit\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDp8NT9CJT7q"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Grit Scale survey scoring\n","def score_grit(df, path):\n","    # Mapping of text answers to 1–5\n","    answer_scores = {\n","        \"Not like me at all\": 1,\n","        \"Not much like me\": 2,\n","        \"Somewhat like me\": 3,\n","        \"Mostly like me\": 4,\n","        \"Very much like me\": 5\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip(), np.nan)\n","\n","    # Item list & count\n","    grit_columns = [\n","        'Grit Scale_1', 'Grit Scale_6', 'Grit Scale_2', 'Grit Scale_3',\n","        'Grit Scale_4', 'Grit Scale_7', 'Grit Scale_5', 'Grit Scale_8',\n","        'Grit Scale_9', 'Grit Scale_10'\n","    ]\n","    n_items = len(grit_columns)\n","\n","    # Score items\n","    scored_data = df[grit_columns].copy().applymap(map_scores)\n","\n","    # Blank counts & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Total score (only if ≥ half answered)\n","    scored_data['Grit_Total_Score'] = scored_data.apply(\n","        lambda row: row[grit_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Item‐wise standard deviation\n","    scored_data['Grit_Item_SD'] = scored_data[grit_columns]\\\n","        .std(axis=1, skipna=True)\n","\n","    # Hash ID, add metadata, save\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"code","source":["def save_with_metadata(df, path):\n","    # Extract header rows from the MultiIndex\n","    if isinstance(df.columns, pd.MultiIndex):\n","        headers = pd.DataFrame(df.columns.tolist()).T\n","        df.columns = [''] * df.shape[1]  # temporary dummy columns for correct format\n","        with open(path, 'w', encoding='utf-8', newline='') as f:\n","            headers.to_csv(f, index=False, header=False)\n","            df.to_csv(f, index=False, header=False)\n","    else:\n","        df.to_csv(path, index=False)"],"metadata":{"id":"wbX9TzyWBLvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xXdKEAHCVQk7"},"source":["## Oldenburg Burnout Inventory\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-9G2TBrVcbb"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_oldenburg(df, path):\n","    # Items 1–16\n","    oldenburg_columns = [f'Burnout_{i}' for i in range(1, 17)]\n","    n_items = len(oldenburg_columns)\n","\n","    # Reverse‐scoring items\n","    reverse_items = {2, 3, 4, 6, 8, 9, 11, 12}\n","\n","    # Map textual responses to 1–4\n","    response_mapping = {\n","        'strongly agree': 1,\n","        'agree': 2,\n","        'disagree': 3,\n","        'strongly disagree': 4\n","    }\n","    scored = df[oldenburg_columns].replace(response_mapping)\n","\n","    # Reverse‐score designated items (1 <-> 4, 2 <-> 3)\n","    def _rev(x):\n","        if pd.isna(x):\n","            return np.nan\n","        return 5 - x  # flips 1→4, 2→3, 3→2, 4→1\n","\n","    rev_cols = [f'Burnout_{i}' for i in reverse_items]\n","    scored[rev_cols] = scored[rev_cols].applymap(_rev)\n","\n","    # Compute blanks & percentage\n","    scored['Blank_Count']      = scored.isna().sum(axis=1)\n","    scored['Blank_Percentage'] = scored['Blank_Count'] / n_items\n","\n","    # Subscales\n","    exhaustion_items   = [2, 4, 5, 8, 10, 12, 14, 16]\n","    disengagement_items = [1, 3, 6, 7, 9, 11, 13, 15]\n","\n","    exhaustion_cols   = [f'Burnout_{i}' for i in exhaustion_items]\n","    disengagement_cols = [f'Burnout_{i}' for i in disengagement_items]\n","\n","    scored['Exhaustion_Score']    = scored[exhaustion_cols].sum(axis=1, min_count=1)\n","    scored['Disengagement_Score'] = scored[disengagement_cols].sum(axis=1, min_count=1)\n","\n","    # Total (only if ≥ half answered)\n","    scored['Oldenburg_Total_Score'] = scored.apply(\n","        lambda r: r[oldenburg_columns].sum(min_count=1)\n","                  if r['Blank_Count'] <= n_items/2 else np.nan,\n","        axis=1\n","    )\n","\n","    # Item‐level SD\n","    scored['Oldenburg_Item_SD'] = scored[oldenburg_columns].std(axis=1, skipna=True)\n","\n","    # hashed ID\n","    scored.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # ---- Add only question text + Normal/Reversed rows ----\n","    metadata_texts = s1_metadata_row  # use stored metadata row instead of raw answers\n","    level0 = scored.columns\n","    level1 = [metadata_texts.get(c, \"\") if c in metadata_texts.index else \"\" for c in level0]\n","    level2 = []\n","    for c in level0:\n","        if c.startswith(\"Burnout_\"):\n","            q = int(c.split(\"_\",1)[1])\n","            level2.append(\"Reversed\" if q in reverse_items else \"Normal\")\n","        else:\n","            level2.append(\"\")\n","\n","    scored.columns = pd.MultiIndex.from_tuples(\n","        list(zip(level0, level1, level2)),\n","        names=[\"Variable\",\"Question Text\",\"Scoring\"]\n","    )\n","\n","    # Save\n","    scored.to_csv(path, index=False)\n","    return scored"]},{"cell_type":"markdown","source":["## Maslach Burnout Inventory\n"],"metadata":{"id":"xTvZrJttfEMQ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_maslach(df, path):\n","    # Define MBI subscales\n","    exhaustion_items = [f'Maslach_{i}' for i in [1, 2, 3, 4, 6]]\n","    cynicism_items = [f'Maslach_{i}' for i in [8, 9, 13, 14, 15]]\n","    professional_efficacy_items = [f'Maslach_{i}' for i in [5, 7, 10, 11, 12, 16]]\n","    maslach_columns = exhaustion_items + cynicism_items + professional_efficacy_items\n","    n_items = len(maslach_columns)\n","\n","    # Response mapping\n","    response_mapping = {\n","        'Never': 0,\n","        'A few times a year or less': 1,\n","        'Once a month or less': 2,\n","        'A few times a month': 3,\n","        'Once a week': 4,\n","        'A few times a week': 5,\n","        'Every Day': 6\n","    }\n","\n","    # Track missing before transformation\n","    df = df.copy()\n","    df['Missing_Fields_Count_Original'] = df[maslach_columns].isna().sum(axis=1)\n","\n","    # Map responses to numeric\n","    scored_data = df[maslach_columns].replace(response_mapping).apply(pd.to_numeric, errors='coerce')\n","\n","    # Missing counts\n","    scored_data['Missing_Fields_Count_Transformed'] = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Count']      = scored_data['Missing_Fields_Count_Transformed']\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional sums & means\n","    def conditional_sum(row, items):\n","        return row[items].sum(skipna=True) if row['Blank_Count'] <= n_items/2 else np.nan\n","    def conditional_mean(row, items):\n","        return row[items].mean(skipna=True) if row['Blank_Count'] <= n_items/2 else np.nan\n","\n","    scored_data['Exhaustion_Total_Score']            = scored_data.apply(lambda r: conditional_sum(r, exhaustion_items), axis=1)\n","    scored_data['Cynicism_Total_Score']              = scored_data.apply(lambda r: conditional_sum(r, cynicism_items), axis=1)\n","    scored_data['Professional_Efficacy_Total_Score'] = scored_data.apply(lambda r: conditional_sum(r, professional_efficacy_items), axis=1)\n","\n","    scored_data['Exhaustion_Average_Score']            = scored_data.apply(lambda r: conditional_mean(r, exhaustion_items), axis=1)\n","    scored_data['Cynicism_Average_Score']              = scored_data.apply(lambda r: conditional_mean(r, cynicism_items), axis=1)\n","    scored_data['Professional_Efficacy_Average_Score'] = scored_data.apply(lambda r: conditional_mean(r, professional_efficacy_items), axis=1)\n","\n","    # SD across items\n","    scored_data['Maslach_Item_SD'] = scored_data[maslach_columns].std(axis=1, skipna=True)\n","\n","    # --- Add reversed Professional Efficacy columns ---\n","    def reverse_score(x):\n","        if pd.isna(x): return np.nan\n","        return 6 - x  # flips 0→6, 1→5, 2→4, 3→3, 4→2, 5→1, 6→0\n","\n","    reversed_prof = scored_data[professional_efficacy_items].map(reverse_score)\n","    scored_data['Professional_Efficacy_Total_Score_Reversed'] = reversed_prof.sum(axis=1, min_count=1)\n","    scored_data['Professional_Efficacy_Average_Score_Reversed'] = reversed_prof.mean(axis=1)\n","\n","    # Add hashed Subject ID\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save\n","    output_data.to_csv(path, index=False)\n","    return output_data"],"metadata":{"id":"vwk4e1onfJgk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCyTciCU4Wv7"},"source":["## BFNE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rA_6RZAq4Yst"},"outputs":[],"source":["# BFNE survey scoring\n","def score_bfne(df, path):\n","    # Map text answers to numeric scores\n","    answer_scores = {\n","        \"Not at all characteristic or true of me\": 1,\n","        \"Slightly characteristic or true of me\": 2,\n","        \"Moderately characteristic or true of me\": 3,\n","        \"Very characteristic or true of me\": 4,\n","        \"Extremely characteristic or true of me\": 5\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip(), np.nan)\n","\n","    # Define BFNE columns\n","    bfne_columns = [f'BFNE_{i}' for i in range(1, 9)]\n","    n_items = len(bfne_columns)\n","\n","    # Score each item\n","    scored_data = df[bfne_columns].applymap(map_scores)\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['BFNE_Total_Score'] = scored_data.apply(\n","        lambda row: row[bfne_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items / 2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation\n","    scored_data['BFNE_Item_SD'] = scored_data[bfne_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed ID and metadata, then save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"Id9TXCRjDaXI"},"source":["## CUSADOS\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVB-QMTSDoPZ"},"outputs":[],"source":["# CUSADOS survey scoring\n","def score_cusados(df, path):\n","    # Map text answers to numeric scores\n","    answer_scores = {\n","        \"never\": 0,\n","        \"rarely\": 1,\n","        \"sometimes\": 2,\n","        \"usually\": 3,\n","        \"always\": 4\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Define your CUSADOS columns\n","    cusados_columns = [f'CUSADOS_{i}' for i in range(1, 13)]\n","    n_items = len(cusados_columns)\n","\n","    # Score each item\n","    scored_data = df[cusados_columns].applymap(map_scores)\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['CUSADOS_Total_Score'] = scored_data.apply(\n","        lambda row: row[cusados_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation across the 12 items\n","    scored_data['CUSADOS_Item_SD'] = scored_data[cusados_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed ID, metadata and save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"5egR3xApExaL"},"source":["## UCLA Loneliness"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fqYE62dE1Wt"},"outputs":[],"source":["# Loneliness survey scoring\n","def score_ucla_loneliness(df, path):\n","    # Map text answers to numeric scores\n","    answer_scores = {\n","        \"hardly ever\": 1,\n","        \"some of the time\": 2,\n","        \"often\": 3\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Define UCLA Loneliness columns\n","    loneliness_columns = [f'UCLA_Loneliness_{i}' for i in range(1, 4)]\n","    n_items = len(loneliness_columns)\n","\n","    # Score each item\n","    scored_data = df[loneliness_columns].applymap(map_scores)\n","\n","    # Blank counts & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['Loneliness_Total_Score'] = scored_data.apply(\n","        lambda row: row[loneliness_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation across the 3 items\n","    scored_data['UCLA_Loneliness_SD'] = scored_data[loneliness_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed ID, metadata, save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"CDcTfor4GRmT"},"source":["## Gallup Best Friend"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9sf7HunGZ8c"},"outputs":[],"source":["# Function to extract Gallup Best Friend Item response\n","def score_gallup_bff(df, path):\n","    # List of GallupBFF item\n","    gallup_bff_column = 'GallupBFF_1'\n","\n","    # Create a copy of the relevant column\n","    scored_data = df[[gallup_bff_column]].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data\n","\n","  # some of these items are numeric some are 'strongly disagree' etc."]},{"cell_type":"markdown","metadata":{"id":"5KrZtEOPKXi6"},"source":["## AUDIT\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1snU5VwKY-q"},"outputs":[],"source":["# Function to score the AUDIT survey\n","def score_audit(df, path):\n","    import numpy as np\n","    import pandas as pd\n","\n","    # Map text to values\n","    answer_scores = {\n","        \"never\":                  0,\n","        \"monthly or less\":        1,\n","        \"less than monthly\":      1,\n","        \"2-4 times a month\":      2,\n","        \"monthly\":                2,\n","        \"2-3 times a week\":       3,\n","        \"weekly\":                 3,\n","        \"4 or more times a week\": 4,\n","        \"daily or almost daily\":  4,\n","\n","        \"1 or 2\":                 0,\n","        \"3 or 4\":                 1,\n","        \"5 or 6\":                 2,\n","        \"7 to 9\":                 3,\n","        \"10 or more\":             4,\n","\n","        \"no\":                     0,\n","        \"yes, but not in the last year\": 2,\n","        \"yes, during the last year\":    4\n","    }\n","\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Define AUDIT columns\n","    audit_columns = [f'AUDIT_{i}' for i in range(1, 11)]\n","    n_items = len(audit_columns)\n","\n","    # Score each item\n","    scored_data = df[audit_columns].copy().applymap(map_scores)\n","\n","    # Subscales\n","    scored_data['AUDIT_Consumption_Score'] = scored_data[['AUDIT_1','AUDIT_2','AUDIT_3']].sum(axis=1, min_count=1)\n","    scored_data['AUDIT_Problem_Score']     = scored_data[['AUDIT_4','AUDIT_5','AUDIT_6','AUDIT_7','AUDIT_8','AUDIT_9','AUDIT_10']].sum(axis=1, min_count=1)\n","\n","    # Blank counts & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total (only if ≥ half answered)\n","    scored_data['AUDIT_Total_Score'] = scored_data.apply(\n","        lambda row: row[audit_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation across the 10 items\n","    scored_data['AUDIT_Item_SD'] = scored_data[audit_columns].std(axis=1, skipna=True)\n","\n","    # Hashed ID, metadata, save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"QLfGzXbLQ9Nw"},"source":["## BRCS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfXDmf9QQ-yy"},"outputs":[],"source":["# Function to score the BRCS survey\n","def score_brcs(df, path):\n","    import numpy as np\n","    import pandas as pd\n","\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"does not describe me at all\": 1,\n","        \"does not describe me\": 2,\n","        \"neutral\": 3,\n","        \"describes me\": 4,\n","        \"describes me very well\": 5\n","    }\n","\n","    # Clean-and-map function\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Define 4 BRCS columns\n","    brcs_columns = [f'BRCS_{i}' for i in range(1, 5)]\n","    n_items = len(brcs_columns)\n","\n","    # Score each item\n","    scored_data = df[brcs_columns].copy().applymap(map_scores)\n","\n","    # Blank counts & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total (only if ≥ half answered)\n","    scored_data['BRCS_Total_Score'] = scored_data.apply(\n","        lambda row: row[brcs_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Interpretation\n","    def categorize_score(score):\n","        if pd.isna(score):\n","            return np.nan\n","        if score <= 13:\n","            return \"Low resilient coper\"\n","        elif score <= 16:\n","            return \"Medium resilient coper\"\n","        else:\n","            return \"High resilient coper\"\n","\n","    scored_data['BRCS_Interpretation'] = scored_data['BRCS_Total_Score'].apply(categorize_score)\n","\n","    # SD across the 4 items\n","    scored_data['BRCS_Item_SD'] = scored_data[brcs_columns].std(axis=1, skipna=True)\n","\n","    # Hashed ID, metadata, save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"eMvlVsexSPXx"},"source":["## Pastimes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMdzONk0SRMN"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Function to score the Pastimes survey\n","def score_pastimes(df, path):\n","    # Define columns\n","    pastimes_columns = [f'Pastimes_{i}' for i in range(1, 19)]\n","    nonnum = pastimes_columns[0]      # e.g. 'By Myself' / 'With Others'\n","    num_cols = pastimes_columns[1:]   # numeric‐scored items\n","    n_numeric = len(num_cols)\n","\n","    # Text to numeric mapping\n","    answer_scores = {\n","        \"never\": 0,\n","        \"1-3 hours\": 3,\n","        \"4-6 hours\": 6,\n","        \"7-9 hours\": 9,\n","        \"10+ hours\": 10\n","    }\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Copy & map\n","    scored_data = df[pastimes_columns].copy()\n","    scored_data[num_cols] = (\n","        scored_data[num_cols]\n","        .applymap(map_scores)\n","        .apply(pd.to_numeric, errors='coerce')\n","    )\n","\n","    # Blank counts & percentage (numeric only)\n","    scored_data['Blank_Count']      = scored_data[num_cols].isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_numeric\n","\n","    # Conditional total on numeric only\n","    scored_data['Pastimes_Total_Score'] = scored_data.apply(\n","        lambda r: r[num_cols].sum(min_count=1)\n","                  if r['Blank_Count'] <= n_numeric/2\n","                  else np.nan,\n","        axis=1\n","    )\n","\n","    # SD across the numeric items\n","    scored_data['Pastimes_Item_SD'] = scored_data[num_cols].std(axis=1, skipna=True)\n","\n","    # Hashed ID + metadata + save\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"dEjOhBakUYy5"},"source":["## PSQI"]},{"cell_type":"code","source":["def score_psqi(df, path):\n","    import numpy as np\n","    import pandas as pd\n","\n","    # Define the PSQI columns to process\n","    psqi_columns = [\n","        \"PSQI_1_1\", \"PSQI_2_1\", \"PSQI_3_1\", \"PSQI_4_1\", \"PSQI_tib_1\",\n","        \"PSQI_5a\", \"PSQI_5b\", \"PSQI_5c\", \"PSQI_5d\", \"PSQI_5e\",\n","        \"PSQI_5f\", \"PSQI_5g\", \"PSQI_5h\", \"PSQI_5i\", \"PSQI_5j_2\",\n","        \"PSQI_6\", \"PSQI_7\", \"PSQI_8\", \"PSQI_9\"\n","    ]\n","    n_items = len(psqi_columns)\n","\n","    # Create a working copy of the PSQI data\n","    scored_data = df[psqi_columns].copy()\n","\n","    # === Clean Numeric Columns ===\n","    for col in [\"PSQI_2_1\", \"PSQI_4_1\", \"PSQI_tib_1\"]:\n","        scored_data[col] = scored_data[col].replace(\"\", np.nan)\n","        scored_data[col] = scored_data[col].astype(str).str.extract(r\"(\\d+\\.?\\d*)\")[0]\n","        scored_data[col] = pd.to_numeric(scored_data[col], errors=\"coerce\")\n","\n","    # === Mapping Dictionaries ===\n","    sleep_freq_map = {\n","        \"Not during the past month\": 0,\n","        \"Not during the last month\": 0,\n","        \"Less than once a week\": 1,\n","        \"Once or twice a week\": 2,\n","        \"Three or more times a week\": 3,\n","        \"N/A\": 0\n","    }\n","    sleep_quality_map = {\n","        \"Very good\": 0,\n","        \"Fairly good\": 1,\n","        \"Fairly bad\": 2,\n","        \"Very bad\": 3\n","    }\n","\n","    # === Apply Mapping to Frequency Items ===\n","    freq_cols = [\"PSQI_5a\",\"PSQI_5b\",\"PSQI_5c\",\"PSQI_5d\",\"PSQI_5e\",\n","                 \"PSQI_5f\",\"PSQI_5g\",\"PSQI_5h\",\"PSQI_5i\",\"PSQI_5j_2\",\"PSQI_8\"]\n","    scored_data[freq_cols] = scored_data[freq_cols].apply(\n","        lambda col: col.astype(str).str.strip().map(sleep_freq_map)\n","    )\n","    scored_data[\"PSQI_9\"] = scored_data[\"PSQI_9\"].astype(str).str.strip().map(sleep_freq_map)\n","\n","    # === Sleep Duration Score (PSQIDURAT) ===\n","    def compute_psqidurat(value):\n","        if pd.isna(value): return np.nan\n","        if value >= 7:                       return 0\n","        elif 6 <= value < 7:                 return 1\n","        elif 5 <= value < 6:                 return 2\n","        elif value < 5:                      return 3\n","        else:                                return np.nan\n","    scored_data[\"PSQIDURAT\"] = scored_data[\"PSQI_4_1\"].apply(compute_psqidurat)\n","\n","    # === Sleep Latency Scoring (PSQILATEN) ===\n","    def compute_q2new(value):\n","        if pd.isna(value): return np.nan\n","        if 0 <= value <= 15:         return 0\n","        elif 15 < value <= 30:       return 1\n","        elif 30 < value <= 60:       return 2\n","        elif value > 60:             return 3\n","        else:                         return np.nan\n","    scored_data[\"Q2new\"] = scored_data[\"PSQI_2_1\"].apply(compute_q2new)\n","\n","    def compute_psqilaten(row):\n","        if pd.isna(row[\"PSQI_5a\"]) or pd.isna(row[\"Q2new\"]):\n","            return np.nan\n","        total_latency = row[\"PSQI_5a\"] + row[\"Q2new\"]\n","        if total_latency == 0:        return 0\n","        elif 1 <= total_latency <= 2:  return 1\n","        elif 3 <= total_latency <= 4:  return 2\n","        elif 5 <= total_latency <= 6:  return 3\n","        else:                          return np.nan\n","    scored_data[\"PSQILATEN\"] = scored_data.apply(compute_psqilaten, axis=1)\n","\n","    # === Sleep Efficiency Scoring (PSQIHSE) ===\n","    def compute_psqihse(row):\n","        if pd.isna(row[\"PSQI_4_1\"]) or pd.isna(row[\"PSQI_tib_1\"]) or row[\"PSQI_tib_1\"] == 0:\n","            return np.nan\n","        tmphse = (row[\"PSQI_4_1\"] / row[\"PSQI_tib_1\"]) * 100\n","        if tmphse >= 85:               return 0\n","        elif 75 <= tmphse < 85:        return 1\n","        elif 65 <= tmphse < 75:        return 2\n","        elif tmphse < 65:              return 3\n","        else:                          return np.nan\n","    scored_data[\"PSQIHSE\"] = scored_data.apply(compute_psqihse, axis=1)\n","\n","    # === Sleep Disturbance Scoring (PSQIDISTB) ===\n","    disturbance_cols = [\"PSQI_5b\",\"PSQI_5c\",\"PSQI_5d\",\"PSQI_5e\",\"PSQI_5f\",\n","                        \"PSQI_5g\",\"PSQI_5h\",\"PSQI_5i\",\"PSQI_5j_2\"]\n","    scored_data[\"PSQI_5j_2\"].fillna(0, inplace=True)\n","    scored_data[\"PSQIDISTB_raw\"] = scored_data[disturbance_cols].sum(axis=1, min_count=1)\n","    def compute_psqidistb(row):\n","        td = row[\"PSQIDISTB_raw\"]\n","        if td == 0:                   return 0\n","        elif 1 <= td <= 9:            return 1\n","        elif 10 <= td <= 18:          return 2\n","        elif td > 18:                 return 3\n","        else:                         return np.nan\n","    scored_data[\"PSQIDISTB\"] = scored_data.apply(compute_psqidistb, axis=1)\n","\n","    # === Daytime Dysfunction Scoring (PSQIDAYDYS) ===\n","    scored_data[[\"PSQI_8\",\"PSQI_9\"]] = scored_data[[\"PSQI_8\",\"PSQI_9\"]].fillna(0)\n","    scored_data[\"PSQIDAYDYS_raw\"] = scored_data[\"PSQI_8\"] + scored_data[\"PSQI_9\"]\n","    def compute_psqidaydys(total):\n","        if total == 0:                return 0\n","        elif 1 <= total <= 2:         return 1\n","        elif 3 <= total <= 4:         return 2\n","        elif 5 <= total <= 6:         return 3\n","        else:                         return np.nan\n","    scored_data[\"PSQIDAYDYS\"] = scored_data[\"PSQIDAYDYS_raw\"].apply(compute_psqidaydys)\n","\n","    # === Overall Sleep Quality & Medication ===\n","    scored_data[\"PSQISLPQUAL\"] = scored_data[\"PSQI_6\"].astype(str).str.strip().map(sleep_quality_map)\n","    scored_data[\"PSQIMEDS\"]   = (scored_data[\"PSQI_7\"]\n","                                 .astype(str)\n","                                 .str.strip()\n","                                 .replace(\"Not during the last month\",\"Not during the past month\")\n","                                 .map(sleep_freq_map))\n","    scored_data[\"PSQI_6\"] = scored_data[\"PSQISLPQUAL\"]\n","    scored_data[\"PSQI_7\"] = scored_data[\"PSQIMEDS\"]\n","\n","    # === Compute Total PSQI Score ===\n","    scored_data['Blank_Count']      = scored_data[psqi_columns].isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    components = [\"PSQIDURAT\",\"PSQILATEN\",\"PSQIHSE\",\"PSQIDISTB\",\"PSQIDAYDYS\",\"PSQISLPQUAL\",\"PSQIMEDS\"]\n","    scored_data[\"PSQI_Total\"] = scored_data.apply(\n","        lambda r: r[components].sum(min_count=1)\n","                  if r['Blank_Count'] <= n_items/2\n","                  else np.nan,\n","        axis=1\n","    )\n","\n","    # === Add Sleep Quality Category ===\n","    scored_data[\"PSQI_Category\"] = np.where(\n","        scored_data[\"PSQI_Total\"] < 5, \"Good Sleep Quality\", \"Poor Sleep Quality\"\n","    )\n","\n","    # === Standard Deviation across the 7 component scores ===\n","    scored_data[\"PSQI_Item_SD\"] = scored_data[components].std(axis=1, skipna=True)\n","\n","    # === Add Hashed Subject ID & Metadata, then Save ===\n","    scored_data.insert(0, 'Subject_ID', df['Q1'].apply(hash_id))\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"],"metadata":{"id":"YjVOtCp_0_uQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FHvkrH-1XXV5"},"source":["## Media Multi-Tasking Inventory (short) (MMTI-S)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qEgK18NXZPK"},"outputs":[],"source":["def score_mmti_s(df, path):\n","    import pandas as pd\n","    import numpy as np\n","\n","    # List of MMTI-S items\n","    mmti_s_columns = [f'MMTI-S_{i}' for i in range(1, 10)]\n","    n_items = len(mmti_s_columns)\n","\n","    # Pull raw and convert to numeric (coerce non-numeric → NaN)\n","    scored_data = df[mmti_s_columns].copy().apply(pd.to_numeric, errors='coerce')\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['MMTI-S_Total_Score'] = scored_data.apply(\n","        lambda row: row[mmti_s_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Conditional average\n","    scored_data['MMTI_S_Average_Score'] = scored_data.apply(\n","        lambda row: row[mmti_s_columns].mean(skipna=True)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation across the 9 items\n","    scored_data['MMTI_S_Item_SD'] = scored_data[mmti_s_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed `PROLIFIC_PID`\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","source":[],"metadata":{"id":"N7hts1EXMQJi"}},{"cell_type":"markdown","metadata":{"id":"oBVB--RgfDLz"},"source":["## PANAS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_U7r9TxifESm"},"outputs":[],"source":["# Function to score the PANAS (Positive and Negative Affect Schedule)\n","def score_panas(df, path):\n","    import numpy as np\n","    import pandas as pd\n","\n","    # List of PANAS items\n","    panas_columns = [f'PANAS_{i}' for i in range(1, 21)]\n","    n_items = len(panas_columns)\n","\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"very slightly or not at all\": 1,\n","        \"a little\": 2,\n","        \"moderately\": 3,\n","        \"quite a bit\": 4,\n","        \"extremely\": 5\n","    }\n","\n","    # Function to map and clean scores\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip().lower(), np.nan)\n","\n","    # Apply mapping\n","    scored_data = df[panas_columns].applymap(map_scores)\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Define positive and negative items\n","    positive_items = [1,3,5,9,10,12,14,16,17,19]\n","    negative_items = [2,4,6,7,8,11,13,15,18,20]\n","\n","    # Compute subscale totals (only if at least half answered)\n","    scored_data['PANAS_Positive_Score'] = scored_data.apply(\n","        lambda row: row[[f'PANAS_{i}' for i in positive_items]].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","    scored_data['PANAS_Negative_Score'] = scored_data.apply(\n","        lambda row: row[[f'PANAS_{i}' for i in negative_items]].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation across all 20 items\n","    scored_data['PANAS_Item_SD'] = scored_data[panas_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed `PROLIFIC_PID`\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","metadata":{"id":"6FNvRzeBh8xL"},"source":["## PFI\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_u0jidYPh-No"},"outputs":[],"source":["# Function to score the Professional Fulfillment Index (PFI)\n","def score_pfi(df, path):\n","    import numpy as np\n","    import pandas as pd\n","\n","    # List of PFI items\n","    pfi_columns = [f'PFI_{i}' for i in range(1, 17)]\n","    n_items = len(pfi_columns)\n","\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"Not at all\": 0,\n","        \"Very Little\": 1,\n","        \"Moderately\": 2,\n","        \"A lot\": 3,\n","        \"Extremely\": 4\n","    }\n","\n","    # Function to map and clean scores\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip(), np.nan)\n","\n","    # Map all PFI items\n","    scored_data = df[pfi_columns].applymap(map_scores)\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['PFI_Total_Score'] = scored_data.apply(\n","        lambda row: row[pfi_columns].sum(min_count=1)\n","                    if row['Blank_Count'] <= n_items/2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Calculate average score across all items (NaNs will be ignored)\n","    scored_data['PFI_Average_Score'] = scored_data[pfi_columns].mean(axis=1, skipna=True)\n","\n","    # Standard deviation across all 16 items\n","    scored_data['PFI_Item_SD'] = scored_data[pfi_columns].std(axis=1, skipna=True)\n","\n","    # Add hashed `PROLIFIC_PID`\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save to CSV\n","    output_data.to_csv(path, index=False)\n","\n","    return output_data"]},{"cell_type":"markdown","source":["## Wordle"],"metadata":{"id":"Rb-I0CXlL_b3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_wordle(df, path):\n","\n","    # List of Wordle items\n","    import re\n","\n","    # Only match columns like 'Wordle_1', 'Wordle_2', etc. — no extra text after the number\n","    Wordle_columns = [col for col in df.columns if re.fullmatch(r'Wordle_\\d+', col)]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[Wordle_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"dHSvtjWiMCVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cudit"],"metadata":{"id":"KsBONekSQ-IH"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_cudit(df, path):\n","\n","  # Map text to values\n","    answer_scores = {\n","        \"never\":                  0,\n","        \"monthly or less\":        1,\n","        \"2-4 times a month\":      2,\n","        \"2-3 times a week\":       3,\n","        \"4 or more times a week\": 4,\n","\n","        \"less than 1\":            0,\n","        \"1 or 2\":                 1,\n","        \"3 or 4\":                 2,\n","        \"5 or 6\":                 3,\n","        \"7 or more\":              4,\n","\n","        \"no\":                     0,\n","        \"yes\":                    4,\n","\n","        \"never\":                  0,\n","        \"less than monthly\":      1,\n","        \"monthly\":                2,\n","        \"weekly\":                 3,\n","        \"daily or almost daily\":  4\n","    }\n","\n","    # Function to clean and map scores\n","    def map_scores(value):\n","        value = str(value).strip().lower()\n","        return answer_scores.get(value, np.nan)\n","\n","    # List of Demographic items\n","    cudit_columns = [col for col in df.columns if col.startswith(f'CUDIT_')]\n","    n_items = len(cudit_columns)\n","\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[cudit_columns].copy()\n","\n","    # Apply mapping and cleaning\n","    scored_data = scored_data.applymap(map_scores)\n","\n","    # Count blanks & percentage\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Conditional total: only if at least half answered\n","    scored_data['CUDIT_Total_Score'] = scored_data.apply(\n","        lambda row: row[cudit_columns].sum()\n","                    if row['Blank_Count'] <= n_items / 2\n","                    else np.nan,\n","        axis=1\n","    )\n","\n","    # Standard deviation of the numeric items\n","    scored_data['CUDIT_Item_SD'] = scored_data[cudit_columns]\\\n","        .std(axis=1, skipna=True)\n","\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path,index=False)\n","\n","    return scored_data"],"metadata":{"id":"m_5nIbMTQ9fw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Demographics S1"],"metadata":{"id":"Dj5IT2_QY6OM"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_demographics(df, path):\n","\n","    # List of Demographic items\n","    Demos_columns = [col for col in df.columns if col.startswith(f'Demos_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[Demos_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"NLN97xM8Y5se"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Demos Dummy test"],"metadata":{"id":"l8HPS-8jlaYU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_demographics_test(df, path):\n","\n","    # List of Demographic items\n","    Demos_columns = [col for col in df.columns if col.startswith(f'Demos_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[Demos_columns].copy()\n","\n","    scored_data[:] = 0\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path,index=False)\n","\n","    return scored_data"],"metadata":{"id":"-YcUo9tQlco8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Demographics S2"],"metadata":{"id":"myv9FIp_Y93g"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_demographics_2(df, path):\n","\n","    # List of Demographic items\n","    Demos_columns = [col for col in df.columns if col.startswith(f'Demographics_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[Demos_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    scored_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path)\n","\n","    return scored_data"],"metadata":{"id":"rdZ6elSkZErZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Demographics"],"metadata":{"id":"-JGIyAgnKbIh"}},{"cell_type":"code","source":["import pandas as pd\n","import hashlib\n","\n","def score_demographics_s3(df, path):\n","    # Grab all Demographics_ and NewDemographics_ columns,\n","    # exclude any whose name contains \"Time\"\n","    prefixes = ('Demographics_', 'NewDemographics_')\n","    demographics_columns = [\n","        col for col in df.columns\n","        if col.startswith(prefixes) and 'Time' not in col\n","    ]\n","\n","    # Copy over\n","    scored_data = df[demographics_columns].copy()\n","\n","    # Hashed Subject_ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # Session 3 metadata and save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"W67QAcYVKdHk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Readiness"],"metadata":{"id":"7bY55rdqNp_R"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Readiness survey scoring for Session 3\n","def score_readiness_S3(df, path):\n","    # 1) Grab all Readiness_ columns\n","    readiness_columns = [col for col in df.columns if col.startswith('Readiness_')]\n","\n","    # Copy over\n","    scored_data = df[readiness_columns].copy()\n","\n","    # Hashed Subject_ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # Session 3 metadata & save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"gEK3777oNsOD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Locus of Control"],"metadata":{"id":"26LZ48UJM0i7"}},{"cell_type":"code","source":["def score_loc(df, path):\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"Rarely (less than 10% of the time)\": 1,\n","        \"Occasionally (About 30% of the time)\": 2,\n","        \"Sometimes (About half the time)\": 3,\n","        \"Frequently (About 70% of the time)\": 4,\n","        \"Usually (More than 90% of the time)\": 5,\n","    }\n","\n","    # Function to clean and map scores\n","    def map_scores(value):\n","        # Clean the string to remove leading/trailing whitespaces\n","        value = str(value).strip()\n","        # Return the mapped score or NaN if the value is not found\n","        return answer_scores.get(value, np.nan)\n","\n","    # Function to reverse score the BFI items\n","    def loc_reverse_score(value):\n","        if pd.isna(value):\n","            return value  # Preserve NaN values\n","        return 6 - value\n","\n","    # List of BFI items\n","    loc_columns = [f'LocusControl_{i}' for i in range(1, 29)]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[loc_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # Apply mapping and cleaning\n","    scored_data[loc_columns] = scored_data[loc_columns].applymap(map_scores)\n","\n","    # Apply reverse scoring\n","    reverse_scored_items = [1, 2, 4, 6, 8, 11, 14, 17, 19, 22, 23, 24, 26, 27]\n","    reverse_columns = [f'LocusControl_{item}' for item in reverse_scored_items]\n","    scored_data[reverse_columns] = scored_data[reverse_columns].applymap(loc_reverse_score)\n","\n","    # Final and additional metrics\n","    scored_data['LOC_Final_Score'] = scored_data[loc_columns].apply(lambda x: x.sum() if x.count() >= 1 else np.nan, axis=1)\n","    scored_data['LOC_Mean_of_Answers'] = scored_data[loc_columns].apply(lambda x: x.mean() if x.count() >= 1 else np.nan, axis=1)\n","    scored_data['LOC_SD_of_Answers'] = scored_data[loc_columns].std(axis=1)\n","    scored_data['LOC_Questions_Not_Answered'] = scored_data[loc_columns].isna().sum(axis=1)\n","\n","    # Add metadata\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"xIbUi3fFRy_X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Need for Cognition"],"metadata":{"id":"f2G7TUr3fHbE"}},{"cell_type":"code","source":["def score_nfc(df,path):\n","    # Mapping of text answers to scores\n","    answer_scores = {\n","        \"Strongly Disagree\": 1,\n","        \"Disagree\": 2,\n","        \"Neutral\": 3,\n","        \"Agree\": 4,\n","        \"Strongly Agree\": 5\n","    }\n","\n","    # Function to clean and map scores\n","    def map_scores(value):\n","        # Clean the string to remove leading/trailing whitespaces\n","        value = str(value).strip()\n","        # Return the mapped score or NaN if the value is not found\n","        return answer_scores.get(value, np.nan)\n","\n","    # Function to reverse score the BFI items\n","    def nfc_reverse_score(value):\n","        if pd.isna(value):\n","            return value  # Preserve NaN values\n","        return 6 - value\n","\n","    # List of BFI items\n","    nfc_columns = [f'NeedForCognition _{i}' for i in range(1, 19)]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[nfc_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","\n","    # Apply mapping and cleaning\n","    scored_data[nfc_columns] = scored_data[nfc_columns].applymap(map_scores)\n","\n","    # Apply reverse scoring\n","    reverse_scored_items = [3, 4, 5, 7, 8, 9, 12, 16, 17]\n","    reverse_columns = [f'NeedForCognition _{item}' for item in reverse_scored_items]\n","    scored_data[reverse_columns] = scored_data[reverse_columns].applymap(nfc_reverse_score)\n","\n","    # Final and additional metrics\n","    scored_data['NFC_Final_Score'] = scored_data[nfc_columns].apply(lambda x: x.sum() if x.count() >= 1 else np.nan, axis=1)\n","    scored_data['NFC_mean_of_Answers'] = scored_data[nfc_columns].apply(lambda x: x.mean() if x.count() >= 1 else np.nan, axis=1)\n","    scored_data['NFC_SD_of_Answers'] = scored_data[nfc_columns].std(axis=1)\n","    scored_data['NFC_Questions_Not_Answered'] = scored_data[nfc_columns].isna().sum(axis=1)\n","\n","    # Add metadata\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"muQaQISCfLo4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Emotional Reaction to Social Media Use"],"metadata":{"id":"lD9N-RGtRy3J"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_emotion_socialmedia(df, path):\n","    # Mapping\n","    answer_scores = {\n","        \"1 (Never)\": 1,\n","        \"2\":          2,\n","        \"3\":          3,\n","        \"4\":          4,\n","        \"5 (Always)\": 5\n","    }\n","    def map_scores(value):\n","        return answer_scores.get(str(value).strip(), np.nan)\n","\n","    # Define columns\n","    esm_cols = [f\"EmotionSocialMedia_{i}\" for i in range(1, 11)]\n","    n_items  = len(esm_cols)\n","\n","    # Keep original header\n","    scored_data = df[esm_cols].copy()\n","    scored_data[esm_cols] = scored_data[esm_cols].applymap(map_scores)\n","\n","    # Missing-value metrics\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Total score (only if ≤50% missing)\n","    def compute_total(row):\n","        return row[esm_cols].sum(min_count=1) if row['Blank_Count'] <= n_items/2 else np.nan\n","    scored_data['ESM_Total_Score'] = scored_data.apply(compute_total, axis=1)\n","\n","    # Item-level SD\n","    scored_data['ESM_Item_SD'] = scored_data[esm_cols].std(axis=1, skipna=True)\n","\n","    # Subscale\n","    pos = [f\"EmotionSocialMedia_{i}\" for i in [1,3,4,6,9]]\n","    neg = [f\"EmotionSocialMedia_{i}\" for i in [2,5,7,8,10]]\n","    scored_data['Positive_Total'] = scored_data[pos].sum(axis=1, skipna=True)\n","    scored_data['Negative_Total'] = scored_data[neg].sum(axis=1, skipna=True)\n","\n","    # Hash ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s1_prolific_id].apply(hash_id)\n","    )\n","\n","    # Add metadata\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"rk9GFfB4VFY5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Performance Pressure"],"metadata":{"id":"j1fBQ_V-dwjK"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_performance_pressure(df, path):\n","    # Only these six items\n","    pp_cols = [\n","        'PerformPressure_1_1',\n","        'PerformPressure_2_1',\n","        'PerformPressure_3_1',\n","        'PerformPressure_4',\n","        'PerformPressure_5',\n","        'PerformPressure_6_1'\n","    ]\n","\n","    # Copy raw responses (preserves your original headers)\n","    scored_data = df[pp_cols].copy()\n","\n","    # Hash ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # Add metadata & save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"EET5krOedzgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Flow/hyperfocusing"],"metadata":{"id":"Qlpk3HMnTk62"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_fss_s3(df, path):\n","    # grab all your Flow/HypFocus columns (drop any timing ones)\n","    fss_cols = [c for c in df.columns\n","                if c.startswith('Flow/HypFocus') and 'Time' not in c]\n","    scored_data = df[fss_cols].copy()\n","\n","    # build one big map for all the verbal labels\n","    text_map = {\n","        'Not At All':   1,\n","        'Partly':       4,\n","        'Very Much':    7,\n","        # Q4 scale\n","        'Easy':         1,\n","        'Average':      4,\n","        'Difficult':    7,\n","        # Q5 scale\n","        'Low':          1,\n","        'High':         7,\n","        # Q6 scale\n","        'Too Low':      1,\n","        'Just Right':   4,\n","        'Too High':     7\n","    }\n","\n","    # define columns\n","    num_cols = [f'Flow/HypFocus_3_{i}' for i in range(1,14)]\n","    num_cols += ['Flow/HypFocus_4_1', 'Flow/HypFocus_5_1', 'Flow/HypFocus_6_1']\n","\n","    # replace any of those verbal labels with numbers, then force numeric\n","    for col in num_cols:\n","        if col in scored_data:\n","            scored_data[col] = scored_data[col].replace(text_map)\n","            scored_data[col] = pd.to_numeric(scored_data[col], errors='coerce')\n","\n","    # missing-data metrics on those numeric cols\n","    scored_data['Blank_Count']      = scored_data[num_cols].isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / len(num_cols)\n","\n","    # subscale sums\n","    flow_items     = [f'Flow/HypFocus_3_{i}' for i in range(1,11) if f'Flow/HypFocus_3_{i}' in scored_data]\n","    worry_items    = [f'Flow/HypFocus_3_{i}' for i in (11,12,13)        if f'Flow/HypFocus_3_{i}' in scored_data]\n","    fluency_idx    = (2,4,5,7,8,9)\n","    absorption_idx = (1,3,6,10)\n","    fluency_items    = [f'Flow/HypFocus_3_{i}' for i in fluency_idx    if f'Flow/HypFocus_3_{i}' in scored_data]\n","    absorption_items = [f'Flow/HypFocus_3_{i}' for i in absorption_idx if f'Flow/HypFocus_3_{i}' in scored_data]\n","\n","    scored_data['Flow_Total_Score']  = scored_data[flow_items].sum(axis=1, skipna=True)\n","    scored_data['Worry_Score']       = scored_data[worry_items].sum(axis=1, skipna=True)\n","    scored_data['Fluency_Score']     = scored_data[fluency_items].sum(axis=1, skipna=True)\n","    scored_data['Absorption_Score']  = scored_data[absorption_items].sum(axis=1, skipna=True)\n","\n","    # mask out all of those metrics if they answered \"No\" to Q1\n","    no_mask = df['Flow/HypFocus_1'].astype(str).str.strip().eq('No')\n","    # clear out summary fields on those rows\n","    for c in ['Blank_Count','Blank_Percentage',\n","              'Flow_Total_Score','Worry_Score',\n","              'Fluency_Score','Absorption_Score']:\n","        scored_data.loc[no_mask, c] = np.nan\n","\n","    # hash subject id\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # add metadata header and write out\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"_kI137t3Tn5G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Object-Spatial Imagery Questionnaire (OSIQ)"],"metadata":{"id":"l2hgSGpUbLtt"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import csv\n","import hashlib\n","\n","def score_osiq(df, path):\n","    # Define items\n","    osiq_cols = [f\"OSIQ_{i}\" for i in range(1, 31)]\n","    object_idx = {4,7,8,10,11,12,16,17,19,21,22,25,26,28,30}\n","\n","    # Mapping\n","    answer_map = {\n","        \"1 (totally disagree)\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5 (totally agree)\": 5\n","    }\n","    scored = df[osiq_cols].copy()\n","    scored[osiq_cols] = scored[osiq_cols].applymap(lambda x: answer_map.get(str(x).strip(), np.nan))\n","\n","    # Reverse‐score #27\n","    scored[\"OSIQ_27\"] = scored[\"OSIQ_27\"].apply(lambda x: 6 - x if pd.notna(x) else np.nan)\n","\n","    # Missing‐data metrics\n","    n = len(osiq_cols)\n","    scored[\"Blank_Count\"]      = scored[osiq_cols].isna().sum(axis=1)\n","    scored[\"Blank_Percentage\"] = scored[\"Blank_Count\"] / n\n","\n","    # Subscale means\n","    obj_cols = [f\"OSIQ_{i}\" for i in object_idx]\n","    spa_cols = [c for c in osiq_cols if c not in obj_cols]\n","    scored[\"OSIQ_Object_Score\"]  = scored[obj_cols].mean(axis=1, skipna=True)\n","    scored[\"OSIQ_Spatial_Score\"] = scored[spa_cols].mean(axis=1, skipna=True)\n","\n","    # Hashed ID\n","    scored.insert(\n","        0,\n","        \"Subject_ID\",\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # Final headers\n","    headers = list(scored.columns)\n","    type_row = []\n","    for h in headers:\n","        m = re.match(r\"OSIQ_(\\d+)$\", h)\n","        if m:\n","            idx = int(m.group(1))\n","            type_row.append(\"Object\" if idx in object_idx else \"Spatial\")\n","        else:\n","            type_row.append(\"\")   # blanks for Subject_ID, Blank_Count, etc.\n","\n","    # Write CSV with header + type row + data\n","    with open(path, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(headers)\n","        writer.writerow(type_row)\n","        for row in scored.itertuples(index=False, name=None):\n","            writer.writerow(row)\n","\n","    return scored"],"metadata":{"id":"eJtFCKZZbPv3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Frequency of Social Media Use"],"metadata":{"id":"M7DyzqASja6A"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import csv\n","import hashlib\n","\n","def score_freq_social_media(df, path):\n","    # Raw survey columns\n","    cols = [\n","        \"FreqSocialMediaUse_1_1\",  # Twitter/X\n","        \"FreqSocialMediaUse_1_2\",  # Instagram\n","        \"FreqSocialMediaUse_1_3\",  # Facebook\n","        \"FreqSocialMediaUse_1_4\",  # Snapchat\n","        \"FreqSocialMediaUse_1_5\",  # YouTube\n","        \"FreqSocialMediaUse_1_7\",  # Pinterest\n","        \"FreqSocialMediaUse_1_8\",  # Reddit\n","        \"FreqSocialMediaUse_1_9\",  # TikTok\n","        \"FreqSocialMediaUse_2\",    # Overall effect on society\n","        \"FreqSocialMediaUse_3\"     # Overall effect on you personally\n","    ]\n","\n","    # Labels for all raw columns\n","    label_map = {\n","        \"FreqSocialMediaUse_1_1\": \"Twitter/X\",\n","        \"FreqSocialMediaUse_1_2\": \"Instagram\",\n","        \"FreqSocialMediaUse_1_3\": \"Facebook\",\n","        \"FreqSocialMediaUse_1_4\": \"Snapchat\",\n","        \"FreqSocialMediaUse_1_5\": \"YouTube\",\n","        \"FreqSocialMediaUse_1_7\": \"Pinterest\",\n","        \"FreqSocialMediaUse_1_8\": \"Reddit\",\n","        \"FreqSocialMediaUse_1_9\": \"TikTok\",\n","        \"FreqSocialMediaUse_2\":   \"Effect on society\",\n","        \"FreqSocialMediaUse_3\":   \"Effect on you personally\"\n","    }\n","\n","    # copy raw text responses\n","    scored = df[cols].copy()\n","\n","    # blank metrics\n","    n_items = len(cols)\n","    scored['Blank_Count']      = scored.isna().sum(axis=1)\n","    scored['Blank_Percentage'] = scored['Blank_Count'] / n_items\n","\n","    # numeric duplicates only for the first 8 frequency items\n","    usage_cols = cols[:8]\n","    freq_map = {\n","        \"Never\": 0,\n","        \"Less Often\": 1,\n","        \"Several Times a Week\": 2,\n","        \"About Once a Day\": 3,\n","        \"Several Times a Day\": 4,\n","        \"Almost Constantly\": 5,\n","        \"I Don’t Know What This Is\": -1\n","    }\n","    def map_freq(val):\n","        return freq_map.get(str(val).strip(), np.nan)\n","\n","    num_df = df[usage_cols].copy().applymap(map_freq)\n","    num_cols = [c + \"_num\" for c in usage_cols]\n","    num_df.columns = num_cols\n","\n","    # append numeric block\n","    scored = pd.concat([scored, num_df], axis=1)\n","\n","    # hash ID\n","    scored.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # write CSV with two‐line header\n","    with open(path, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","\n","        # header\n","        writer.writerow(scored.columns)\n","\n","        # second row:\n","        #    - blank under Subject_ID\n","        #    - human labels under all 10 raw columns\n","        #    - blanks under Blank_Count & Blank_Percentage\n","        #    - labels under the 8 numeric columns\n","        second = (\n","            [\"\"] +\n","            [label_map[c] for c in cols] +\n","            [\"\", \"\"] +  # blanks under the two metrics\n","            [label_map[c] for c in usage_cols]\n","        )\n","        writer.writerow(second)\n","\n","        # data rows (nan → blank)\n","        for row in scored.itertuples(index=False, name=None):\n","            clean = [\"\" if pd.isna(v) else v for v in row]\n","            writer.writerow(clean)\n","\n","    return scored"],"metadata":{"id":"8gM8O1wtjfZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Views on AI"],"metadata":{"id":"qLNy081savti"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_viewsai(df, path):\n","    # Raw ViewsAI columns (preserves your MultiIndex question headers)\n","    viewsai_cols = [\n","        'ViewsAI_1',\n","        'ViewsAI_2_1', 'ViewsAI_2_2', 'ViewsAI_2_3',\n","        'ViewsAI_3_1', 'ViewsAI_3_2', 'ViewsAI_3_3',\n","        'ViewsAI_3_4', 'ViewsAI_3_5', 'ViewsAI_3_6',\n","        'ViewsAI_3_7', 'ViewsAI_3_8', 'ViewsAI_3_9',\n","        'ViewsAI_3_10', 'ViewsAI_3_11',\n","        'ViewsAI_5',\n","        'ViewsAI_6',\n","        'ViewsAI_7'\n","    ]\n","\n","    # Copy raw responses\n","    scored_data = df[viewsai_cols].copy()\n","\n","    # Missing‐data metrics over those 18 items\n","    n_items = len(viewsai_cols)\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # hash subject id\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # add metadata\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"pDt_lxq0ayv0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 VVIQ"],"metadata":{"id":"WfOLcuzdHM70"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","# Vividness of Visual Imagery Questionnaire (VVIQ) scoring for Session 3\n","\n","\n","def score_vviq_s3(df, path):\n","    # Define the VVIQ item columns\n","    vviq_cols = [f'VVIQ_{i}' for i in range(1, 17)]\n","    n_items = len(vviq_cols)\n","\n","    # Copy responses\n","    scored_data = df[vviq_cols].copy()\n","\n","    # Map responses to numeric 1-5\n","    answer_map = {\n","        \"No image at all (only \\\"knowing\\\" that you are thinking of the object)\": 1,\n","        \"Vague and dim\": 2,\n","        \"Moderately clear and vivid\": 3,\n","        \"Clear and reasonably vivid\": 4,\n","        \"Perfectly clear and as vivid as normal vision\": 5\n","    }\n","    scored_data[vviq_cols] = scored_data[vviq_cols].applymap(\n","        lambda x: answer_map.get(str(x).strip(), np.nan)\n","    )\n","\n","    # Missing-value metrics\n","    scored_data['Blank_Count']      = scored_data.isna().sum(axis=1)\n","    scored_data['Blank_Percentage'] = scored_data['Blank_Count'] / n_items\n","\n","    # Total score (only if ≤50% missing)\n","    def compute_total(row):\n","        return row[vviq_cols].sum(min_count=1) if row['Blank_Count'] <= n_items/2 else np.nan\n","    scored_data['VVIQ_Total'] = scored_data.apply(compute_total, axis=1)\n","\n","    # Item-level SD\n","    scored_data['VVIQ_Item_SD'] = scored_data[vviq_cols].std(axis=1, skipna=True)\n","\n","    # Hash Subject_ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # Add metadata & save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"l1jsP2mThWsW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Self-report Aphantasia"],"metadata":{"id":"dP3lPWkUHQqJ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","\n","def score_aphantasia(df, path):\n","    # Aphantasia questions\n","    raw_cols = ['Aphantasia_1', 'Aphantasia_2']\n","    num_cols = [c + '_num' for c in raw_cols]\n","\n","    # Copy raw responses\n","    scored = df[raw_cols].copy()\n","\n","    # Map to numeric duplicates\n","    map1 = {\n","        \"I have never heard of aphantasia\": 4,\n","        \"I have heard of the term, but not sure what it is\": 3,\n","        \"I think I know what aphantasia is\": 2,\n","        \"I am very familiar with aphantasia\": 1\n","    }\n","    scored['Aphantasia_1_num'] = df['Aphantasia_1'].map(lambda v: map1.get(str(v).strip(), np.nan))\n","\n","    map2 = {\n","        \"I am confident I have aphantasia\": 1,\n","        \"I think I might have aphantasia\": 2,\n","        \"I think I might have normal imagery\": 3,\n","        \"I am confident I have normal mental imagery\": 4\n","    }\n","    scored['Aphantasia_2_num'] = df['Aphantasia_2'].map(lambda v: map2.get(str(v).strip(), np.nan))\n","\n","    # Missing‐data metrics on the numeric items\n","    n = len(num_cols)\n","    scored['Blank_Count']      = scored[num_cols].isna().sum(axis=1)\n","    scored['Blank_Percentage'] = scored['Blank_Count'] / n\n","\n","    # Hashed ID\n","    scored.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # Add metadata row and save\n","    scored = add_metadata_as_multiindex(scored, s3_metadata_row)\n","    scored.to_csv(path, index=False)\n","    return scored"],"metadata":{"id":"xeyz4rUdHVVJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Readiness Pt 2"],"metadata":{"id":"w2SSAP4dQl-h"}},{"cell_type":"code","source":["import pandas as pd\n","import hashlib\n","\n","# Readiness Part 2 scoring for Session 3, excluding any “Time” columns\n","def score_readiness_pt2_S3(df, path):\n","\n","    readinesspt2_columns = [\n","        col for col in df.columns\n","        if col.startswith('ReadinessPt2_') and 'Time' not in col\n","    ]\n","\n","    # Copy over\n","    scored_data = df[readinesspt2_columns].copy()\n","\n","    # Hashed Subject_ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(hash_id)\n","    )\n","\n","    # Session 3 metadata & save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"RJA1I5NxQo6l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3 Attention Checks"],"metadata":{"id":"uz8qNrMhXTOh"}},{"cell_type":"code","source":["import pandas as pd\n","import hashlib\n","\n","def score_attn_S3(df, path):\n","    # List of attention check items (blocks 1–3, attempts 1–4)\n","    attn_columns = [f'AttnCheck_{i}.{j}' for i in range(1, 4) for j in range(1, 5)]\n","\n","    # Copy just those columns\n","    scored_data = df[attn_columns].copy()\n","\n","    # Count attempts per block\n","    for i in range(1, 4):\n","        cols = [c for c in attn_columns if c.startswith(f'AttnCheck_{i}.')]\n","        scored_data[f'AttnCheck_{i}_attempts'] = scored_data[cols].notna().sum(axis=1)\n","\n","    # Summaries\n","    attempt_cols = [c for c in scored_data.columns if c.endswith('_attempts')]\n","    # total attempts minus number of blocks touched\n","    total_sum = scored_data[attempt_cols].sum(axis=1)\n","    checks_attempted = (scored_data[attempt_cols] > 0).sum(axis=1)\n","    scored_data['Attn_Redo_Count']     = total_sum - checks_attempted\n","    # how many checks were failed (all 4 tries used)\n","    scored_data['Failed_Attn_Checks']  = (scored_data[attempt_cols] == 4).sum(axis=1)\n","    # flag if they maxed out redos\n","    scored_data['Attn_Max_Redos?']     = scored_data['Attn_Redo_Count'] >= 7\n","\n","    # Hash Prolific ID\n","    scored_data.insert(\n","        0,\n","        'Subject_ID',\n","        df[s3_prolific_id].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n","    )\n","\n","    # metadata and save\n","    scored_data = add_metadata_as_multiindex(scored_data, s3_metadata_row)\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"5EVQ0daPXWbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Readiness S1"],"metadata":{"id":"bXFpG7DaS4qk"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_readiness(df, path):\n","\n","    # List of readiness items\n","    ##readiness_columns = [f'Readiness_{i}' for i in range(1, 17)]  # Adjust the range according to the number of items in readiness\n","    readiness_columns = [col for col in df.columns if col.startswith(f'Readiness_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[readiness_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"VLSq4hzMS6wa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Second Readiness S1"],"metadata":{"id":"lx6PaWrR-9SJ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_second_readiness(df, path):\n","\n","    # List of readiness items\n","    ##readiness_columns = [f'Readiness_{i}' for i in range(1, 17)]  # Adjust the range according to the number of items in readiness\n","    readiness_columns = [col for col in df.columns if col.startswith(f'Second_Readiness')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[readiness_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"FaKnGWmc_CNA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Readiness S2"],"metadata":{"id":"mPdVcbAQR_oa"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_readiness_S2(df, path):\n","\n","    # List of readiness items\n","    ##readiness_columns = [f'Readiness_{i}' for i in range(1, 17)]  # Adjust the range according to the number of items in readiness\n","    readiness_columns = [col for col in df.columns if col.startswith(f'Readiness_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[readiness_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path,index=False)\n","\n","    return scored_data"],"metadata":{"id":"aI1vM3_lSDe2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# S2 Second Readiness"],"metadata":{"id":"CO4hSwvKBlPa"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import hashlib\n","from google.colab import drive\n","\n","# Big Five Inventory (BFI) scoring\n","def score_second_readiness_S2(df, path):\n","\n","    # List of readiness items\n","    ##readiness_columns = [f'Readiness_{i}' for i in range(1, 17)]  # Adjust the range according to the number of items in readiness\n","    readiness_columns = [col for col in df.columns if col.startswith(f'ReadinessPt2_')]\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[readiness_columns].copy()\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data"],"metadata":{"id":"IXUTMCegBoAw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Attention Checks"],"metadata":{"id":"aUv5dhmZBCqv"}},{"cell_type":"code","source":["## Need to save column for each of the attention check questions\n","## Subject number and how many tries from each attention check\n","\n","# Attention check (attn) scoring\n","def score_attn_S1(df, path):\n","\n","# List of attention check items\n","    attn_columns = [f'Attn_Check_{i}_{j}' for i in range(1, 4) for j in range(1,5) ]  # Adjust the range according to the number of items in attn checks\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[attn_columns].copy()\n","\n","    # Create a dictionary to hold the counts\n","    attn_check_counts = {}\n","\n","    # Create summary columns based on the counts for each row\n","    for i in range(1, 4):\n","        cols = [col for col in scored_data.columns if col.startswith(f'Attn_Check_{i}_')]\n","        scored_data[f'attn_check_{i}_attempts'] = scored_data[cols].notna().sum(axis=1)\n","\n","    # Summaries for attention checks\n","    attempt_columns = [col for col in scored_data.columns if col.startswith('attn_check_')]\n","    failed_checks = (scored_data[attempt_columns] == 4).sum(axis=1)\n","\n","    checks_attempted = (scored_data[attempt_columns] > 0).sum(axis=1)\n","    total_sum = scored_data[attempt_columns].sum(axis=1)\n","    scored_data['Attn_Redo_Count'] = total_sum - checks_attempted\n","    scored_data['Failed_Attn_Checks'] = failed_checks\n","    scored_data['Attn_Max_Redos?'] = scored_data['Attn_Redo_Count'] >= 7\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s1_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s1_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path,index=False)\n","\n","    return scored_data\n"],"metadata":{"id":"j27D7QG2BFaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# S2 Attention Checks"],"metadata":{"id":"TcnUkLhDLZXJ"}},{"cell_type":"code","source":["## Need to save column for each of the attention check questions\n","## Subject number and how many tries from each attention check\n","\n","# Attention check (attn) scoring\n","def score_attn_S2(df, path):\n","\n","# List of attention check items\n","    attn_columns = [f'AttnCheck{i}.{j}' for i in range(1, 4) for j in range(1,5) ]  # Adjust the range according to the number of items in attn checks\n","\n","    # Create a copy of the relevant columns\n","    scored_data = df[attn_columns].copy()\n","\n","    # Create a dictionary to hold the counts\n","    attn_check_counts = {}\n","\n","    # Create summary columns based on the counts for each row\n","    for i in range(1, 4):\n","        cols = [col for col in scored_data.columns if col.startswith(f'AttnCheck{i}')]\n","        scored_data[f'AttnCheck_{i}_attempts'] = scored_data[cols].notna().sum(axis=1)\n","\n","    # Summaries for attention checks\n","    attempt_columns = [col for col in scored_data.columns if col.startswith('attn_check_')]\n","    failed_checks = (scored_data[attempt_columns] == 4).sum(axis=1)\n","\n","    checks_attempted = (scored_data[attempt_columns] > 0).sum(axis=1)\n","    total_sum = scored_data[attempt_columns].sum(axis=1)\n","    scored_data['Attn_Redo_Count'] = total_sum - checks_attempted\n","    scored_data['Failed_Attn_Checks'] = failed_checks\n","    scored_data['Attn_Max_Redos?'] = scored_data['Attn_Redo_Count'] >= 7\n","\n","    # Add hashed `PROLIFIC_PID` to the result\n","    scored_data.insert(0, 'Subject_ID', df[s2_prolific_id].apply(hash_id))\n","\n","    # Add metadata as a multi-index (if applicable)\n","    output_data = add_metadata_as_multiindex(scored_data, s2_metadata_row)\n","\n","    # Save the scored data\n","    scored_data.to_csv(path, index=False)\n","\n","    return scored_data\n"],"metadata":{"id":"_wqul8s2LcBQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xMoUcPWyfvMR"},"source":["# Score Surveys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dn9JD8qf6mz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760028219860,"user_tz":240,"elapsed":2773,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"660b9e74-2619-4891-94b4-9eb66ddca9d2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1748562585.py:39: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  scored_data[nfc_columns] = scored_data[nfc_columns].applymap(map_scores)\n","/tmp/ipython-input-1748562585.py:44: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  scored_data[reverse_columns] = scored_data[reverse_columns].applymap(nfc_reverse_score)\n"]}],"source":["# Session 1 Paths\n","aq_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_AQ.csv'\n","bis_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_BIS.csv'\n","bfi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_BFI.csv'\n","adhd_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_ADHD.csv'\n","stai_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_STAI.csv'\n","ocd_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_OCD.csv'\n","grit_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_GRIT.csv'\n","oldenburg_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_OLDENBURG.csv'\n","maslach_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_MASLACH.csv'\n","attn_path = '/content/drive/My Drive/battery_survey_scoring/analyses/JG_scored_Attn_Checks.csv'\n","readi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Readiness.csv'\n","second_readi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Second_Readiness.csv'\n","demos_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Demos.csv'\n","demos_test_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_test_Demos.csv'\n","overview_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Overview.csv'\n","wordle_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_Wordle.csv'\n","\n","\n","\n","# Session 2 Paths\n","bfne_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_BFNE.csv'\n","cusados_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_CUSADOS.csv'\n","ucla_loneliness_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_UCLA_Loneliness.csv'\n","gallup_bff_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_Gallup_BFF.csv'\n","audit_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_AUDIT.csv'\n","brcs_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_BRCS.csv'\n","pastimes_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_PASTIMES.csv'\n","psqi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_PSQI.csv'\n","mmti_s_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_AL_scored_MMTI-S.csv'\n","panas_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_PANAS.csv'\n","pfi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_PFI.csv'\n","pfi_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_PFI_test.csv'\n","attn_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/JG_s2_scored_Attn_Checks.csv'\n","readi_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_s2_scored_Readiness.csv'\n","overview_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_s2_scored_Overview.csv'\n","demos_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_s2_scored_Demos.csv'\n","cudit_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_scored_CUDIT.csv'\n","second_readi_s2_path = '/content/drive/My Drive/battery_survey_scoring/analyses/J_s2_scored_Second_Readiness.csv'\n","\n","\n","\n","# Session 3 Paths\n","esm_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_EmotionSocialMedia.csv'\n","perf_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_PerformancePressure.csv'\n","osiq_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_OSIQ.csv'\n","freq_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_FreqSocialMediaUse.csv'\n","viewsai_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_ViewsAI.csv'\n","aphantasia_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_Aphantasia.csv'\n","demo_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_S3_Demos.csv'\n","readi_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_Readiness.csv'\n","readi2_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_ReadinessPt2.csv'\n","attn_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_S3_Attn_Checks.csv'\n","flow_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_Flow.csv'\n","vviq_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_VVIQ.csv'\n","loc_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/scored_LOC.csv'\n","nfc_s3_path    = '/content/drive/My Drive/battery_survey_scoring/analyses/scored_NFC.csv'\n","overview_s3_path = '/content/drive/My Drive/battery_survey_scoring/analyses/SM_scored_Overview_S3.csv'\n","\n","\n","# Session 1 Function Execution\n","# scored_aq_data = score_aq(s1_filtered_data, aq_path)\n","# scored_bis_data = score_bis(s1_filtered_data, bis_path)\n","# scored_bfi_data = score_bfi(s1_filtered_data, bfi_path)\n","# scored_adhd_data = score_adhd(s1_filtered_data, adhd_path)\n","# scored_stai_data = score_stai(s1_filtered_data, stai_path)\n","# scored_ocd_data = score_ocd(s1_filtered_data, ocd_path)\n","# scored_grit_data = score_grit(s1_filtered_data, grit_path)\n","# scored_oldenburg_data = score_oldenburg(s1_filtered_data, oldenburg_path)\n","# scored_maslach_data = score_maslach(s1_filtered_data, maslach_path)\n","# scored_attn_data = score_attn_S1(s1_filtered_data, attn_path)\n","# scored_readi_data = score_readiness(s1_filtered_data, readi_path)\n","# scored_demos_data = score_demographics(s1_filtered_data, demos_path)\n","# test_scored_demos_data = score_demographics_test(s1_filtered_data, demos_test_path)\n","# scored_overview_data = score_overview(s1_prolific_combined_df, overview_path)\n","# scored_wordle_data = score_wordle(s1_filtered_data, wordle_path)\n","# scored_second_readi_data = score_second_readiness(s1_filtered_data, second_readi_path)\n","\n","\n","\n","# Session 2 Function Execution\n","# scored_bfne_data = score_bfne(s2_filtered_data, bfne_path)\n","# scored_cusados_data = score_cusados(s2_filtered_data, cusados_path)\n","# scored_ucla_loneliness_data = score_ucla_loneliness(s2_filtered_data, ucla_loneliness_path)\n","# scored_gallup_bff_data = score_gallup_bff(s2_filtered_data, gallup_bff_path)\n","# scored_audit_data = score_audit(s2_filtered_data, audit_path)\n","# scored_brcs_data = score_brcs(s2_filtered_data, brcs_path)\n","# scored_pastimes_data = score_pastimes(s2_filtered_data, pastimes_path)\n","# scored_psqi_data = score_psqi(s2_filtered_data, psqi_path)\n","# scored_mmti_s_data = score_mmti_s(s2_filtered_data, mmti_s_path)\n","# scored_panas_data = score_panas(s2_filtered_data, panas_path)\n","# scored_pfi_data = score_pfi(s2_filtered_data, pfi_path)\n","# scored_pfi_data = score_pfi_with_questions_inline(s2_filtered_data, pfi_path)\n","# scored_s2_attn_data = score_attn_S2(s2_filtered_data, attn_s2_path)\n","# scored_s2_readi_data = score_readiness_S2(s2_filtered_data, readi_s2_path)\n","# scored_s2_overview_data = score_overview_s2(s2_prolific_data, overview_s2_path)\n","# scored_s2_demos_data = score_demographics_2(s2_filtered_data, demos_s2_path)\n","# scored_cudit_data = score_cudit(s2_filtered_data, cudit_path)\n","# scored_second_readi_s2_data = score_second_readiness_S2(s2_filtered_data, second_readi_s2_path)\n","\n","# Session 3 Function Execution\n","# scored_esm_data = score_emotion_socialmedia(s3_filtered_data, esm_path)\n","# scored_perf_data = score_performance_pressure(s3_filtered_data, perf_path)\n","# scored_osiq_data = score_osiq(s3_filtered_data, osiq_path)\n","# scored_freq = score_freq_social_media(s3_filtered_data, freq_path)\n","# scored_viewsai_data = score_viewsai(s3_filtered_data, viewsai_path)\n","# scored_aphantasia = score_aphantasia(s3_filtered_data, aphantasia_path)\n","# scored_demos_s3 = score_demographics_s3(s3_filtered_data, demo_path)\n","# scored_readi_s3 = score_readiness_S3(s3_filtered_data, readi_s3_path)\n","# scored_readi_pt2_s3 = score_readiness_pt2_S3(s3_filtered_data, readi2_s3_path)\n","# scored_attn_s3 = score_attn_S3(s3_filtered_data, attn_s3_path)\n","# scored_flow_s3 = score_fss_s3(s3_filtered_data, flow_s3_path)\n","# scored_vviq_s3 = score_vviq_s3(s3_filtered_data, vviq_s3_path)\n","# scored_loc_s3 = score_loc(s3_filtered_data, loc_s3_path)\n","scored_nfc_s3  = score_nfc(s3_filtered_data, nfc_s3_path)\n","scored_overview_s3 = score_overview_s3(s3_prolific_data, overview_s3_path)"]},{"cell_type":"code","source":["#scored_cudit_data"],"metadata":{"id":"0vyqAVZqdUmL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Export to Excel Sheet with multiple tabs"],"metadata":{"id":"BzL5KS1j7rop"}},{"cell_type":"code","source":["#S2_bfne have session be a variable, all caps for acronyms\n","#test extra column in old file and new file\n","#add session 1 data\n","#attention check tabs (4 questions)\n","\n","# Create an Excel writer object\n","# with pd.ExcelWriter('/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data.xlsx') as writer:\n","#     # Write each DataFrame to a different sheet\n","#     scored_bfne_data.to_excel(writer, sheet_name='S2_bfne', index=True)\n","#     scored_cusados_data.to_excel(writer, sheet_name='S2_cusados', index=True)\n","#     scored_ucla_loneliness_data.to_excel(writer, sheet_name='S2_loneliness', index=True)\n","#     scored_gallup_bff_data.to_excel(writer, sheet_name='S2_gallup', index=True)\n","#     scored_audit_data.to_excel(writer, sheet_name='S2_audit', index=True)\n","#     scored_brcs_data.to_excel(writer, sheet_name='S2_brcs', index=True)\n","#     scored_pastimes_data.to_excel(writer, sheet_name='S2_pastimes', index=True)\n","#     scored_psqi_data.to_excel(writer, sheet_name='S2_psqi', index=True)\n","#     scored_mmti_s_data.to_excel(writer, sheet_name='S2_mmti', index=True)\n","#     scored_panas_data.to_excel(writer, sheet_name='S2_panas', index=True)\n","#     scored_pfi_data.to_excel(writer, sheet_name='S2_pfi', index=True)"],"metadata":{"id":"j4XJUKZn7q7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"RsIYtu6o-w2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760028219948,"user_tz":240,"elapsed":82,"user":{"displayName":"Justin Grady","userId":"18158704379059964495"}},"outputId":"f5155a32-cfec-4513-f0c1-61b11a24ead2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}]},{"cell_type":"markdown","source":["# Merge New Data with Excel Sheet"],"metadata":{"id":"ewCimX6Jxlp5"}},{"cell_type":"markdown","source":["This appends new rows to each tab and adds new tab while mainting the styling and enhancements to the original file"],"metadata":{"id":"MxBjnnBb5ghw"}},{"cell_type":"code","source":["# from openpyxl import load_workbook\n","# import pandas as pd\n","\n","# # File paths\n","# #original_excel_path = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_test.xlsx'\n","# original_excel_path = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_merged_2025_06_11_SRMEdits.xlsx'\n","# new_excel_path = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_7_22_2025.xlsx'\n","\n","# # Read new Excel file\n","# new_excel = pd.read_excel(new_excel_path, sheet_name=None)\n","\n","# # Load the original workbook with openpyxl\n","# wb = load_workbook(original_excel_path)\n","\n","# # Variable to track the total number of new unique Subject_IDs\n","# total_new_subject_ids = 0\n","\n","# # Dictionary to store added Subject_ID counts for each sheet\n","# sheet_subject_id_counts = {}\n","\n","# # Iterate through sheets\n","# for sheet_name, new_df in new_excel.items():\n","#     if sheet_name in wb.sheetnames:\n","#         ws = wb[sheet_name]\n","\n","#         # Convert the original sheet into a DataFrame, skipping empty rows\n","#         original_data = list(ws.values)\n","#         original_df = pd.DataFrame(original_data[1:], columns=original_data[0]).dropna(how=\"all\")\n","\n","#         # Align columns between original and new data\n","#         new_df = new_df[original_df.columns.intersection(new_df.columns)]\n","\n","#         # Identify new unique Subject_IDs in the new data\n","#         if \"Subject_ID\" in original_df.columns and \"Subject_ID\" in new_df.columns:\n","#             original_subject_ids = set(original_df[\"Subject_ID\"].dropna().unique())\n","#             new_subject_ids = set(new_df[\"Subject_ID\"].dropna().unique())\n","#             added_subject_ids = new_subject_ids - original_subject_ids\n","\n","#             # Update the total count\n","#             sheet_subject_id_counts[sheet_name] = len(added_subject_ids)\n","#             total_new_subject_ids += len(added_subject_ids)\n","\n","#             # Print details for this sheet\n","#             print(f\"Sheet: {sheet_name}\")\n","#             print(f\"New unique Subject_IDs added: {len(added_subject_ids)}\")\n","#         else:\n","#             sheet_subject_id_counts[sheet_name] = 0\n","#             print(f\"Sheet: {sheet_name} - No Subject_ID column found.\")\n","\n","#         # Concatenate and remove duplicates across all columns\n","#         combined_df = pd.concat([original_df, new_df], ignore_index=True).drop_duplicates()\n","\n","#         # Clear the sheet (except the header row) but keep its styles\n","#         for row in ws.iter_rows(min_row=2, max_row=ws.max_row):  # Skip header\n","#             for cell in row:\n","#                 cell.value = None\n","\n","#         # Write updated data back to the sheet\n","#         for r_idx, row in combined_df.iterrows():\n","#             for c_idx, value in enumerate(row, start=1):\n","#                 ws.cell(row=r_idx + 2, column=c_idx, value=value)  # Start writing from row 2\n","\n","#     else:\n","#         # Add new sheet for new data\n","#         new_ws = wb.create_sheet(sheet_name)\n","#         # Write the header first\n","#         for c_idx, col_name in enumerate(new_df.columns, start=1):\n","#             new_ws.cell(row=1, column=c_idx, value=col_name)\n","#         # Write the data\n","#         for r_idx, row in new_df.iterrows():\n","#             for c_idx, value in enumerate(row, start=1):\n","#                 new_ws.cell(row=r_idx + 2, column=c_idx, value=value)\n","\n","# # Remove blank rows from all worksheets\n","# for ws in wb.worksheets:\n","#     rows_to_delete = []\n","#     for row in ws.iter_rows(min_row=1, max_row=ws.max_row):\n","#         if all(cell.value is None or str(cell.value).strip() == '' for cell in row):\n","#             rows_to_delete.append(row[0].row)\n","\n","#     for row_idx in reversed(rows_to_delete):\n","#         ws.delete_rows(row_idx)\n","\n","# # Save the updated workbook\n","# wb.save(original_excel_path)\n","\n","# # Print the total number of new unique Subject_IDs across all sheets\n","# print(f\"\\nTotal new unique Subject_IDs added across all sheets: {total_new_subject_ids}\")\n","# for sheet_name, count in sheet_subject_id_counts.items():\n","#     print(f\"Sheet: {sheet_name}, New Subject_IDs added: {count}\")"],"metadata":{"id":"nbkPlmqd6M7S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sarah update"],"metadata":{"id":"HUyMN7NA0_Lg"}},{"cell_type":"code","source":["# from openpyxl import load_workbook\n","# from openpyxl.cell.cell import MergedCell\n","# import pandas as pd\n","\n","# # File paths\n","# original_excel_path = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_merged_2025_06_11_SRMEdits.xlsx'\n","# new_excel_path      = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_7_22_2025.xlsx'\n","# # <— here’s the new one:\n","# output_excel_path   = '/content/drive/My Drive/battery_survey_scoring/data/excel_data/battery_data_merged_2025_07_22.xlsx'\n","\n","# # Read all sheets from the new workbook\n","# new_excel = pd.read_excel(new_excel_path, sheet_name=None)\n","\n","# # Load the original workbook\n","# wb = load_workbook(original_excel_path)\n","\n","# total_new_subject_ids = 0\n","# sheet_subject_id_counts = {}\n","\n","# for sheet_name, new_df in new_excel.items():\n","#     if sheet_name in wb.sheetnames:\n","#         ws = wb[sheet_name]\n","\n","#         # Read existing sheet into DataFrame\n","#         original_data = list(ws.values)\n","#         original_df   = (\n","#             pd.DataFrame(original_data[1:], columns=original_data[0])\n","#               .dropna(how=\"all\")\n","#         )\n","\n","#         # Drop any duplicated columns\n","#         original_df = original_df.loc[:, ~original_df.columns.duplicated()]\n","#         new_df      = new_df.loc[:, ~new_df.columns.duplicated()]\n","\n","#         # Align columns\n","#         common = original_df.columns.intersection(new_df.columns)\n","#         original_df = original_df[common]\n","#         new_df      = new_df[common]\n","\n","#         # Count new Subject_IDs\n","#         if \"Subject_ID\" in common:\n","#             orig_ids = set(original_df[\"Subject_ID\"].dropna())\n","#             new_ids  = set(new_df[\"Subject_ID\"].dropna())\n","#             added    = new_ids - orig_ids\n","#             sheet_subject_id_counts[sheet_name] = len(added)\n","#             total_new_subject_ids += len(added)\n","#             print(f\"Sheet: {sheet_name} — New IDs: {len(added)}\")\n","#         else:\n","#             sheet_subject_id_counts[sheet_name] = 0\n","#             print(f\"Sheet: {sheet_name} — No Subject_ID column.\")\n","\n","#         # Merge & dedupe\n","#         combined_df = pd.concat([original_df, new_df], ignore_index=True)\\\n","#                         .drop_duplicates()\n","\n","#         # Clear old rows (skip merged‐cell placeholders)\n","#         for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n","#             for cell in row:\n","#                 if isinstance(cell, MergedCell):\n","#                     continue\n","#                 cell.value = None\n","\n","#         # Write merged data back\n","#         for r_idx, row in combined_df.iterrows():\n","#             for c_idx, val in enumerate(row, start=1):\n","#                 ws.cell(row=r_idx+2, column=c_idx, value=val)\n","\n","#     else:\n","#         # New sheet: just write it\n","#         new_ws = wb.create_sheet(sheet_name)\n","#         for c_idx, col in enumerate(new_df.columns, start=1):\n","#             new_ws.cell(row=1, column=c_idx, value=col)\n","#         for r_idx, row in new_df.iterrows():\n","#             for c_idx, val in enumerate(row, start=1):\n","#                 new_ws.cell(row=r_idx+2, column=c_idx, value=val)\n","\n","# # Drop fully blank rows\n","# for ws in wb.worksheets:\n","#     blank_rows = []\n","#     for row in ws.iter_rows(min_row=1, max_row=ws.max_row):\n","#         if all(cell.value in (None, \"\") for cell in row):\n","#             blank_rows.append(row[0].row)\n","#     for rid in reversed(blank_rows):\n","#         ws.delete_rows(rid)\n","\n","# # SAVE UNDER A NEW FILENAME\n","# wb.save(output_excel_path)\n","\n","# # Summary\n","# print(f\"\\nTotal new unique IDs added: {total_new_subject_ids}\")\n","# for sheet, cnt in sheet_subject_id_counts.items():\n","#     print(f\"  {sheet}: {cnt}\")"],"metadata":{"id":"VYPh75_BzALG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OjE9U4g_jljL"},"source":["# Scrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IgMTzJ_jnLg"},"outputs":[],"source":["# # Initialize with PID and has_Ts_and_Ls (and other demos)\n","# master_df = filtered_data[['Q5', 'has_Ts_and_Ls']].copy()\n","# master_df['Subject_ID'] = filtered_data['Q5'].apply(hash_id)\n","\n","# # Selecting specific AQ columns to merge\n","# aq_columns_to_merge = [\n","#     'AQ_Social_Skill', 'AQ_Attention_Switching', 'AQ_Attention_To_Detail',\n","#     'AQ_Communication', 'AQ_Imagination', 'AQ_Short_Social_Skill',\n","#     'AQ_Short_Routine', 'AQ_Short_Switching', 'AQ_Short_Imagination',\n","#     'AQ_Short_Numbers_and_Patterns', 'AQ_Three_Factor_Sociability',\n","#     'AQ_Three_Factor_Mentalizing', 'AQ_Three_Factor_Detail_Orientation',\n","#     'AQ_Total_Score', 'AQ_exclude_sparse', 'AQ_exclude_zero_std', 'Subject_ID'\n","# ]\n","\n","# # Selecting BIS columns to merge\n","# bis_columns_to_merge = [\n","#     'BIS_Attentional_Scores','BIS_Motor_Scores','BIS_Nonplanning_Scores','BIS_Final_Score',\n","#     'BIS_SD_of_Answers','BIS_Questions_Not_Answered', 'Subject_ID'\n","# ]\n","\n","# # Add yours here:\n","\n","# # Merge AQ data\n","# master_df = master_df.merge(scored_aq_data[aq_columns_to_merge], on='Subject_ID', how='left')\n","\n","# # Merge BIS data\n","# master_df = master_df.merge(scored_bis_data[bis_columns_to_merge], on='Subject_ID', how='left')\n","\n","# # Optionally, save the master dataframe\n","# master_df.to_csv('/content/drive/My Drive/battery_survey_scoring/analyses/master_df.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtzkjwiOpgja"},"outputs":[],"source":["# import pandas as pd\n","# from google.colab import drive\n","\n","# # Mount Google Drive\n","# drive.mount('/content/drive')\n","\n","# # Load survey data\n","# data_path = '/content/drive/My Drive/battery_survey_scoring/data/survey/Burnout Battery - Prolific (April 2024)_May 5, 2024_19.56.csv'\n","# data = pd.read_csv(data_path)\n","\n","# # Load worker data for Ts and Ls\n","# worker_data_path = '/content/drive/My Drive/battery_survey_scoring/data/worker_info/Ts-and-Ls_burnout_prolific_worker_data_S1.csv'\n","# worker_data = pd.read_csv(worker_data_path)\n","\n","# # Extract the 'workerId' column into a list\n","# prolific_ids = set(worker_data['workerId'].tolist())  # Use a set for faster lookup\n","\n","# # Mark each survey entry with whether the ID is in the worker data\n","# data['has_Ts_and_Ls'] = data['Q5'].apply(lambda x: 'Yes' if x in prolific_ids else 'No')\n","\n","# # Remove duplicates based on PROLIFIC_PID\n","# filtered_data = data.drop_duplicates(subset=['Q5'], keep='first')\n","\n","# # Output the number of unique PROLIFIC_PID in the survey and those matching with worker data\n","# print(f\"Total Prolific IDs in survey: {data['Q5'].nunique()}\")\n","# print(f\"Total unique IDs in filtered data: {filtered_data['Q5'].nunique()}\")\n","# print(f\"IDs matched with Ts and Ls data: {filtered_data['has_Ts_and_Ls'].value_counts()['Yes']}\")\n","\n","# import hashlib\n","# import pandas as pd\n","\n","# def hash_id(participant_id):\n","#     \"\"\"Hashes the participant ID using SHA-256.\"\"\"\n","#     hash_object = hashlib.sha256()\n","#     hash_object.update(participant_id.encode())\n","#     return hash_object.hexdigest()\n","\n","# # AQ Functions\n","# # Function to create the column names with 'ASQ_' prefix\n","# def asq_column(question_number):\n","#     return f'ASQ_{question_number}'\n","\n","# # Define question sets for each scoring scheme\n","# default_subscales = {\n","#     'Social_Skill': [1, 11, 13, 15, 22, 36, 44, 45, 47, 48],\n","#     'Attention_Switching': [2, 4, 10, 16, 25, 32, 34, 37, 43, 46],\n","#     'Attention_To_Detail': [5, 6, 9, 12, 19, 23, 28, 29, 30, 49],\n","#     'Communication': [7, 17, 18, 26, 27, 31, 33, 35, 38, 39],\n","#     'Imagination': [3, 8, 14, 20, 21, 24, 40, 41, 42, 50]\n","# }\n","\n","# asq_short_subscales = {\n","#     'ASQ_Short_Social_Skill': [1, 15, 36, 45, 50],\n","#     'ASQ_Short_Routine': [2, 25, 34, 46],\n","#     'ASQ_Short_Switching': [4, 10, 32, 37],\n","#     'ASQ_Short_Imagination': [3, 8, 14, 20, 36, 42, 45, 50],\n","#     'ASQ_Short_Numbers_and_Patterns': [6, 9, 19, 23, 41]\n","# }\n","\n","# three_factor_subscales = {\n","#     'Three_Factor_Sociability': [7, 11, 17, 28, 31, 42, 50],\n","#     'Three_Factor_Mentalizing': [2, 15, 23, 29, 30, 32],\n","#     'Three_Factor_Detail_Orientation': [3, 5, 12, 25, 26, 33, 38]\n","# }\n","\n","# macro_1_questions = [1, 2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]\n","# macro_2_questions = [3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]\n","\n","# def apply_asq_macros(row):\n","#     \"\"\"Apply macros for scoring questions.\"\"\"\n","#     scores = {}\n","\n","#     for question in macro_1_questions:\n","#         col = asq_column(question)\n","#         scores[col] = int(row[col] in [\"Definitely Agree\", \"Slightly Agree\"])\n","#         # 1 if definitely agree or slightly agree; else 0\n","\n","#     for question in macro_2_questions:\n","#         col = asq_column(question)\n","#         scores[col] = int(row[col] in [\"Definitely Disagree\", \"Slightly Disagree\"])\n","#         # 1 if definitely disagree or slightly disagree; else 0\n","\n","#     return pd.Series(scores)\n","\n","# def calculate_subscale_scores(df, subscales):\n","#     \"\"\"Calculate subscale scores given a subscale-question mapping.\"\"\"\n","#     for subscale_name, questions in subscales.items():\n","#         columns = [asq_column(q) for q in questions]\n","#         df[subscale_name] = df[columns].sum(axis=1)\n","\n","# # Quality check functions\n","# def flag_sparse_data(df, question_columns, min_answers=25):\n","#     \"\"\"Flag participants with less than the minimum number of answered questions.\"\"\"\n","#     answered_counts = df[question_columns].notna().sum(axis=1)\n","#     return answered_counts < min_answers\n","\n","# def flag_zero_std_data(df, question_columns):\n","#     \"\"\"Flag participants with standard deviation of zero.\"\"\"\n","#     return df[question_columns].std(axis=1) == 0\n","\n","# # Apply macros to score each ASQ question\n","# scored_data = filtered_data.apply(apply_asq_macros, axis=1)\n","\n","# # Flag data with less than half of the questions answered\n","# question_columns = [asq_column(q) for q in range(1, 51)]\n","# scored_data['exclude_sparse'] = flag_sparse_data(scored_data, question_columns).astype(str)\n","\n","# # Flag data with no standard deviation\n","# scored_data['exclude_zero_std'] = flag_zero_std_data(scored_data, question_columns).astype(str)\n","\n","# # Exclude flagged participants from getting subscale and total scores, but keep them in the data\n","# # Don't remove no standard deviation data or any of the data just use flags\n","# scored_data.loc[(scored_data['exclude_sparse'] == 'True') | (scored_data['exclude_zero_std'] == 'True'), scored_data.columns[scored_data.columns != 'exclude_sparse']] = None\n","\n","# # Calculate subscale scores and total score for the default scoring\n","# calculate_subscale_scores(scored_data, default_subscales)\n","# scored_data['Total_Score'] = scored_data.iloc[:, :50].sum(axis=1)\n","\n","# # Calculate subscale scores for the other scales\n","# calculate_subscale_scores(scored_data, asq_short_subscales)\n","# calculate_subscale_scores(scored_data, three_factor_subscales)\n","\n","# # Calculate the total score\n","# scored_data['Total_Score'] = scored_data.iloc[:, :50].sum(axis=1)\n","# scored_data.loc[(scored_data['exclude_sparse'] == 'True') | (scored_data['exclude_zero_std'] == 'True'), 'Total_Score'] = None\n","\n","# # Add hashed `PROLIFIC_PID` to the result\n","# scored_data['Subject_ID'] = filtered_data['Q5'].apply(hash_id)\n","\n","# # Export the resulting DataFrame to a CSV file\n","# scored_data.to_csv('/content/drive/My Drive/battery_survey_scoring/analyses/ASQ_Scored_All.csv', index=False)\n","\n","# print(\"CSV file with all ASQ scored data has been created.\")\n","\n","# # BIS Score\n","\n","# # Mapping of text answers to scores\n","# answer_scores = {\n","#     \"Rarely/Never\": 1,\n","#     \"Occasionally\": 2,\n","#     \"Often\": 3,\n","#     \"Almost always/Always\": 4\n","# }\n","\n","# # Function to clean and map scores\n","# def map_scores(value):\n","#     # Clean the string to remove leading/trailing whitespaces\n","#     value = str(value).strip()\n","#     # Return the mapped score or NaN if the value is not found\n","#     return answer_scores.get(value, np.nan)\n","\n","# # Function to reverse score the BIS items\n","# def BIS_reverse_score(value):\n","#     if pd.isna(value):\n","#         return value  # Preserve NaN values\n","#     return 5 - value\n","\n","# # Function to score the BIS survey\n","# def score_bis(df):\n","#     bis_columns = [f'BIS_{i}' for i in range(1, 31)]\n","#     new_df = df[bis_columns].copy()\n","\n","#     # Apply mapping and cleaning\n","#     new_df = new_df.applymap(map_scores)\n","\n","#     # Apply reverse scoring\n","#     reverse_scored_items = [1, 7, 8, 9, 10, 12, 13, 15, 20, 29, 30]\n","#     reverse_columns = [f'BIS_{item}' for item in reverse_scored_items]\n","#     new_df[reverse_columns] = new_df[reverse_columns].applymap(BIS_reverse_score)\n","\n","#     # Compute subscale scores\n","#     new_df['Attentional_Scores'] = new_df[['BIS_5', 'BIS_6', 'BIS_9', 'BIS_11', 'BIS_20', 'BIS_24', 'BIS_26', 'BIS_28']].sum(axis=1, min_count=1)\n","#     new_df['Motor_Scores'] = new_df[['BIS_2', 'BIS_3', 'BIS_4', 'BIS_16', 'BIS_17', 'BIS_19', 'BIS_21', 'BIS_22', 'BIS_23', 'BIS_25', 'BIS_30']].sum(axis=1, min_count=1)\n","#     new_df['Nonplanning_Scores'] = new_df[['BIS_2', 'BIS_7', 'BIS_8', 'BIS_10', 'BIS_12', 'BIS_13', 'BIS_14', 'BIS_15', 'BIS_18', 'BIS_27', 'BIS_29']].sum(axis=1, min_count=1)\n","\n","#     # Final and additional metrics\n","#     new_df['Final_Score'] = new_df[bis_columns].sum(axis=1, min_count=1)\n","#     new_df['SD_of_Answers'] = new_df[bis_columns].std(axis=1)\n","#     new_df['Questions_Not_Answered'] = new_df[bis_columns].isna().sum(axis=1)\n","\n","#     return new_df\n","\n","# # Assuming data is loaded as DataFrame named 'filtered_data'\n","# scored_bis_data = score_bis(filtered_data)\n","\n","# # Add hashed `PROLIFIC_PID` to the result\n","# scored_bis_data['Subject_ID'] = filtered_data['Q5'].apply(hash_id)\n","\n","# # Save the scored data\n","# scored_bis_data.to_csv('/content/drive/My Drive/battery_survey_scoring/analyses/scored_bis_data.csv', index=False)\n"]}],"metadata":{"colab":{"collapsed_sections":["CDcTfor4GRmT","5KrZtEOPKXi6","QLfGzXbLQ9Nw","dEjOhBakUYy5","FHvkrH-1XXV5","Dj5IT2_QY6OM","l8HPS-8jlaYU"],"provenance":[{"file_id":"1LYqZTELloRwdycbGP8B-dcJuvUz68Ojy","timestamp":1737476945053}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}